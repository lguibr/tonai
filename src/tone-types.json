{
  "classes.d.ts": "export * from \"./core/index\";\nexport * from \"./source/index\";\nexport * from \"./signal/index\";\nexport * from \"./instrument/index\";\nexport * from \"./event/index\";\nexport * from \"./effect/index\";\nexport * from \"./component/index\";\n",
  "component/analysis/Analyser.d.ts": "import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { NormalRange, PowerOfTwo } from \"../../core/type/Units\";\nexport type AnalyserType = \"fft\" | \"waveform\";\nexport interface AnalyserOptions extends ToneAudioNodeOptions {\n    size: PowerOfTwo;\n    type: AnalyserType;\n    smoothing: NormalRange;\n    channels: number;\n}\n/**\n * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n * Extracts FFT or Waveform data from the incoming signal.\n * @category Component\n */\nexport declare class Analyser extends ToneAudioNode<AnalyserOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * The analyser node.\n     */\n    private _analysers;\n    /**\n     * Input and output are a gain node\n     */\n    private _gain;\n    /**\n     * The channel splitter node\n     */\n    private _split;\n    /**\n     * The analysis type\n     */\n    private _type;\n    /**\n     * The buffer that the FFT data is written to\n     */\n    private _buffers;\n    /**\n     * @param type The return type of the analysis, either \"fft\", or \"waveform\".\n     * @param size The size of the FFT. This must be a power of two in the range 16 to 16384.\n     */\n    constructor(type?: AnalyserType, size?: number);\n    constructor(options?: Partial<AnalyserOptions>);\n    static getDefaults(): AnalyserOptions;\n    /**\n     * Run the analysis given the current settings. If {@link channels} = 1,\n     * it will return a Float32Array. If {@link channels} > 1, it will\n     * return an array of Float32Arrays where each index in the array\n     * represents the analysis done on a channel.\n     */\n    getValue(): Float32Array | Float32Array[];\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     */\n    get size(): PowerOfTwo;\n    set size(size: PowerOfTwo);\n    /**\n     * The number of channels the analyser does the analysis on. Channel\n     * separation is done using {@link Split}\n     */\n    get channels(): number;\n    /**\n     * The analysis function returned by analyser.getValue(), either \"fft\" or \"waveform\".\n     */\n    get type(): AnalyserType;\n    set type(type: AnalyserType);\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing(): NormalRange;\n    set smoothing(val: NormalRange);\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "component/analysis/DCMeter.d.ts": "import { MeterBase, MeterBaseOptions } from \"./MeterBase\";\nexport type DCMeterOptions = MeterBaseOptions;\n/**\n * DCMeter gets the raw value of the input signal at the current time.\n * @see {@link Meter}.\n *\n * @example\n * const meter = new Tone.DCMeter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * const level = meter.getValue();\n * @category Component\n */\nexport declare class DCMeter extends MeterBase<DCMeterOptions> {\n    readonly name: string;\n    constructor(options?: Partial<DCMeterOptions>);\n    /**\n     * Get the signal value of the incoming signal\n     */\n    getValue(): number;\n}\n",
  "component/analysis/FFT.d.ts": "import { Hertz, NormalRange, PowerOfTwo } from \"../../core/type/Units\";\nimport { MeterBase, MeterBaseOptions } from \"./MeterBase\";\nexport interface FFTOptions extends MeterBaseOptions {\n    size: PowerOfTwo;\n    smoothing: NormalRange;\n    normalRange: boolean;\n}\n/**\n * Get the current frequency data of the connected audio source using a fast Fourier transform.\n * Read more about FFT algorithms on [Wikipedia] (https://en.wikipedia.org/wiki/Fast_Fourier_transform).\n * @category Component\n */\nexport declare class FFT extends MeterBase<FFTOptions> {\n    readonly name: string;\n    /**\n     * If the output should be in decibels or normal range between 0-1. If `normalRange` is false,\n     * the output range will be the measured decibel value, otherwise the decibel value will be converted to\n     * the range of 0-1\n     */\n    normalRange: boolean;\n    /**\n     * @param size The size of the FFT. Value must be a power of two in the range 16 to 16384.\n     */\n    constructor(size?: PowerOfTwo);\n    constructor(options?: Partial<FFTOptions>);\n    static getDefaults(): FFTOptions;\n    /**\n     * Gets the current frequency data from the connected audio source.\n     * Returns the frequency data of length {@link size} as a Float32Array of decibel values.\n     */\n    getValue(): Float32Array;\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by {@link getValue} (i.e. the number of\n     * frequency bins). Large FFT sizes may be costly to compute.\n     */\n    get size(): PowerOfTwo;\n    set size(size: PowerOfTwo);\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing(): NormalRange;\n    set smoothing(val: NormalRange);\n    /**\n     * Returns the frequency value in hertz of each of the indices of the FFT's {@link getValue} response.\n     * @example\n     * const fft = new Tone.FFT(32);\n     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));\n     */\n    getFrequencyOfIndex(index: number): Hertz;\n}\n",
  "component/analysis/Follower.d.ts": "import { Time } from \"../../core/type/Units\";\nimport { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nexport interface FollowerOptions extends ToneAudioNodeOptions {\n    smoothing: Time;\n}\n/**\n * Follower is a simple envelope follower.\n * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.\n * ```\n *          +-----+    +---------------+\n * Input +--> Abs +----> OnePoleFilter +--> Output\n *          +-----+    +---------------+\n * ```\n * @category Component\n */\nexport declare class Follower extends ToneAudioNode<FollowerOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * Private reference to the smoothing parameter\n     */\n    private _smoothing;\n    /**\n     * The lowpass filter\n     */\n    private _lowpass;\n    /**\n     * The absolute value\n     */\n    private _abs;\n    /**\n     * @param smoothing The rate of change of the follower.\n     */\n    constructor(smoothing?: Time);\n    constructor(options?: Partial<FollowerOptions>);\n    static getDefaults(): FollowerOptions;\n    /**\n     * The amount of time it takes a value change to arrive at the updated value.\n     */\n    get smoothing(): Time;\n    set smoothing(smoothing: Time);\n    dispose(): this;\n}\n",
  "component/analysis/Meter.d.ts": "import { NormalRange } from \"../../core/type/Units\";\nimport { MeterBase, MeterBaseOptions } from \"./MeterBase\";\nexport interface MeterOptions extends MeterBaseOptions {\n    smoothing: NormalRange;\n    normalRange: boolean;\n    channelCount: number;\n}\n/**\n * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n * of an input signal. It can also get the raw value of the input signal.\n * Setting `normalRange` to `true` will covert the output to a range of\n * 0-1. See an example using a graphical display\n * [here](https://tonejs.github.io/examples/meter).\n * @see {@link DCMeter}.\n *\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * setInterval(() => console.log(meter.getValue()), 100);\n * @category Component\n */\nexport declare class Meter extends MeterBase<MeterOptions> {\n    readonly name: string;\n    /**\n     * If the output should be in decibels or normal range between 0-1. If `normalRange` is false,\n     * the output range will be the measured decibel value, otherwise the decibel value will be converted to\n     * the range of 0-1\n     */\n    normalRange: boolean;\n    /**\n     * A value from between 0 and 1 where 0 represents no time averaging with the last analysis frame.\n     */\n    smoothing: number;\n    /**\n     * The previous frame's value for each channel.\n     */\n    private _rms;\n    /**\n     * @param smoothing The amount of smoothing applied between frames.\n     */\n    constructor(smoothing?: NormalRange);\n    constructor(options?: Partial<MeterOptions>);\n    static getDefaults(): MeterOptions;\n    /**\n     * Use {@link getValue} instead. For the previous getValue behavior, use DCMeter.\n     * @deprecated\n     */\n    getLevel(): number | number[];\n    /**\n     * Get the current value of the incoming signal.\n     * Output is in decibels when {@link normalRange} is `false`.\n     * If {@link channels} = 1, then the output is a single number\n     * representing the value of the input signal. When {@link channels} > 1,\n     * then each channel is returned as a value in a number array.\n     */\n    getValue(): number | number[];\n    /**\n     * The number of channels of analysis.\n     */\n    get channels(): number;\n    dispose(): this;\n}\n",
  "component/analysis/MeterBase.d.ts": "import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Analyser } from \"./Analyser\";\nexport type MeterBaseOptions = ToneAudioNodeOptions;\n/**\n * The base class for Metering classes.\n */\nexport declare class MeterBase<Options extends MeterBaseOptions> extends ToneAudioNode<Options> {\n    readonly name: string;\n    /**\n     * The signal to be analysed\n     */\n    input: InputNode;\n    /**\n     * The output is just a pass through of the input\n     */\n    output: OutputNode;\n    /**\n     * The analyser node for the incoming signal\n     */\n    protected _analyser: Analyser;\n    constructor(options?: Partial<MeterBaseOptions>);\n    dispose(): this;\n}\n",
  "component/analysis/Waveform.d.ts": "import { PowerOfTwo } from \"../../core/type/Units\";\nimport { MeterBase, MeterBaseOptions } from \"./MeterBase\";\nexport interface WaveformOptions extends MeterBaseOptions {\n    /**\n     * The size of the Waveform. Value must be a power of two in the range 16 to 16384.\n     */\n    size: PowerOfTwo;\n}\n/**\n * Get the current waveform data of the connected audio source.\n * @category Component\n */\nexport declare class Waveform extends MeterBase<WaveformOptions> {\n    readonly name: string;\n    /**\n     * @param size The size of the Waveform. Value must be a power of two in the range 16 to 16384.\n     */\n    constructor(size?: PowerOfTwo);\n    constructor(options?: Partial<WaveformOptions>);\n    static getDefaults(): WaveformOptions;\n    /**\n     * Return the waveform for the current time as a Float32Array where each value in the array\n     * represents a sample in the waveform.\n     */\n    getValue(): Float32Array;\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by {@link getValue}.\n     */\n    get size(): PowerOfTwo;\n    set size(size: PowerOfTwo);\n}\n",
  "component/channel/Channel.d.ts": "import { AudioRange, Decibels } from \"../../core/type/Units\";\nimport { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Param } from \"../../core/context/Param\";\nimport { Gain } from \"../../core/context/Gain\";\nexport interface ChannelOptions extends ToneAudioNodeOptions {\n    pan: AudioRange;\n    volume: Decibels;\n    solo: boolean;\n    mute: boolean;\n    channelCount: number;\n}\n/**\n * Channel provides a channel strip interface with volume, pan, solo and mute controls.\n * @see {@link PanVol} and {@link Solo}\n * @example\n * // pan the incoming signal left and drop the volume 12db\n * const channel = new Tone.Channel(-0.25, -12);\n * @category Component\n */\nexport declare class Channel extends ToneAudioNode<ChannelOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * The soloing interface\n     */\n    private _solo;\n    /**\n     * The panning and volume node\n     */\n    private _panVol;\n    /**\n     * The L/R panning control. -1 = hard left, 1 = hard right.\n     * @min -1\n     * @max 1\n     */\n    readonly pan: Param<\"audioRange\">;\n    /**\n     * The volume control in decibels.\n     */\n    readonly volume: Param<\"decibels\">;\n    /**\n     * @param volume The output volume.\n     * @param pan the initial pan\n     */\n    constructor(volume?: Decibels, pan?: AudioRange);\n    constructor(options?: Partial<ChannelOptions>);\n    static getDefaults(): ChannelOptions;\n    /**\n     * Solo/unsolo the channel. Soloing is only relative to other {@link Channel}s and {@link Solo} instances\n     */\n    get solo(): boolean;\n    set solo(solo: boolean);\n    /**\n     * If the current instance is muted, i.e. another instance is soloed,\n     * or the channel is muted\n     */\n    get muted(): boolean;\n    /**\n     * Mute/unmute the volume\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    /**\n     * Store the send/receive channels by name.\n     */\n    private static buses;\n    /**\n     * Get the gain node belonging to the bus name. Create it if\n     * it doesn't exist\n     * @param name The bus name\n     */\n    private _getBus;\n    /**\n     * Send audio to another channel using a string. `send` is a lot like\n     * {@link connect}, except it uses a string instead of an object. This can\n     * be useful in large applications to decouple sections since {@link send}\n     * and {@link receive} can be invoked separately in order to connect an object\n     * @param name The channel name to send the audio\n     * @param volume The amount of the signal to send.\n     * \tDefaults to 0db, i.e. send the entire signal\n     * @returns Returns the gain node of this connection.\n     */\n    send(name: string, volume?: Decibels): Gain<\"decibels\">;\n    /**\n     * Receive audio from a channel which was connected with {@link send}.\n     * @param name The channel name to receive audio from.\n     */\n    receive(name: string): this;\n    dispose(): this;\n}\n",
  "component/channel/CrossFade.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { NormalRange } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\ninterface CrossFadeOptions extends ToneAudioNodeOptions {\n    fade: NormalRange;\n}\n/**\n * Tone.Crossfade provides equal power fading between two inputs.\n * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).\n * ```\n *                                             +---------+\n *                                            +> input a +>--+\n * +-----------+   +---------------------+     |         |   |\n * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |\n * +-----------+   |                     |     +---------+   |\n *               +-> pan               R +>-+                |   +--------+\n *               | +---------------------+  |                +---> output +>\n *  +------+     |                          |  +---------+   |   +--------+\n *  | fade +>----+                          | +> input b +>--+\n *  +------+                                |  |         |\n *                                          +--> gain    |\n *                                             +---------+\n * ```\n * @example\n * const crossFade = new Tone.CrossFade().toDestination();\n * // connect two inputs Tone.to a/b\n * const inputA = new Tone.Oscillator(440, \"square\").connect(crossFade.a).start();\n * const inputB = new Tone.Oscillator(440, \"sine\").connect(crossFade.b).start();\n * // use the fade to control the mix between the two\n * crossFade.fade.value = 0.5;\n * @category Component\n */\nexport declare class CrossFade extends ToneAudioNode<CrossFadeOptions> {\n    readonly name: string;\n    /**\n     * The crossfading is done by a StereoPannerNode\n     */\n    private _panner;\n    /**\n     * Split the output of the panner node into two values used to control the gains.\n     */\n    private _split;\n    /**\n     * Convert the fade value into an audio range value so it can be connected\n     * to the panner.pan AudioParam\n     */\n    private _g2a;\n    /**\n     * The input which is at full level when fade = 0\n     */\n    readonly a: Gain;\n    /**\n     * The input which is at full level when fade = 1\n     */\n    readonly b: Gain;\n    /**\n     * The output is a mix between `a` and `b` at the ratio of `fade`\n     */\n    readonly output: Gain;\n    /**\n     * CrossFade has no input, you must choose either `a` or `b`\n     */\n    readonly input: undefined;\n    /**\n     * The mix between the two inputs. A fade value of 0\n     * will output 100% crossFade.a and\n     * a value of 1 will output 100% crossFade.b.\n     */\n    readonly fade: Signal<\"normalRange\">;\n    protected _internalChannels: Gain<\"gain\">[];\n    /**\n     * @param fade The initial fade value [0, 1].\n     */\n    constructor(fade?: NormalRange);\n    constructor(options?: Partial<CrossFadeOptions>);\n    static getDefaults(): CrossFadeOptions;\n    dispose(): this;\n}\nexport {};\n",
  "component/channel/Merge.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Positive } from \"../../core/type/Units\";\ninterface MergeOptions extends ToneAudioNodeOptions {\n    channels: Positive;\n}\n/**\n * Merge brings multiple mono input channels into a single multichannel output channel.\n *\n * @example\n * const merge = new Tone.Merge().toDestination();\n * // routing a sine tone in the left channel\n * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();\n * // and noise in the right channel\n * const noise = new Tone.Noise().connect(merge, 0, 1).start();;\n * @category Component\n */\nexport declare class Merge extends ToneAudioNode<MergeOptions> {\n    readonly name: string;\n    /**\n     * The merger node for the channels.\n     */\n    private _merger;\n    /**\n     * The output is the input channels combined into a single (multichannel) output\n     */\n    readonly output: ChannelMergerNode;\n    /**\n     * Multiple input connections combine into a single output.\n     */\n    readonly input: ChannelMergerNode;\n    /**\n     * @param channels The number of channels to merge.\n     */\n    constructor(channels?: Positive);\n    constructor(options?: Partial<MergeOptions>);\n    static getDefaults(): MergeOptions;\n    dispose(): this;\n}\nexport {};\n",
  "component/channel/MidSideMerge.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Merge } from \"./Merge\";\nexport type MidSideMergeOptions = ToneAudioNodeOptions;\n/**\n * MidSideMerge merges the mid and side signal after they've been separated by {@link MidSideSplit}\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nexport declare class MidSideMerge extends ToneAudioNode<MidSideMergeOptions> {\n    readonly name: string;\n    /**\n     * There is no input, connect sources to either {@link mid} or {@link side} inputs.\n     */\n    readonly input: undefined;\n    /**\n     * The merged signal\n     */\n    readonly output: Merge;\n    /**\n     * Merge the incoming signal into left and right channels\n     */\n    private _merge;\n    /**\n     * The \"mid\" input.\n     */\n    readonly mid: ToneAudioNode;\n    /**\n     * The \"side\" input.\n     */\n    readonly side: ToneAudioNode;\n    /**\n     * Recombine the mid/side into Left\n     */\n    private _left;\n    /**\n     * Recombine the mid/side into Right\n     */\n    private _right;\n    /**\n     * Multiply the right by sqrt(1/2)\n     */\n    private _leftMult;\n    /**\n     * Multiply the left by sqrt(1/2)\n     */\n    private _rightMult;\n    constructor(options?: Partial<MidSideMergeOptions>);\n    dispose(): this;\n}\n",
  "component/channel/MidSideSplit.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Split } from \"./Split\";\nexport type MidSideSplitOptions = ToneAudioNodeOptions;\n/**\n * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels).\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nexport declare class MidSideSplit extends ToneAudioNode<MidSideSplitOptions> {\n    readonly name: string;\n    readonly input: Split;\n    /**\n     * There is no output node, use either {@link mid} or {@link side} outputs.\n     */\n    readonly output: undefined;\n    /**\n     * Split the incoming signal into left and right channels\n     */\n    private _split;\n    /**\n     * Sums the left and right channels\n     */\n    private _midAdd;\n    /**\n     * Subtract left and right channels.\n     */\n    private _sideSubtract;\n    /**\n     * The \"mid\" output. `(Left+Right)/sqrt(2)`\n     */\n    readonly mid: ToneAudioNode;\n    /**\n     * The \"side\" output. `(Left-Right)/sqrt(2)`\n     */\n    readonly side: ToneAudioNode;\n    constructor(options?: Partial<MidSideSplitOptions>);\n    dispose(): this;\n}\n",
  "component/channel/Mono.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nexport type MonoOptions = ToneAudioNodeOptions;\n/**\n * Mono coerces the incoming mono or stereo signal into a mono signal\n * where both left and right channels have the same value. This can be useful\n * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).\n * @category Component\n */\nexport declare class Mono extends ToneAudioNode<MonoOptions> {\n    readonly name: string;\n    /**\n     * merge the signal\n     */\n    private _merge;\n    /**\n     * The summed output of the multiple inputs\n     */\n    readonly output: OutputNode;\n    /**\n     * The stereo signal to sum to mono\n     */\n    readonly input: Gain;\n    constructor(options?: Partial<MonoOptions>);\n    dispose(): this;\n}\n",
  "component/channel/MultibandSplit.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Frequency, Positive } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Filter } from \"../filter/Filter\";\ninterface MultibandSplitOptions extends ToneAudioNodeOptions {\n    Q: Positive;\n    lowFrequency: Frequency;\n    highFrequency: Frequency;\n}\n/**\n * Split the incoming signal into three bands (low, mid, high)\n * with two crossover frequency controls.\n * ```\n *            +----------------------+\n *          +-> input < lowFrequency +------------------> low\n *          | +----------------------+\n *          |\n *          | +--------------------------------------+\n * input ---+-> lowFrequency < input < highFrequency +--> mid\n *          | +--------------------------------------+\n *          |\n *          | +-----------------------+\n *          +-> highFrequency < input +-----------------> high\n *            +-----------------------+\n * ```\n * @category Component\n */\nexport declare class MultibandSplit extends ToneAudioNode<MultibandSplitOptions> {\n    readonly name: string;\n    /**\n     * the input\n     */\n    readonly input: Gain<\"gain\">;\n    /**\n     * no output node, use either low, mid or high outputs\n     */\n    readonly output: undefined;\n    /**\n     * The low band.\n     */\n    readonly low: Filter;\n    /**\n     * the lower filter of the mid band\n     */\n    private _lowMidFilter;\n    /**\n     * The mid band output.\n     */\n    readonly mid: Filter;\n    /**\n     * The high band output.\n     */\n    readonly high: Filter;\n    /**\n     * The low/mid crossover frequency.\n     */\n    readonly lowFrequency: Signal<\"frequency\">;\n    /**\n     * The mid/high crossover frequency.\n     */\n    readonly highFrequency: Signal<\"frequency\">;\n    protected _internalChannels: Filter[];\n    /**\n     * The Q or Quality of the filter\n     */\n    readonly Q: Signal<\"positive\">;\n    /**\n     * @param lowFrequency the low/mid crossover frequency\n     * @param highFrequency the mid/high crossover frequency\n     */\n    constructor(lowFrequency?: Frequency, highFrequency?: Frequency);\n    constructor(options?: Partial<MultibandSplitOptions>);\n    static getDefaults(): MultibandSplitOptions;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "component/channel/PanVol.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { AudioRange, Decibels } from \"../../core/type/Units\";\nexport interface PanVolOptions extends ToneAudioNodeOptions {\n    pan: AudioRange;\n    volume: Decibels;\n    mute: boolean;\n    channelCount: number;\n}\n/**\n * PanVol is a Tone.Panner and Tone.Volume in one.\n * @example\n * // pan the incoming signal left and drop the volume\n * const panVol = new Tone.PanVol(-0.25, -12).toDestination();\n * const osc = new Tone.Oscillator().connect(panVol).start();\n * @category Component\n */\nexport declare class PanVol extends ToneAudioNode<PanVolOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * The panning node\n     */\n    private _panner;\n    /**\n     * The L/R panning control. -1 = hard left, 1 = hard right.\n     * @min -1\n     * @max 1\n     */\n    readonly pan: Param<\"audioRange\">;\n    /**\n     * The volume node\n     */\n    private _volume;\n    /**\n     * The volume control in decibels.\n     */\n    readonly volume: Param<\"decibels\">;\n    /**\n     * @param pan the initial pan\n     * @param volume The output volume.\n     */\n    constructor(pan?: AudioRange, volume?: Decibels);\n    constructor(options?: Partial<PanVolOptions>);\n    static getDefaults(): PanVolOptions;\n    /**\n     * Mute/unmute the volume\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    dispose(): this;\n}\n",
  "component/channel/Panner.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { AudioRange } from \"../../core/type/Units\";\ninterface TonePannerOptions extends ToneAudioNodeOptions {\n    pan: AudioRange;\n    channelCount: number;\n}\n/**\n * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.\n * @example\n * return Tone.Offline(() => {\n * // move the input signal from right to left\n * \tconst panner = new Tone.Panner(1).toDestination();\n * \tpanner.pan.rampTo(-1, 0.5);\n * \tconst osc = new Tone.Oscillator(100).connect(panner).start();\n * }, 0.5, 2);\n * @category Component\n */\nexport declare class Panner extends ToneAudioNode<TonePannerOptions> {\n    readonly name: string;\n    /**\n     * the panner node\n     */\n    private _panner;\n    readonly input: StereoPannerNode;\n    readonly output: StereoPannerNode;\n    /**\n     * The pan control. -1 = hard left, 1 = hard right.\n     * @min -1\n     * @max 1\n     * @example\n     * return Tone.Offline(() => {\n     * \t// pan hard right\n     * \tconst panner = new Tone.Panner(1).toDestination();\n     * \t// pan hard left\n     * \tpanner.pan.setValueAtTime(-1, 0.25);\n     * \tconst osc = new Tone.Oscillator(50, \"triangle\").connect(panner).start();\n     * }, 0.5, 2);\n     */\n    readonly pan: Param<\"audioRange\">;\n    constructor(options?: Partial<TonePannerOptions>);\n    /**\n     * @param pan The initial panner value (Defaults to 0 = \"center\").\n     */\n    constructor(pan?: AudioRange);\n    static getDefaults(): TonePannerOptions;\n    dispose(): this;\n}\nexport {};\n",
  "component/channel/Panner3D.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Degrees, GainFactor } from \"../../core/type/Units\";\nimport  \"../../core/context/Listener\";\nexport interface Panner3DOptions extends ToneAudioNodeOptions {\n    coneInnerAngle: Degrees;\n    coneOuterAngle: Degrees;\n    coneOuterGain: GainFactor;\n    distanceModel: DistanceModelType;\n    maxDistance: number;\n    orientationX: number;\n    orientationY: number;\n    orientationZ: number;\n    panningModel: PanningModelType;\n    positionX: number;\n    positionY: number;\n    positionZ: number;\n    refDistance: number;\n    rolloffFactor: number;\n}\n/**\n * A spatialized panner node which supports equalpower or HRTF panning.\n * @category Component\n */\nexport declare class Panner3D extends ToneAudioNode<Panner3DOptions> {\n    readonly name: string;\n    /**\n     * The panning object\n     */\n    private _panner;\n    readonly input: PannerNode;\n    readonly output: PannerNode;\n    readonly positionX: Param<\"number\">;\n    readonly positionY: Param<\"number\">;\n    readonly positionZ: Param<\"number\">;\n    readonly orientationX: Param<\"number\">;\n    readonly orientationY: Param<\"number\">;\n    readonly orientationZ: Param<\"number\">;\n    /**\n     * @param positionX The initial x position.\n     * @param positionY The initial y position.\n     * @param positionZ The initial z position.\n     */\n    constructor(positionX: number, positionY: number, positionZ: number);\n    constructor(options?: Partial<Panner3DOptions>);\n    static getDefaults(): Panner3DOptions;\n    /**\n     * Sets the position of the source in 3d space.\n     */\n    setPosition(x: number, y: number, z: number): this;\n    /**\n     * Sets the orientation of the source in 3d space.\n     */\n    setOrientation(x: number, y: number, z: number): this;\n    /**\n     * The panning model. Either \"equalpower\" or \"HRTF\".\n     */\n    get panningModel(): PanningModelType;\n    set panningModel(val: PanningModelType);\n    /**\n     * A reference distance for reducing volume as source move further from the listener\n     */\n    get refDistance(): number;\n    set refDistance(val: number);\n    /**\n     * Describes how quickly the volume is reduced as source moves away from listener.\n     */\n    get rolloffFactor(): number;\n    set rolloffFactor(val: number);\n    /**\n     * The distance model used by,  \"linear\", \"inverse\", or \"exponential\".\n     */\n    get distanceModel(): DistanceModelType;\n    set distanceModel(val: DistanceModelType);\n    /**\n     * The angle, in degrees, inside of which there will be no volume reduction\n     */\n    get coneInnerAngle(): Degrees;\n    set coneInnerAngle(val: Degrees);\n    /**\n     * The angle, in degrees, outside of which the volume will be reduced\n     * to a constant value of coneOuterGain\n     */\n    get coneOuterAngle(): Degrees;\n    set coneOuterAngle(val: Degrees);\n    /**\n     * The gain outside of the coneOuterAngle\n     */\n    get coneOuterGain(): GainFactor;\n    set coneOuterGain(val: GainFactor);\n    /**\n     * The maximum distance between source and listener,\n     * after which the volume will not be reduced any further.\n     */\n    get maxDistance(): number;\n    set maxDistance(val: number);\n    dispose(): this;\n}\n",
  "component/channel/Recorder.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { PlaybackState } from \"../../core/util/StateTimeline\";\nexport interface RecorderOptions extends ToneAudioNodeOptions {\n    mimeType?: string;\n}\n/**\n * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer\n * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.\n * This is only natively supported in Chrome and Firefox.\n * For a cross-browser shim, install [audio-recorder-polyfill](https://www.npmjs.com/package/audio-recorder-polyfill).\n * @example\n * const recorder = new Tone.Recorder();\n * const synth = new Tone.Synth().connect(recorder);\n * // start recording\n * recorder.start();\n * // generate a few notes\n * synth.triggerAttackRelease(\"C3\", 0.5);\n * synth.triggerAttackRelease(\"C4\", 0.5, \"+1\");\n * synth.triggerAttackRelease(\"C5\", 0.5, \"+2\");\n * // wait for the notes to end and stop the recording\n * setTimeout(async () => {\n * \t// the recorded audio is returned as a blob\n * \tconst recording = await recorder.stop();\n * \t// download the recording by creating an anchor element and blob url\n * \tconst url = URL.createObjectURL(recording);\n * \tconst anchor = document.createElement(\"a\");\n * \tanchor.download = \"recording.webm\";\n * \tanchor.href = url;\n * \tanchor.click();\n * }, 4000);\n * @category Component\n */\nexport declare class Recorder extends ToneAudioNode<RecorderOptions> {\n    readonly name = \"Recorder\";\n    /**\n     * Recorder uses the Media Recorder API\n     */\n    private _recorder;\n    /**\n     * MediaRecorder requires\n     */\n    private _stream;\n    readonly input: Gain;\n    readonly output: undefined;\n    constructor(options?: Partial<RecorderOptions>);\n    static getDefaults(): RecorderOptions;\n    /**\n     * The mime type is the format that the audio is encoded in. For Chrome\n     * that is typically webm encoded as \"vorbis\".\n     */\n    get mimeType(): string;\n    /**\n     * Test if your platform supports the Media Recorder API. If it's not available,\n     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n     */\n    static get supported(): boolean;\n    /**\n     * Get the playback state of the Recorder, either \"started\", \"stopped\" or \"paused\"\n     */\n    get state(): PlaybackState;\n    /**\n     * Start/Resume the Recorder. Returns a promise which resolves\n     * when the recorder has started.\n     */\n    start(): Promise<void>;\n    /**\n     * Stop the recorder. Returns a promise with the recorded content until this point\n     * encoded as {@link mimeType}\n     */\n    stop(): Promise<Blob>;\n    /**\n     * Pause the recorder\n     */\n    pause(): this;\n    dispose(): this;\n}\n",
  "component/channel/Solo.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nexport interface SoloOptions extends ToneAudioNodeOptions {\n    solo: boolean;\n}\n/**\n * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,\n * it will mute all other instances of Solo.\n * @example\n * const soloA = new Tone.Solo().toDestination();\n * const oscA = new Tone.Oscillator(\"C4\", \"sawtooth\").connect(soloA);\n * const soloB = new Tone.Solo().toDestination();\n * const oscB = new Tone.Oscillator(\"E4\", \"square\").connect(soloB);\n * soloA.solo = true;\n * // no audio will pass through soloB\n * @category Component\n */\nexport declare class Solo extends ToneAudioNode<SoloOptions> {\n    readonly name: string;\n    readonly input: Gain;\n    readonly output: Gain;\n    /**\n     * @param solo If the connection should be initially solo'ed.\n     */\n    constructor(solo?: boolean);\n    constructor(options?: Partial<SoloOptions>);\n    static getDefaults(): SoloOptions;\n    /**\n     * Hold all of the solo'ed tracks belonging to a specific context\n     */\n    private static _allSolos;\n    /**\n     * Hold the currently solo'ed instance(s)\n     */\n    private static _soloed;\n    /**\n     * Isolates this instance and mutes all other instances of Solo.\n     * Only one instance can be soloed at a time. A soloed\n     * instance will report `solo=false` when another instance is soloed.\n     */\n    get solo(): boolean;\n    set solo(solo: boolean);\n    /**\n     * If the current instance is muted, i.e. another instance is soloed\n     */\n    get muted(): boolean;\n    /**\n     * Add this to the soloed array\n     */\n    private _addSolo;\n    /**\n     * Remove this from the soloed array\n     */\n    private _removeSolo;\n    /**\n     * Is this on the soloed array\n     */\n    private _isSoloed;\n    /**\n     * Returns true if no one is soloed\n     */\n    private _noSolos;\n    /**\n     * Solo the current instance and unsolo all other instances.\n     */\n    private _updateSolo;\n    dispose(): this;\n}\n",
  "component/channel/Split.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\ninterface SplitOptions extends ToneAudioNodeOptions {\n    channels: number;\n}\n/**\n * Split splits an incoming signal into the number of given channels.\n *\n * @example\n * const split = new Tone.Split();\n * // stereoSignal.connect(split);\n * @category Component\n */\nexport declare class Split extends ToneAudioNode<SplitOptions> {\n    readonly name: string;\n    /**\n     * The splitting node\n     */\n    private _splitter;\n    readonly input: ChannelSplitterNode;\n    readonly output: ChannelSplitterNode;\n    /**\n     * @param channels The number of channels to merge.\n     */\n    constructor(channels?: number);\n    constructor(options?: Partial<SplitOptions>);\n    static getDefaults(): SplitOptions;\n    dispose(): this;\n}\nexport {};\n",
  "component/channel/Volume.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Decibels } from \"../../core/type/Units\";\ninterface VolumeOptions extends ToneAudioNodeOptions {\n    volume: Decibels;\n    mute: boolean;\n}\n/**\n * Volume is a simple volume node, useful for creating a volume fader.\n *\n * @example\n * const vol = new Tone.Volume(-12).toDestination();\n * const osc = new Tone.Oscillator().connect(vol).start();\n * @category Component\n */\nexport declare class Volume extends ToneAudioNode<VolumeOptions> {\n    readonly name: string;\n    /**\n     * the output node\n     */\n    output: Gain<\"decibels\">;\n    /**\n     * Input and output are the same\n     */\n    input: Gain<\"decibels\">;\n    /**\n     * The unmuted volume\n     */\n    private _unmutedVolume;\n    /**\n     * The volume control in decibels.\n     * @example\n     * const vol = new Tone.Volume().toDestination();\n     * const osc = new Tone.Oscillator().connect(vol).start();\n     * vol.volume.value = -20;\n     */\n    volume: Param<\"decibels\">;\n    /**\n     * @param volume the initial volume in decibels\n     */\n    constructor(volume?: Decibels);\n    constructor(options?: Partial<VolumeOptions>);\n    static getDefaults(): VolumeOptions;\n    /**\n     * Mute the output.\n     * @example\n     * const vol = new Tone.Volume(-12).toDestination();\n     * const osc = new Tone.Oscillator().connect(vol).start();\n     * // mute the output\n     * vol.mute = true;\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "component/dynamics/Compressor.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Decibels, Positive, Time } from \"../../core/type/Units\";\nexport interface CompressorOptions extends ToneAudioNodeOptions {\n    attack: Time;\n    knee: Decibels;\n    ratio: Positive;\n    release: Time;\n    threshold: Decibels;\n}\n/**\n * Compressor is a thin wrapper around the Web Audio\n * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n * Compression reduces the volume of loud sounds or amplifies quiet sounds\n * by narrowing or \"compressing\" an audio signal's dynamic range.\n * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).\n * @example\n * const comp = new Tone.Compressor(-30, 3);\n * @category Component\n */\nexport declare class Compressor extends ToneAudioNode<CompressorOptions> {\n    readonly name: string;\n    /**\n     * the compressor node\n     */\n    private _compressor;\n    readonly input: DynamicsCompressorNode;\n    readonly output: DynamicsCompressorNode;\n    /**\n     * The decibel value above which the compression will start taking effect.\n     * @min -100\n     * @max 0\n     */\n    readonly threshold: Param<\"decibels\">;\n    /**\n     * The amount of time (in seconds) to reduce the gain by 10dB.\n     * @min 0\n     * @max 1\n     */\n    readonly attack: Param<\"time\">;\n    /**\n     * The amount of time (in seconds) to increase the gain by 10dB.\n     * @min 0\n     * @max 1\n     */\n    readonly release: Param<\"time\">;\n    /**\n     * A decibel value representing the range above the threshold where the\n     * curve smoothly transitions to the \"ratio\" portion.\n     * @min 0\n     * @max 40\n     */\n    readonly knee: Param<\"decibels\">;\n    /**\n     * The amount of dB change in input for a 1 dB change in output.\n     * @min 1\n     * @max 20\n     */\n    readonly ratio: Param<\"positive\">;\n    /**\n     * @param threshold The value above which the compression starts to be applied.\n     * @param ratio The gain reduction ratio.\n     */\n    constructor(threshold?: Decibels, ratio?: Positive);\n    constructor(options?: Partial<CompressorOptions>);\n    static getDefaults(): CompressorOptions;\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).\n     */\n    get reduction(): Decibels;\n    dispose(): this;\n}\n",
  "component/dynamics/Gate.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Decibels, Time } from \"../../core/type/Units\";\nexport interface GateOptions extends ToneAudioNodeOptions {\n    threshold: Decibels;\n    smoothing: Time;\n}\n/**\n * Gate only passes a signal through when the incoming\n * signal exceeds a specified threshold. It uses {@link Follower} to follow the ampltiude\n * of the incoming signal and compares it to the {@link threshold} value using {@link GreaterThan}.\n *\n * @example\n * const gate = new Tone.Gate(-30, 0.2).toDestination();\n * const mic = new Tone.UserMedia().connect(gate);\n * // the gate will only pass through the incoming\n * // signal when it's louder than -30db\n * @category Component\n */\nexport declare class Gate extends ToneAudioNode<GateOptions> {\n    readonly name: string;\n    readonly input: ToneAudioNode;\n    readonly output: ToneAudioNode;\n    /**\n     * Follow the incoming signal\n     */\n    private _follower;\n    /**\n     * Test if it's greater than the threshold\n     */\n    private _gt;\n    /**\n     * Gate the incoming signal when it does not exceed the threshold\n     */\n    private _gate;\n    /**\n     * @param threshold The threshold above which the gate will open.\n     * @param smoothing The follower's smoothing time\n     */\n    constructor(threshold?: Decibels, smoothing?: Time);\n    constructor(options?: Partial<GateOptions>);\n    static getDefaults(): GateOptions;\n    /**\n     * The threshold of the gate in decibels\n     */\n    get threshold(): Decibels;\n    set threshold(thresh: Decibels);\n    /**\n     * The attack/decay speed of the gate.\n     * @see {@link Follower.smoothing}\n     */\n    get smoothing(): Time;\n    set smoothing(smoothingTime: Time);\n    dispose(): this;\n}\n",
  "component/dynamics/Limiter.d.ts": "import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Decibels } from \"../../core/type/Units\";\nimport { Param } from \"../../core/context/Param\";\nexport interface LimiterOptions extends ToneAudioNodeOptions {\n    threshold: Decibels;\n}\n/**\n * Limiter will limit the loudness of an incoming signal.\n * Under the hood it's composed of a {@link Compressor} with a fast attack\n * and release and max compression ratio.\n *\n * @example\n * const limiter = new Tone.Limiter(-20).toDestination();\n * const oscillator = new Tone.Oscillator().connect(limiter);\n * oscillator.start();\n * @category Component\n */\nexport declare class Limiter extends ToneAudioNode<LimiterOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * The compressor which does the limiting\n     */\n    private _compressor;\n    readonly threshold: Param<\"decibels\">;\n    /**\n     * @param threshold The threshold above which the gain reduction is applied.\n     */\n    constructor(threshold?: Decibels);\n    constructor(options?: Partial<LimiterOptions>);\n    static getDefaults(): LimiterOptions;\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal.\n     */\n    get reduction(): Decibels;\n    dispose(): this;\n}\n",
  "component/dynamics/MidSideCompressor.d.ts": "import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Compressor, CompressorOptions } from \"./Compressor\";\nimport { RecursivePartial } from \"../../core/util/Interface\";\nexport interface MidSideCompressorOptions extends ToneAudioNodeOptions {\n    mid: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;\n    side: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;\n}\n/**\n * MidSideCompressor applies two different compressors to the {@link mid}\n * and {@link side} signal components of the input.\n * @see {@link MidSideSplit} and {@link MidSideMerge}.\n * @category Component\n */\nexport declare class MidSideCompressor extends ToneAudioNode<MidSideCompressorOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * Split the incoming signal into Mid/Side\n     */\n    private _midSideSplit;\n    /**\n     * Merge the compressed signal back into a single stream\n     */\n    private _midSideMerge;\n    /**\n     * The compression applied to the mid signal\n     */\n    readonly mid: Compressor;\n    /**\n     * The compression applied to the side signal\n     */\n    readonly side: Compressor;\n    constructor(options?: RecursivePartial<MidSideCompressorOptions>);\n    static getDefaults(): MidSideCompressorOptions;\n    dispose(): this;\n}\n",
  "component/dynamics/MultibandCompressor.d.ts": "import { InputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Compressor, CompressorOptions } from \"./Compressor\";\nimport { RecursivePartial } from \"../../core/util/Interface\";\nimport { Frequency } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nexport interface MultibandCompressorOptions extends ToneAudioNodeOptions {\n    mid: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;\n    low: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;\n    high: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;\n    lowFrequency: Frequency;\n    highFrequency: Frequency;\n}\n/**\n * A compressor with separate controls over low/mid/high dynamics.\n * @see {@link Compressor} and {@link MultibandSplit}\n *\n * @example\n * const multiband = new Tone.MultibandCompressor({\n * \tlowFrequency: 200,\n * \thighFrequency: 1300,\n * \tlow: {\n * \t\tthreshold: -12\n * \t}\n * });\n * @category Component\n */\nexport declare class MultibandCompressor extends ToneAudioNode<MultibandCompressorOptions> {\n    readonly name: string;\n    readonly input: InputNode;\n    readonly output: ToneAudioNode;\n    /**\n     * Split the incoming signal into high/mid/low\n     */\n    private _splitter;\n    /**\n     * low/mid crossover frequency.\n     */\n    readonly lowFrequency: Signal<\"frequency\">;\n    /**\n     * mid/high crossover frequency.\n     */\n    readonly highFrequency: Signal<\"frequency\">;\n    /**\n     * The compressor applied to the low frequencies\n     */\n    readonly low: Compressor;\n    /**\n     * The compressor applied to the mid frequencies\n     */\n    readonly mid: Compressor;\n    /**\n     * The compressor applied to the high frequencies\n     */\n    readonly high: Compressor;\n    constructor(options?: RecursivePartial<MultibandCompressorOptions>);\n    static getDefaults(): MultibandCompressorOptions;\n    dispose(): this;\n}\n",
  "component/envelope/AmplitudeEnvelope.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { NormalRange, Time } from \"../../core/type/Units\";\nimport { Envelope, EnvelopeOptions } from \"./Envelope\";\n/**\n * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts\n * an audio signal as the input and will apply the envelope to the amplitude\n * of the signal.\n * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst ampEnv = new Tone.AmplitudeEnvelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 1.0,\n * \t\trelease: 0.8\n * \t}).toDestination();\n * \t// create an oscillator and connect it\n * \tconst osc = new Tone.Oscillator().connect(ampEnv).start();\n * \t// trigger the envelopes attack and release \"8t\" apart\n * \tampEnv.triggerAttackRelease(\"8t\");\n * }, 1.5, 1);\n * @category Component\n */\nexport declare class AmplitudeEnvelope extends Envelope {\n    readonly name: string;\n    private _gainNode;\n    output: Gain;\n    input: Gain;\n    /**\n     * @param attack The amount of time it takes for the envelope to go from 0 to it's maximum value.\n     * @param decay\tThe period of time after the attack that it takes for the envelope\n     *                      \tto fall to the sustain value. Value must be greater than 0.\n     * @param sustain\tThe percent of the maximum value that the envelope rests at until\n     *                               \tthe release is triggered.\n     * @param release\tThe amount of time after the release is triggered it takes to reach 0.\n     *                        \tValue must be greater than 0.\n     */\n    constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);\n    constructor(options?: Partial<EnvelopeOptions>);\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\n",
  "component/envelope/Envelope.d.ts": "import { InputNode, OutputNode } from \"../../core/context/ToneAudioNode\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { NormalRange, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\ntype BasicEnvelopeCurve = \"linear\" | \"exponential\";\nexport type EnvelopeCurve = EnvelopeCurveName | number[];\nexport interface EnvelopeOptions extends ToneAudioNodeOptions {\n    attack: Time;\n    decay: Time;\n    sustain: NormalRange;\n    release: Time;\n    attackCurve: EnvelopeCurve;\n    releaseCurve: EnvelopeCurve;\n    decayCurve: BasicEnvelopeCurve;\n}\n/**\n * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n * envelope generator. Envelope outputs a signal which\n * can be connected to an AudioParam or Tone.Signal.\n * ```\n *           /\\\n *          /  \\\n *         /    \\\n *        /      \\\n *       /        \\___________\n *      /                     \\\n *     /                       \\\n *    /                         \\\n *   /                           \\\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst env = new Tone.Envelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 0.5,\n * \t\trelease: 0.8,\n * \t}).toDestination();\n * \tenv.triggerAttackRelease(0.5);\n * }, 1.5, 1);\n * @category Component\n */\nexport declare class Envelope extends ToneAudioNode<EnvelopeOptions> {\n    readonly name: string;\n    /**\n     * When triggerAttack is called, the attack time is the amount of\n     * time it takes for the envelope to reach it's maximum value.\n     * ```\n     *           /\\\n     *          /X \\\n     *         /XX  \\\n     *        /XXX   \\\n     *       /XXXX    \\___________\n     *      /XXXXX                \\\n     *     /XXXXXX                 \\\n     *    /XXXXXXX                  \\\n     *   /XXXXXXXX                   \\\n     * ```\n     * @min 0\n     * @max 2\n     */\n    attack: Time;\n    /**\n     * After the attack portion of the envelope, the value will fall\n     * over the duration of the decay time to it's sustain value.\n     * ```\n     *           /\\\n     *          / X\\\n     *         /  XX\\\n     *        /   XXX\\\n     *       /    XXXX\\___________\n     *      /     XXXXX           \\\n     *     /      XXXXX            \\\n     *    /       XXXXX             \\\n     *   /        XXXXX              \\\n     * ```\n     * @min 0\n     * @max 2\n     */\n    decay: Time;\n    /**\n     * The sustain value is the value\n     * which the envelope rests at after triggerAttack is\n     * called, but before triggerRelease is invoked.\n     * ```\n     *           /\\\n     *          /  \\\n     *         /    \\\n     *        /      \\\n     *       /        \\___________\n     *      /          XXXXXXXXXXX\\\n     *     /           XXXXXXXXXXX \\\n     *    /            XXXXXXXXXXX  \\\n     *   /             XXXXXXXXXXX   \\\n     * ```\n     */\n    sustain: NormalRange;\n    /**\n     * After triggerRelease is called, the envelope's\n     * value will fall to it's miminum value over the\n     * duration of the release time.\n     * ```\n     *           /\\\n     *          /  \\\n     *         /    \\\n     *        /      \\\n     *       /        \\___________\n     *      /                    X\\\n     *     /                     XX\\\n     *    /                      XXX\\\n     *   /                       XXXX\\\n     * ```\n     * @min 0\n     * @max 5\n     */\n    release: Time;\n    /**\n     * The automation curve type for the attack\n     */\n    private _attackCurve;\n    /**\n     * The automation curve type for the decay\n     */\n    private _decayCurve;\n    /**\n     * The automation curve type for the release\n     */\n    private _releaseCurve;\n    /**\n     * the signal which is output.\n     */\n    protected _sig: Signal<\"normalRange\">;\n    /**\n     * The output signal of the envelope\n     */\n    output: OutputNode;\n    /**\n     * Envelope has no input\n     */\n    input: InputNode | undefined;\n    /**\n     * @param attack The amount of time it takes for the envelope to go from\n     *                        0 to it's maximum value.\n     * @param decay\tThe period of time after the attack that it takes for the envelope\n     *                      \tto fall to the sustain value. Value must be greater than 0.\n     * @param sustain\tThe percent of the maximum value that the envelope rests at until\n     *                               \tthe release is triggered.\n     * @param release\tThe amount of time after the release is triggered it takes to reach 0.\n     *                        \tValue must be greater than 0.\n     */\n    constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);\n    constructor(options?: Partial<EnvelopeOptions>);\n    static getDefaults(): EnvelopeOptions;\n    /**\n     * Read the current value of the envelope. Useful for\n     * synchronizing visual output to the envelope.\n     */\n    get value(): NormalRange;\n    /**\n     * Get the curve\n     * @param  curve\n     * @param  direction  In/Out\n     * @return The curve name\n     */\n    private _getCurve;\n    /**\n     * Assign a the curve to the given name using the direction\n     * @param  name\n     * @param  direction In/Out\n     * @param  curve\n     */\n    private _setCurve;\n    /**\n     * The shape of the attack.\n     * Can be any of these strings:\n     * * \"linear\"\n     * * \"exponential\"\n     * * \"sine\"\n     * * \"cosine\"\n     * * \"bounce\"\n     * * \"ripple\"\n     * * \"step\"\n     *\n     * Can also be an array which describes the curve. Values\n     * in the array are evenly subdivided and linearly\n     * interpolated over the duration of the attack.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope(0.4).toDestination();\n     * \tenv.attackCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get attackCurve(): EnvelopeCurve;\n    set attackCurve(curve: EnvelopeCurve);\n    /**\n     * The shape of the release. See the attack curve types.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\trelease: 0.8\n     * \t}).toDestination();\n     * \tenv.triggerAttack();\n     * \t// release curve could also be defined by an array\n     * \tenv.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];\n     * \tenv.triggerRelease(0.2);\n     * }, 1, 1);\n     */\n    get releaseCurve(): EnvelopeCurve;\n    set releaseCurve(curve: EnvelopeCurve);\n    /**\n     * The shape of the decay either \"linear\" or \"exponential\"\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\tsustain: 0.1,\n     * \t\tdecay: 0.5\n     * \t}).toDestination();\n     * \tenv.decayCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get decayCurve(): EnvelopeCurve;\n    set decayCurve(curve: EnvelopeCurve);\n    /**\n     * Trigger the attack/decay portion of the ADSR envelope.\n     * @param  time When the attack should start.\n     * @param velocity The velocity of the envelope scales the vales.\n     *                             number between 0-1\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the attack 0.5 seconds from now with a velocity of 0.2\n     * env.triggerAttack(\"+0.5\", 0.2);\n     */\n    triggerAttack(time?: Time, velocity?: NormalRange): this;\n    /**\n     * Triggers the release of the envelope.\n     * @param  time When the release portion of the envelope should start.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator({\n     * \ttype: \"sawtooth\"\n     * }).connect(env).start();\n     * env.triggerAttack();\n     * // trigger the release half a second after the attack\n     * env.triggerRelease(\"+0.5\");\n     */\n    triggerRelease(time?: Time): this;\n    /**\n     * Get the scheduled value at the given time. This will\n     * return the unconverted (raw) value.\n     * @example\n     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);\n     * env.triggerAttackRelease(2);\n     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);\n     */\n    getValueAtTime(time: Time): NormalRange;\n    /**\n     * triggerAttackRelease is shorthand for triggerAttack, then waiting\n     * some duration, then triggerRelease.\n     * @param duration The duration of the sustain.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity of the envelope.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the release 0.5 seconds after the attack\n     * env.triggerAttackRelease(0.5);\n     */\n    triggerAttackRelease(duration: Time, time?: Time, velocity?: NormalRange): this;\n    /**\n     * Cancels all scheduled envelope changes after the given time.\n     */\n    cancel(after?: Time): this;\n    /**\n     * Connect the envelope to a destination node.\n     */\n    connect(destination: InputNode, outputNumber?: number, inputNumber?: number): this;\n    /**\n     * Render the envelope curve to an array of the given length.\n     * Good for visualizing the envelope curve. Rescales the duration of the\n     * envelope to fit the length.\n     */\n    asArray(length?: number): Promise<Float32Array>;\n    dispose(): this;\n}\ninterface EnvelopeCurveObject {\n    In: number[];\n    Out: number[];\n}\ninterface EnvelopeCurveMap {\n    linear: \"linear\";\n    exponential: \"exponential\";\n    bounce: EnvelopeCurveObject;\n    cosine: EnvelopeCurveObject;\n    sine: EnvelopeCurveObject;\n    ripple: EnvelopeCurveObject;\n    step: EnvelopeCurveObject;\n}\ntype EnvelopeCurveName = keyof EnvelopeCurveMap;\nexport {};\n",
  "component/envelope/FrequencyEnvelope.d.ts": "import { Frequency, NormalRange, Time } from \"../../core/type/Units\";\nimport { Envelope, EnvelopeOptions } from \"./Envelope\";\nexport interface FrequencyEnvelopeOptions extends EnvelopeOptions {\n    baseFrequency: Frequency;\n    octaves: number;\n    exponent: number;\n}\n/**\n * FrequencyEnvelope is an {@link Envelope} which ramps between {@link baseFrequency}\n * and {@link octaves}. It can also have an optional {@link exponent} to adjust the curve\n * which it ramps.\n * @example\n * const oscillator = new Tone.Oscillator().toDestination().start();\n * const freqEnv = new Tone.FrequencyEnvelope({\n * \tattack: 0.2,\n * \tbaseFrequency: \"C2\",\n * \toctaves: 4\n * });\n * freqEnv.connect(oscillator.frequency);\n * freqEnv.triggerAttack();\n * @category Component\n */\nexport declare class FrequencyEnvelope extends Envelope {\n    readonly name: string;\n    /**\n     * Private reference to the base frequency as a number\n     */\n    private _baseFrequency;\n    /**\n     * The number of octaves\n     */\n    private _octaves;\n    /**\n     * Internal scaler from 0-1 to the final output range\n     */\n    private _scale;\n    /**\n     * Apply a power curve to the output\n     */\n    private _exponent;\n    /**\n     * @param attack\tthe attack time in seconds\n     * @param decay\t\tthe decay time in seconds\n     * @param sustain \ta percentage (0-1) of the full amplitude\n     * @param release\tthe release time in seconds\n     */\n    constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);\n    constructor(options?: Partial<FrequencyEnvelopeOptions>);\n    static getDefaults(): FrequencyEnvelopeOptions;\n    /**\n     * The envelope's minimum output value. This is the value which it\n     * starts at.\n     */\n    get baseFrequency(): Frequency;\n    set baseFrequency(min: Frequency);\n    /**\n     * The number of octaves above the baseFrequency that the\n     * envelope will scale to.\n     */\n    get octaves(): number;\n    set octaves(octaves: number);\n    /**\n     * The envelope's exponent value.\n     */\n    get exponent(): number;\n    set exponent(exponent: number);\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\n",
  "component/filter/BiquadFilter.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Cents, Frequency, GainFactor } from \"../../core/type/Units\";\nimport { Param } from \"../../core/context/Param\";\nexport interface BiquadFilterOptions extends ToneAudioNodeOptions {\n    frequency: Frequency;\n    detune: Cents;\n    Q: number;\n    type: BiquadFilterType;\n    gain: GainFactor;\n}\n/**\n * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).\n * BiquadFilter is similar to {@link Filter} but doesn't have the option to set the \"rolloff\" value.\n * @category Component\n */\nexport declare class BiquadFilter extends ToneAudioNode<BiquadFilterOptions> {\n    readonly name: string;\n    readonly input: BiquadFilterNode;\n    readonly output: BiquadFilterNode;\n    /**\n     * The frequency of the filter\n     */\n    readonly frequency: Param<\"frequency\">;\n    /**\n     * A detune value, in cents, for the frequency.\n     */\n    readonly detune: Param<\"cents\">;\n    /**\n     * The Q factor of the filter.\n     * For lowpass and highpass filters the Q value is interpreted to be in dB.\n     * For these filters the nominal range is [,] where  is the largest value for which 10/20 does not overflow. This is approximately 770.63678.\n     * For the bandpass, notch, allpass, and peaking filters, this value is a linear value.\n     * The value is related to the bandwidth of the filter and hence should be a positive value. The nominal range is\n     * [0,3.402823538], the upper limit being the most-positive-single-float.\n     * This is not used for the lowshelf and highshelf filters.\n     */\n    readonly Q: Param<\"number\">;\n    /**\n     * The gain of the filter. Its value is in dB units. The gain is only used for lowshelf, highshelf, and peaking filters.\n     */\n    readonly gain: Param<\"decibels\">;\n    private readonly _filter;\n    /**\n     * @param frequency The cutoff frequency of the filter.\n     * @param type The type of filter.\n     */\n    constructor(frequency?: Frequency, type?: BiquadFilterType);\n    constructor(options?: Partial<BiquadFilterOptions>);\n    static getDefaults(): BiquadFilterOptions;\n    /**\n     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the\n     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)\n     */\n    get type(): BiquadFilterType;\n    set type(type: BiquadFilterType);\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len?: number): Float32Array;\n    dispose(): this;\n}\n",
  "component/filter/Convolver.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { Gain } from \"../../core/context/Gain\";\nexport interface ConvolverOptions extends ToneAudioNodeOptions {\n    onload: () => void;\n    normalize: boolean;\n    url?: string | AudioBuffer | ToneAudioBuffer;\n}\n/**\n * Convolver is a wrapper around the Native Web Audio\n * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).\n *\n * @example\n * // initializing the convolver with an impulse response\n * const convolver = new Tone.Convolver(\"./path/to/ir.wav\").toDestination();\n * @category Component\n */\nexport declare class Convolver extends ToneAudioNode<ConvolverOptions> {\n    readonly name: string;\n    /**\n     * The native ConvolverNode\n     */\n    private _convolver;\n    /**\n     * The Buffer belonging to the convolver\n     */\n    private _buffer;\n    readonly input: Gain;\n    readonly output: Gain;\n    /**\n     * @param url The URL of the impulse response or the ToneAudioBuffer containing the impulse response.\n     * @param onload The callback to invoke when the url is loaded.\n     */\n    constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);\n    constructor(options?: Partial<ConvolverOptions>);\n    static getDefaults(): ConvolverOptions;\n    /**\n     * Load an impulse response url as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     */\n    load(url: string): Promise<void>;\n    /**\n     * The convolver's buffer\n     */\n    get buffer(): ToneAudioBuffer | null;\n    set buffer(buffer: ToneAudioBuffer | null);\n    /**\n     * The normalize property of the ConvolverNode interface is a boolean that\n     * controls whether the impulse response from the buffer will be scaled by\n     * an equal-power normalization when the buffer attribute is set, or not.\n     */\n    get normalize(): boolean;\n    set normalize(norm: boolean);\n    dispose(): this;\n}\n",
  "component/filter/EQ3.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Decibels, Frequency } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { MultibandSplit } from \"../channel/MultibandSplit\";\ninterface EQ3Options extends ToneAudioNodeOptions {\n    low: Decibels;\n    mid: Decibels;\n    high: Decibels;\n    lowFrequency: Frequency;\n    highFrequency: Frequency;\n}\n/**\n * EQ3 provides 3 equalizer bins: Low/Mid/High.\n * @category Component\n */\nexport declare class EQ3 extends ToneAudioNode<EQ3Options> {\n    readonly name: string;\n    /**\n     * the input\n     */\n    readonly input: MultibandSplit;\n    /**\n     * the output\n     */\n    readonly output: Gain<\"gain\">;\n    /**\n     * Splits the input into three outputs\n     */\n    private _multibandSplit;\n    /**\n     * The gain for the lower signals\n     */\n    private _lowGain;\n    /**\n     * The gain for the mid signals\n     */\n    private _midGain;\n    /**\n     * The gain for the high signals\n     */\n    private _highGain;\n    /**\n     * The gain in decibels of the low part\n     */\n    readonly low: Param<\"decibels\">;\n    /**\n     * The gain in decibels of the mid part\n     */\n    readonly mid: Param<\"decibels\">;\n    /**\n     * The gain in decibels of the high part\n     */\n    readonly high: Param<\"decibels\">;\n    /**\n     * The Q value for all of the filters.\n     */\n    readonly Q: Signal<\"positive\">;\n    /**\n     * The low/mid crossover frequency.\n     */\n    readonly lowFrequency: Signal<\"frequency\">;\n    /**\n     * The mid/high crossover frequency.\n     */\n    readonly highFrequency: Signal<\"frequency\">;\n    protected _internalChannels: ToneAudioNode[];\n    constructor(lowLevel?: Decibels, midLevel?: Decibels, highLevel?: Decibels);\n    constructor(options: Partial<EQ3Options>);\n    static getDefaults(): EQ3Options;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "component/filter/FeedbackCombFilter.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { Param } from \"../../core/context/Param\";\nimport { ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { NormalRange, Time } from \"../../core/type/Units\";\nimport { RecursivePartial } from \"../../core/util/Interface\";\nimport { ToneAudioWorklet } from \"../../core/worklet/ToneAudioWorklet\";\nexport interface FeedbackCombFilterOptions extends ToneAudioNodeOptions {\n    delayTime: Time;\n    resonance: NormalRange;\n}\n/**\n * Comb filters are basic building blocks for physical modeling. Read more\n * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).\n *\n * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the\n * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the\n * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.\n * @category Component\n */\nexport declare class FeedbackCombFilter extends ToneAudioWorklet<FeedbackCombFilterOptions> {\n    readonly name = \"FeedbackCombFilter\";\n    /**\n     * The amount of delay of the comb filter.\n     */\n    readonly delayTime: Param<\"time\">;\n    /**\n     * The amount of feedback of the delayed signal.\n     */\n    readonly resonance: Param<\"normalRange\">;\n    readonly input: Gain;\n    readonly output: Gain;\n    /**\n     * @param delayTime The delay time of the filter.\n     * @param resonance The amount of feedback the filter has.\n     */\n    constructor(delayTime?: Time, resonance?: NormalRange);\n    constructor(options?: RecursivePartial<FeedbackCombFilterOptions>);\n    protected _audioWorkletName(): string;\n    /**\n     * The default parameters\n     */\n    static getDefaults(): FeedbackCombFilterOptions;\n    onReady(node: AudioWorkletNode): void;\n    dispose(): this;\n}\n",
  "component/filter/FeedbackCombFilter.worklet.d.ts": "import  \"../../core/worklet/SingleIOProcessor.worklet\";\nimport  \"../../core/worklet/DelayLine.worklet\";\nexport declare const workletName = \"feedback-comb-filter\";\n",
  "component/filter/Filter.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Frequency } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { BiquadFilterOptions } from \"./BiquadFilter\";\nexport type FilterRollOff = -12 | -24 | -48 | -96;\nexport type FilterOptions = BiquadFilterOptions & {\n    rolloff: FilterRollOff;\n};\n/**\n * Tone.Filter is a filter which allows for all of the same native methods\n * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n * Tone.Filter has the added ability to set the filter rolloff at -12\n * (default), -24 and -48.\n * @example\n * const filter = new Tone.Filter(1500, \"highpass\").toDestination();\n * filter.frequency.rampTo(20000, 10);\n * const noise = new Tone.Noise().connect(filter).start();\n * @category Component\n */\nexport declare class Filter extends ToneAudioNode<FilterOptions> {\n    readonly name: string;\n    readonly input: Gain<\"gain\">;\n    readonly output: Gain<\"gain\">;\n    private _filters;\n    /**\n     * the rolloff value of the filter\n     */\n    private _rolloff;\n    private _type;\n    /**\n     * The Q or Quality of the filter\n     */\n    readonly Q: Signal<\"positive\">;\n    /**\n     * The cutoff frequency of the filter.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune parameter\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The gain of the filter, only used in certain filter types\n     */\n    readonly gain: Signal<\"decibels\">;\n    /**\n     * @param frequency The cutoff frequency of the filter.\n     * @param type The type of filter.\n     * @param rolloff The drop in decibels per octave after the cutoff frequency\n     */\n    constructor(frequency?: Frequency, type?: BiquadFilterType, rolloff?: FilterRollOff);\n    constructor(options?: Partial<FilterOptions>);\n    static getDefaults(): FilterOptions;\n    /**\n     * The type of the filter. Types: \"lowpass\", \"highpass\",\n     * \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", or \"peaking\".\n     */\n    get type(): BiquadFilterType;\n    set type(type: BiquadFilterType);\n    /**\n     * The rolloff of the filter which is the drop in db\n     * per octave. Implemented internally by cascading filters.\n     * Only accepts the values -12, -24, -48 and -96.\n     */\n    get rolloff(): FilterRollOff;\n    set rolloff(rolloff: FilterRollOff);\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len?: number): Float32Array;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "component/filter/LowpassCombFilter.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Frequency, NormalRange, Time } from \"../../core/type/Units\";\nimport { RecursivePartial } from \"../../core/util/Interface\";\ninterface LowpassCombFilterOptions extends ToneAudioNodeOptions {\n    delayTime: Time;\n    resonance: NormalRange;\n    dampening: Frequency;\n}\n/**\n * A lowpass feedback comb filter. It is similar to\n * {@link FeedbackCombFilter}, but includes a lowpass filter.\n * @category Component\n */\nexport declare class LowpassCombFilter extends ToneAudioNode<LowpassCombFilterOptions> {\n    readonly name = \"LowpassCombFilter\";\n    /**\n     * The delay node\n     */\n    private _combFilter;\n    /**\n     * The lowpass filter\n     */\n    private _lowpass;\n    /**\n     * The delayTime of the comb filter.\n     */\n    readonly delayTime: Param<\"time\">;\n    /**\n     * The amount of feedback of the delayed signal.\n     */\n    readonly resonance: Param<\"normalRange\">;\n    readonly input: InputNode;\n    readonly output: OutputNode;\n    /**\n     * @param delayTime The delay time of the comb filter\n     * @param resonance The resonance (feedback) of the comb filter\n     * @param dampening The cutoff of the lowpass filter dampens the signal as it is fedback.\n     */\n    constructor(delayTime?: Time, resonance?: NormalRange, dampening?: Frequency);\n    constructor(options?: RecursivePartial<LowpassCombFilterOptions>);\n    static getDefaults(): LowpassCombFilterOptions;\n    /**\n     * The dampening control of the feedback\n     */\n    get dampening(): Frequency;\n    set dampening(fq: Frequency);\n    dispose(): this;\n}\nexport {};\n",
  "component/filter/OnePoleFilter.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\nimport { Frequency } from \"../../core/type/Units\";\nimport { Gain } from \"../../core/context/Gain\";\nexport type OnePoleFilterType = \"highpass\" | \"lowpass\";\nexport interface OnePoleFilterOptions extends ToneAudioNodeOptions {\n    frequency: Frequency;\n    type: OnePoleFilterType;\n}\n/**\n * A one pole filter with 6db-per-octave rolloff. Either \"highpass\" or \"lowpass\".\n * Note that changing the type or frequency may result in a discontinuity which\n * can sound like a click or pop.\n * References:\n * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/\n * * http://www.dspguide.com/ch19/2.htm\n * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts\n * @category Component\n */\nexport declare class OnePoleFilter extends ToneAudioNode<OnePoleFilterOptions> {\n    readonly name: string;\n    /**\n     * Hold the current frequency\n     */\n    private _frequency;\n    /**\n     * the current one pole type\n     */\n    private _type;\n    /**\n     * the current one pole filter\n     */\n    private _filter;\n    readonly input: Gain;\n    readonly output: Gain;\n    /**\n     * @param frequency The frequency\n     * @param type The  filter type, either \"lowpass\" or \"highpass\"\n     */\n    constructor(frequency?: Frequency, type?: OnePoleFilterType);\n    constructor(options?: Partial<OnePoleFilterOptions>);\n    static getDefaults(): OnePoleFilterOptions;\n    /**\n     * Create a filter and dispose the old one\n     */\n    private _createFilter;\n    /**\n     * The frequency value.\n     */\n    get frequency(): Frequency;\n    set frequency(fq: Frequency);\n    /**\n     * The OnePole Filter type, either \"highpass\" or \"lowpass\"\n     */\n    get type(): OnePoleFilterType;\n    set type(t: OnePoleFilterType);\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len?: number): Float32Array;\n    dispose(): this;\n}\n",
  "component/filter/PhaseShiftAllpass.d.ts": "import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../../core/context/ToneAudioNode\";\n/**\n * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform\n * using two Allpass filter banks whose outputs have a phase difference of 90.\n * Here the `offset90` phase is offset by +90 in relation to `output`.\n * Coefficients and structure was developed by Olli Niemitalo.\n * For more details see: http://yehar.com/blog/?p=368\n * @category Component\n */\nexport declare class PhaseShiftAllpass extends ToneAudioNode<ToneAudioNodeOptions> {\n    readonly name: string;\n    readonly input: Gain<\"gain\">;\n    /**\n     * The Allpass filter in the first bank\n     */\n    private _bank0;\n    /**\n     * The Allpass filter in the seconds bank\n     */\n    private _bank1;\n    /**\n     * A IIR filter implementing a delay by one sample used by the first bank\n     */\n    private _oneSampleDelay;\n    /**\n     * The phase shifted output\n     */\n    readonly output: Gain<\"gain\">;\n    /**\n     * The PhaseShifted allpass output\n     */\n    readonly offset90: Gain<\"gain\">;\n    constructor(options?: Partial<ToneAudioNodeOptions>);\n    /**\n     * Create all of the IIR filters from an array of values using the coefficient calculation.\n     */\n    private _createAllPassFilterBank;\n    dispose(): this;\n}\n",
  "component/index.d.ts": "export * from \"./analysis/Analyser\";\nexport * from \"./analysis/Meter\";\nexport * from \"./analysis/FFT\";\nexport * from \"./analysis/DCMeter\";\nexport * from \"./analysis/Waveform\";\nexport * from \"./analysis/Follower\";\nexport * from \"./channel/Channel\";\nexport * from \"./channel/CrossFade\";\nexport * from \"./channel/Merge\";\nexport * from \"./channel/MidSideMerge\";\nexport * from \"./channel/MidSideSplit\";\nexport * from \"./channel/Mono\";\nexport * from \"./channel/MultibandSplit\";\nexport * from \"./channel/Panner\";\nexport * from \"./channel/Panner3D\";\nexport * from \"./channel/PanVol\";\nexport * from \"./channel/Recorder\";\nexport * from \"./channel/Solo\";\nexport * from \"./channel/Split\";\nexport * from \"./channel/Volume\";\nexport * from \"./dynamics/Compressor\";\nexport * from \"./dynamics/Gate\";\nexport * from \"./dynamics/Limiter\";\nexport * from \"./dynamics/MidSideCompressor\";\nexport * from \"./dynamics/MultibandCompressor\";\nexport * from \"./envelope/AmplitudeEnvelope\";\nexport * from \"./envelope/Envelope\";\nexport * from \"./envelope/FrequencyEnvelope\";\nexport * from \"./filter/EQ3\";\nexport * from \"./filter/Filter\";\nexport * from \"./filter/OnePoleFilter\";\nexport * from \"./filter/FeedbackCombFilter\";\nexport * from \"./filter/LowpassCombFilter\";\nexport * from \"./filter/Convolver\";\nexport * from \"./filter/BiquadFilter\";\n",
  "core/Global.d.ts": "import { AnyAudioContext } from \"./context/AudioContext\";\nimport { BaseContext } from \"./context/BaseContext\";\n/**\n * Returns the default system-wide {@link Context}\n * @category Core\n */\nexport declare function getContext(): BaseContext;\n/**\n * Set the default audio context\n * @param context\n * @param disposeOld Pass `true` if you don't need the old context to dispose it.\n * @category Core\n */\nexport declare function setContext(context: BaseContext | AnyAudioContext, disposeOld?: boolean): void;\n/**\n * Most browsers will not play _any_ audio until a user\n * clicks something (like a play button). Invoke this method\n * on a click or keypress event handler to start the audio context.\n * More about the Autoplay policy\n * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)\n * @example\n * document.querySelector(\"button\").addEventListener(\"click\", async () => {\n * \tawait Tone.start();\n * \tconsole.log(\"context started\");\n * });\n * @category Core\n */\nexport declare function start(): Promise<void>;\n",
  "core/Tone.d.ts": "export interface BaseToneOptions {\n}\n/**\n * Tone is the base class of all other classes.\n *\n * @category Core\n * @constructor\n */\nexport declare abstract class Tone {\n    /**\n     * The version number semver\n     */\n    static version: string;\n    /**\n     * The name of the class\n     */\n    protected abstract name: string;\n    /**\n     * Returns all of the default options belonging to the class.\n     */\n    static getDefaults(): BaseToneOptions;\n    /**\n     * Set this debug flag to log all events that happen in this class.\n     */\n    debug: boolean;\n    /**\n     * Prints the outputs to the console log for debugging purposes.\n     * Prints the contents only if either the object has a property\n     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS\n     * is set to the name of the class.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * // prints all logs originating from this oscillator\n     * osc.debug = true;\n     * // calls to start/stop will print in the console\n     * osc.start();\n     */\n    protected log(...args: any[]): void;\n    /**\n     * Indicates if the instance was disposed\n     */\n    private _wasDisposed;\n    /**\n     * disconnect and dispose.\n     */\n    dispose(): this;\n    /**\n     * Indicates if the instance was disposed. 'Disposing' an\n     * instance means that all of the Web Audio nodes that were\n     * created for the instance are disconnected and freed for garbage collection.\n     */\n    get disposed(): boolean;\n    /**\n     * Convert the class to a string\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.toString());\n     */\n    toString(): string;\n}\n",
  "core/clock/Clock.d.ts": "import { ToneWithContext, ToneWithContextOptions } from \"../context/ToneWithContext\";\nimport { Frequency, Hertz, Seconds, Ticks, Time } from \"../type/Units\";\nimport { Emitter } from \"../util/Emitter\";\nimport { PlaybackState } from \"../util/StateTimeline\";\nimport { TickSignal } from \"./TickSignal\";\ntype ClockCallback = (time: Seconds, ticks?: Ticks) => void;\ninterface ClockOptions extends ToneWithContextOptions {\n    frequency: Hertz;\n    callback: ClockCallback;\n    units: \"hertz\" | \"bpm\";\n}\ntype ClockEvent = \"start\" | \"stop\" | \"pause\";\n/**\n * A sample accurate clock which provides a callback at the given rate.\n * While the callback is not sample-accurate (it is still susceptible to\n * loose JS timing), the time passed in as the argument to the callback\n * is precise. For most applications, it is better to use Tone.Transport\n * instead of the Clock by itself since you can synchronize multiple callbacks.\n * @example\n * // the callback will be invoked approximately once a second\n * // and will print the time exactly once a second apart.\n * const clock = new Tone.Clock(time => {\n * \tconsole.log(time);\n * }, 1);\n * clock.start();\n * @category Core\n */\nexport declare class Clock<TypeName extends \"bpm\" | \"hertz\" = \"hertz\"> extends ToneWithContext<ClockOptions> implements Emitter<ClockEvent> {\n    readonly name: string;\n    /**\n     * The callback function to invoke at the scheduled tick.\n     */\n    callback: ClockCallback;\n    /**\n     * The tick counter\n     */\n    private _tickSource;\n    /**\n     * The last time the loop callback was invoked\n     */\n    private _lastUpdate;\n    /**\n     * Keep track of the playback state\n     */\n    private _state;\n    /**\n     * Context bound reference to the _loop method\n     * This is necessary to remove the event in the end.\n     */\n    private _boundLoop;\n    /**\n     * The rate the callback function should be invoked.\n     */\n    frequency: TickSignal<TypeName>;\n    /**\n     * @param callback The callback to be invoked with the time of the audio event\n     * @param frequency The rate of the callback\n     */\n    constructor(callback?: ClockCallback, frequency?: Frequency);\n    constructor(options: Partial<ClockOptions>);\n    static getDefaults(): ClockOptions;\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state(): PlaybackState;\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset  Where the tick counter starts counting from.\n     */\n    start(time?: Time, offset?: Ticks): this;\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     * @example\n     * const clock = new Tone.Clock(time => {\n     * \tconsole.log(time);\n     * }, 1);\n     * clock.start();\n     * // stop the clock after 10 seconds\n     * clock.stop(\"+10\");\n     */\n    stop(time?: Time): this;\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time?: Time): this;\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked.\n     */\n    get ticks(): Ticks;\n    set ticks(t: Ticks);\n    /**\n     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves\n     */\n    get seconds(): Seconds;\n    set seconds(s: Seconds);\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time: Time): Seconds;\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks: Ticks, time: Time): this;\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick: Ticks, before?: number): Seconds;\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time?: Time): Ticks;\n    /**\n     * Get the time of the next tick\n     * @param  offset The tick number.\n     */\n    nextTickTime(offset: Ticks, when: Time): Seconds;\n    /**\n     * The scheduling loop.\n     */\n    private _loop;\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     * @example\n     * const clock = new Tone.Clock();\n     * clock.start(\"+0.1\");\n     * clock.getStateAtTime(\"+0.1\"); // returns \"started\"\n     */\n    getStateAtTime(time: Time): PlaybackState;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n    on: (event: ClockEvent, callback: (...args: any[]) => void) => this;\n    once: (event: ClockEvent, callback: (...args: any[]) => void) => this;\n    off: (event: ClockEvent, callback?: ((...args: any[]) => void) | undefined) => this;\n    emit: (event: any, ...args: any[]) => this;\n}\nexport {};\n",
  "core/clock/TickParam.d.ts": "import { AutomationEvent, Param, ParamOptions } from \"../context/Param\";\nimport { Seconds, Ticks, Time, UnitMap, UnitName } from \"../type/Units\";\nimport { Timeline } from \"../util/Timeline\";\ntype TickAutomationEvent = AutomationEvent & {\n    ticks: number;\n};\ninterface TickParamOptions<TypeName extends UnitName> extends ParamOptions<TypeName> {\n    multiplier: number;\n}\n/**\n * A Param class just for computing ticks. Similar to the {@link Param} class,\n * but offers conversion to BPM values as well as ability to compute tick\n * duration and elapsed ticks\n */\nexport declare class TickParam<TypeName extends \"hertz\" | \"bpm\"> extends Param<TypeName> {\n    readonly name: string;\n    /**\n     * The timeline which tracks all of the automations.\n     */\n    protected _events: Timeline<TickAutomationEvent>;\n    /**\n     * The internal holder for the multiplier value\n     */\n    private _multiplier;\n    /**\n     * @param param The AudioParam to wrap\n     * @param units The unit name\n     * @param convert Whether or not to convert the value to the target units\n     */\n    /**\n     * @param value The initial value of the signal\n     */\n    constructor(value?: number);\n    constructor(options: Partial<TickParamOptions<TypeName>>);\n    static getDefaults(): TickParamOptions<any>;\n    setTargetAtTime(value: UnitMap[TypeName], time: Time, constant: number): this;\n    setValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  event The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    private _getTicksUntilEvent;\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  time The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    getTicksAtTime(time: Time): Ticks;\n    /**\n     * Return the elapsed time of the number of ticks from the given time\n     * @param ticks The number of ticks to calculate\n     * @param  time The time to get the next tick from\n     * @return The duration of the number of ticks from the given time in seconds\n     */\n    getDurationOfTicks(ticks: Ticks, time: Time): Seconds;\n    /**\n     * Given a tick, returns the time that tick occurs at.\n     * @return The time that the tick occurs.\n     */\n    getTimeOfTick(tick: Ticks): Seconds;\n    /**\n     * Convert some number of ticks their the duration in seconds accounting\n     * for any automation curves starting at the given time.\n     * @param  ticks The number of ticks to convert to seconds.\n     * @param  when  When along the automation timeline to convert the ticks.\n     * @return The duration in seconds of the ticks.\n     */\n    ticksToTime(ticks: Ticks, when: Time): Seconds;\n    /**\n     * The inverse of {@link ticksToTime}. Convert a duration in\n     * seconds to the corresponding number of ticks accounting for any\n     * automation curves starting at the given time.\n     * @param  duration The time interval to convert to ticks.\n     * @param  when When along the automation timeline to convert the ticks.\n     * @return The duration in ticks.\n     */\n    timeToTicks(duration: Time, when: Time): Ticks;\n    /**\n     * Convert from the type when the unit value is BPM\n     */\n    protected _fromType(val: UnitMap[TypeName]): number;\n    /**\n     * Special case of type conversion where the units === \"bpm\"\n     */\n    protected _toType(val: number): UnitMap[TypeName];\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier(): number;\n    set multiplier(m: number);\n}\nexport {};\n",
  "core/clock/TickSignal.d.ts": "import { Signal, SignalOptions } from \"../../signal/Signal\";\nimport { InputNode } from \"../context/ToneAudioNode\";\nimport { Seconds, Ticks, Time, UnitMap, UnitName } from \"../type/Units\";\nimport { TickParam } from \"./TickParam\";\ninterface TickSignalOptions<TypeName extends UnitName> extends SignalOptions<TypeName> {\n    value: UnitMap[TypeName];\n    multiplier: number;\n}\n/**\n * TickSignal extends Tone.Signal, but adds the capability\n * to calculate the number of elapsed ticks. exponential and target curves\n * are approximated with multiple linear ramps.\n *\n * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,\n * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n * describing integrating timing functions for tempo calculations.\n */\nexport declare class TickSignal<TypeName extends \"hertz\" | \"bpm\"> extends Signal<TypeName> {\n    readonly name: string;\n    /**\n     * The param which controls the output signal value\n     */\n    protected _param: TickParam<TypeName>;\n    readonly input: InputNode;\n    /**\n     * @param value The initial value of the signal\n     */\n    constructor(value?: UnitMap[TypeName]);\n    constructor(options: Partial<TickSignalOptions<TypeName>>);\n    static getDefaults(): TickSignalOptions<any>;\n    ticksToTime(ticks: Ticks, when: Time): Seconds;\n    timeToTicks(duration: Time, when: Time): Ticks;\n    getTimeOfTick(tick: Ticks): Seconds;\n    getDurationOfTicks(ticks: Ticks, time: Time): Seconds;\n    getTicksAtTime(time: Time): Ticks;\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier(): number;\n    set multiplier(m: number);\n    dispose(): this;\n}\nexport {};\n",
  "core/clock/TickSource.d.ts": "import { ToneWithContext, ToneWithContextOptions } from \"../context/ToneWithContext\";\nimport { Seconds, Ticks, Time } from \"../type/Units\";\nimport { PlaybackState } from \"../util/StateTimeline\";\nimport { TickSignal } from \"./TickSignal\";\ninterface TickSourceOptions extends ToneWithContextOptions {\n    frequency: number;\n    units: \"bpm\" | \"hertz\";\n}\n/**\n * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.\n */\nexport declare class TickSource<TypeName extends \"bpm\" | \"hertz\"> extends ToneWithContext<TickSourceOptions> {\n    readonly name: string;\n    /**\n     * The frequency the callback function should be invoked.\n     */\n    readonly frequency: TickSignal<TypeName>;\n    /**\n     * The state timeline\n     */\n    private _state;\n    /**\n     * The offset values of the ticks\n     */\n    private _tickOffset;\n    /**\n     * Memoized values of getTicksAtTime at events with state other than \"started\"\n     */\n    private _ticksAtTime;\n    /**\n     * Memoized values of getSecondsAtTime at events with state other than \"started\"\n     */\n    private _secondsAtTime;\n    /**\n     * @param frequency The initial frequency that the signal ticks at\n     */\n    constructor(frequency?: number);\n    constructor(options?: Partial<TickSourceOptions>);\n    static getDefaults(): TickSourceOptions;\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state(): PlaybackState;\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset The number of ticks to start the source at\n     */\n    start(time: Time, offset?: Ticks): this;\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     */\n    stop(time: Time): this;\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time: Time): this;\n    /**\n     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.\n     * @param time When to clear the events after\n     */\n    cancel(time: Time): this;\n    /**\n     * Get the elapsed ticks at the given time\n     * @param  time  When to get the tick value\n     * @return The number of ticks\n     */\n    getTicksAtTime(time?: Time): Ticks;\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked. Returns -1 when stopped.\n     */\n    get ticks(): Ticks;\n    set ticks(t: Ticks);\n    /**\n     * The time since ticks=0 that the TickSource has been running. Accounts\n     * for tempo curves\n     */\n    get seconds(): Seconds;\n    set seconds(s: Seconds);\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time: Time): Seconds;\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks: Ticks, time: Time): this;\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     */\n    getStateAtTime(time: Time): PlaybackState;\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick: Ticks, before?: number): Seconds;\n    /**\n     * Invoke the callback event at all scheduled ticks between the\n     * start time and the end time\n     * @param  startTime  The beginning of the search range\n     * @param  endTime    The end of the search range\n     * @param  callback   The callback to invoke with each tick\n     */\n    forEachTickBetween(startTime: number, endTime: number, callback: (when: Seconds, ticks: Ticks) => void): this;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/clock/Ticker.d.ts": "import { Seconds } from \"../type/Units\";\nexport type TickerClockSource = \"worker\" | \"timeout\" | \"offline\";\n/**\n * A class which provides a reliable callback using either\n * a Web Worker, or if that isn't supported, falls back to setTimeout.\n */\nexport declare class Ticker {\n    /**\n     * Either \"worker\" or \"timeout\" or \"offline\"\n     */\n    private _type;\n    /**\n     * The update interval of the worker\n     */\n    private _updateInterval;\n    /**\n     * The lowest allowable interval, preferably calculated from context sampleRate\n     */\n    private _minimumUpdateInterval;\n    /**\n     * The callback to invoke at regular intervals\n     */\n    private _callback;\n    /**\n     * track the callback interval\n     */\n    private _timeout;\n    /**\n     * private reference to the worker\n     */\n    private _worker;\n    constructor(callback: () => void, type: TickerClockSource, updateInterval: Seconds, contextSampleRate?: number);\n    /**\n     * Generate a web worker\n     */\n    private _createWorker;\n    /**\n     * Create a timeout loop\n     */\n    private _createTimeout;\n    /**\n     * Create the clock source.\n     */\n    private _createClock;\n    /**\n     * Clean up the current clock source\n     */\n    private _disposeClock;\n    /**\n     * The rate in seconds the ticker will update\n     */\n    get updateInterval(): Seconds;\n    set updateInterval(interval: Seconds);\n    /**\n     * The type of the ticker, either a worker or a timeout\n     */\n    get type(): TickerClockSource;\n    set type(type: TickerClockSource);\n    /**\n     * Clean up\n     */\n    dispose(): void;\n}\n",
  "core/clock/Transport.d.ts": "import { TimeClass } from \"../../core/type/Time\";\nimport { PlaybackState } from \"../../core/util/StateTimeline\";\nimport { Signal } from \"../../signal/Signal\";\nimport { ToneWithContext, ToneWithContextOptions } from \"../context/ToneWithContext\";\nimport { TransportTimeClass } from \"../type/TransportTime\";\nimport { BarsBeatsSixteenths, BPM, NormalRange, Seconds, Subdivision, Ticks, Time, TimeSignature, TransportTime } from \"../type/Units\";\nimport { Emitter } from \"../util/Emitter\";\nimport { TickParam } from \"./TickParam\";\ninterface TransportOptions extends ToneWithContextOptions {\n    bpm: BPM;\n    swing: NormalRange;\n    swingSubdivision: Subdivision;\n    timeSignature: number;\n    loopStart: Time;\n    loopEnd: Time;\n    ppq: number;\n}\ntype TransportEventNames = \"start\" | \"stop\" | \"pause\" | \"loop\" | \"loopEnd\" | \"loopStart\" | \"ticks\";\ntype TransportCallback = (time: Seconds) => void;\n/**\n * Transport for timing musical events.\n * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n * Transport timing events pass in the exact time of the scheduled event\n * in the argument of the callback function. Pass that time value to the object\n * you're scheduling. <br><br>\n * A single transport is created for you when the library is initialized.\n * <br><br>\n * The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n * called with the time of that event as the argument.\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination();\n * // repeated event every 8th note\n * Tone.getTransport().scheduleRepeat((time) => {\n * \t// use the callback time to schedule events\n * \tosc.start(time).stop(time + 0.1);\n * }, \"8n\");\n * // transport must be started before it starts invoking events\n * Tone.getTransport().start();\n * @category Core\n */\nexport declare class TransportClass extends ToneWithContext<TransportOptions> implements Emitter<TransportEventNames> {\n    readonly name: string;\n    /**\n     * If the transport loops or not.\n     */\n    private _loop;\n    /**\n     * The loop start position in ticks\n     */\n    private _loopStart;\n    /**\n     * The loop end position in ticks\n     */\n    private _loopEnd;\n    /**\n     * Pulses per quarter is the number of ticks per quarter note.\n     */\n    private _ppq;\n    /**\n     * watches the main oscillator for timing ticks\n     * initially starts at 120bpm\n     */\n    private _clock;\n    /**\n     * The Beats Per Minute of the Transport.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * Tone.getTransport().bpm.value = 80;\n     * // start/stop the oscillator every quarter note\n     * Tone.getTransport().scheduleRepeat(time => {\n     * \tosc.start(time).stop(time + 0.1);\n     * }, \"4n\");\n     * Tone.getTransport().start();\n     * // ramp the bpm to 120 over 10 seconds\n     * Tone.getTransport().bpm.rampTo(120, 10);\n     */\n    bpm: TickParam<\"bpm\">;\n    /**\n     * The time signature, or more accurately the numerator\n     * of the time signature over a denominator of 4.\n     */\n    private _timeSignature;\n    /**\n     * All the events in an object to keep track by ID\n     */\n    private _scheduledEvents;\n    /**\n     * The scheduled events.\n     */\n    private _timeline;\n    /**\n     * Repeated events\n     */\n    private _repeatedEvents;\n    /**\n     * All of the synced Signals\n     */\n    private _syncedSignals;\n    /**\n     * The subdivision of the swing\n     */\n    private _swingTicks;\n    /**\n     * The swing amount\n     */\n    private _swingAmount;\n    constructor(options?: Partial<TransportOptions>);\n    static getDefaults(): TransportOptions;\n    /**\n     * called on every tick\n     * @param  tickTime clock relative tick time\n     */\n    private _processTick;\n    /**\n     * Schedule an event along the timeline.\n     * @param callback The callback to be invoked at the time.\n     * @param time The time to invoke the callback at.\n     * @return The id of the event which can be used for canceling the event.\n     * @example\n     * // schedule an event on the 16th measure\n     * Tone.getTransport().schedule((time) => {\n     * \t// invoked on measure 16\n     * \tconsole.log(\"measure 16!\");\n     * }, \"16:0:0\");\n     */\n    schedule(callback: TransportCallback, time: TransportTime | TransportTimeClass): number;\n    /**\n     * Schedule a repeated event along the timeline. The event will fire\n     * at the `interval` starting at the `startTime` and for the specified\n     * `duration`.\n     * @param  callback   The callback to invoke.\n     * @param  interval   The duration between successive callbacks. Must be a positive number.\n     * @param  startTime  When along the timeline the events should start being invoked.\n     * @param  duration How long the event should repeat.\n     * @return  The ID of the scheduled event. Use this to cancel the event.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // a callback invoked every eighth note after the first measure\n     * Tone.getTransport().scheduleRepeat((time) => {\n     * \tosc.start(time).stop(time + 0.1);\n     * }, \"8n\", \"1m\");\n     */\n    scheduleRepeat(callback: TransportCallback, interval: Time | TimeClass, startTime?: TransportTime | TransportTimeClass, duration?: Time): number;\n    /**\n     * Schedule an event that will be removed after it is invoked.\n     * @param callback The callback to invoke once.\n     * @param time The time the callback should be invoked.\n     * @returns The ID of the scheduled event.\n     */\n    scheduleOnce(callback: TransportCallback, time: TransportTime | TransportTimeClass): number;\n    /**\n     * Clear the passed in event id from the timeline\n     * @param eventId The id of the event.\n     */\n    clear(eventId: number): this;\n    /**\n     * Add an event to the correct timeline. Keep track of the\n     * timeline it was added to.\n     * @returns the event id which was just added\n     */\n    private _addEvent;\n    /**\n     * Remove scheduled events from the timeline after\n     * the given time. Repeated events will be removed\n     * if their startTime is after the given time\n     * @param after Clear all events after this time.\n     */\n    cancel(after?: TransportTime): this;\n    /**\n     * Bind start/stop/pause events from the clock and emit them.\n     */\n    private _bindClockEvents;\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\", or \"paused\"\n     */\n    get state(): PlaybackState;\n    /**\n     * Start the transport and all sources synced to the transport.\n     * @param  time The time when the transport should start.\n     * @param  offset The timeline offset to start the transport.\n     * @example\n     * // start the transport in one second starting at beginning of the 5th measure.\n     * Tone.getTransport().start(\"+1\", \"4:0:0\");\n     */\n    start(time?: Time, offset?: TransportTime): this;\n    /**\n     * Stop the transport and all sources synced to the transport.\n     * @param time The time when the transport should stop.\n     * @example\n     * Tone.getTransport().stop();\n     */\n    stop(time?: Time): this;\n    /**\n     * Pause the transport and all sources synced to the transport.\n     */\n    pause(time?: Time): this;\n    /**\n     * Toggle the current state of the transport. If it is\n     * started, it will stop it, otherwise it will start the Transport.\n     * @param  time The time of the event\n     */\n    toggle(time?: Time): this;\n    /**\n     * The time signature as just the numerator over 4.\n     * For example 4/4 would be just 4 and 6/8 would be 3.\n     * @example\n     * // common time\n     * Tone.getTransport().timeSignature = 4;\n     * // 7/8\n     * Tone.getTransport().timeSignature = [7, 8];\n     * // this will be reduced to a single number\n     * Tone.getTransport().timeSignature; // returns 3.5\n     */\n    get timeSignature(): TimeSignature;\n    set timeSignature(timeSig: TimeSignature);\n    /**\n     * When the Transport.loop = true, this is the starting position of the loop.\n     */\n    get loopStart(): Time;\n    set loopStart(startPosition: Time);\n    /**\n     * When the Transport.loop = true, this is the ending position of the loop.\n     */\n    get loopEnd(): Time;\n    set loopEnd(endPosition: Time);\n    /**\n     * If the transport loops or not.\n     */\n    get loop(): boolean;\n    set loop(loop: boolean);\n    /**\n     * Set the loop start and stop at the same time.\n     * @example\n     * // loop over the first measure\n     * Tone.getTransport().setLoopPoints(0, \"1m\");\n     * Tone.getTransport().loop = true;\n     */\n    setLoopPoints(startPosition: TransportTime, endPosition: TransportTime): this;\n    /**\n     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.\n     */\n    get swing(): NormalRange;\n    set swing(amount: NormalRange);\n    /**\n     * Set the subdivision which the swing will be applied to.\n     * The default value is an 8th note. Value must be less\n     * than a quarter note.\n     */\n    get swingSubdivision(): Subdivision;\n    set swingSubdivision(subdivision: Subdivision);\n    /**\n     * The Transport's position in Bars:Beats:Sixteenths.\n     * Setting the value will jump to that position right away.\n     */\n    get position(): BarsBeatsSixteenths | Time;\n    set position(progress: Time);\n    /**\n     * The Transport's position in seconds.\n     * Setting the value will jump to that position right away.\n     */\n    get seconds(): Seconds;\n    set seconds(s: Seconds);\n    /**\n     * The Transport's loop position as a normalized value. Always\n     * returns 0 if the Transport.loop = false.\n     */\n    get progress(): NormalRange;\n    /**\n     * The Transport's current tick position.\n     */\n    get ticks(): Ticks;\n    set ticks(t: Ticks);\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time?: Time): Ticks;\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time: Time): Seconds;\n    /**\n     * Pulses Per Quarter note. This is the smallest resolution\n     * the Transport timing supports. This should be set once\n     * on initialization and not set again. Changing this value\n     * after other objects have been created can cause problems.\n     */\n    get PPQ(): number;\n    set PPQ(ppq: number);\n    /**\n     * Returns the time aligned to the next subdivision\n     * of the Transport. If the Transport is not started,\n     * it will return 0.\n     * Note: this will not work precisely during tempo ramps.\n     * @param  subdivision  The subdivision to quantize to\n     * @return  The context time of the next subdivision.\n     * @example\n     * // the transport must be started, otherwise returns 0\n     * Tone.getTransport().start();\n     * Tone.getTransport().nextSubdivision(\"4n\");\n     */\n    nextSubdivision(subdivision?: Time): Seconds;\n    /**\n     * Attaches the signal to the tempo control signal so that\n     * any changes in the tempo will change the signal in the same\n     * ratio.\n     *\n     * @param signal\n     * @param ratio Optionally pass in the ratio between the two signals.\n     * \t\t\tOtherwise it will be computed based on their current values.\n     */\n    syncSignal(signal: Signal<any>, ratio?: number): this;\n    /**\n     * Unsyncs a previously synced signal from the transport's control.\n     * @see {@link syncSignal}.\n     */\n    unsyncSignal(signal: Signal<any>): this;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n    on: (event: TransportEventNames, callback: (...args: any[]) => void) => this;\n    once: (event: TransportEventNames, callback: (...args: any[]) => void) => this;\n    off: (event: TransportEventNames, callback?: ((...args: any[]) => void) | undefined) => this;\n    emit: (event: any, ...args: any[]) => this;\n}\nexport {};\n",
  "core/clock/TransportEvent.d.ts": "import { Seconds, Ticks } from \"../type/Units\";\nimport type { TransportClass as Transport } from \"./Transport\";\nexport interface TransportEventOptions {\n    callback: (time: number) => void;\n    once: boolean;\n    time: Ticks;\n}\n/**\n * TransportEvent is an internal class used by {@link TransportClass}\n * to schedule events. Do no invoke this class directly, it is\n * handled from within Tone.Transport.\n */\nexport declare class TransportEvent {\n    /**\n     * Reference to the Transport that created it\n     */\n    protected transport: Transport;\n    /**\n     * The unique id of the event\n     */\n    id: number;\n    /**\n     * The time the event starts\n     */\n    time: Ticks;\n    /**\n     * The callback to invoke\n     */\n    private callback?;\n    /**\n     * If the event should be removed after being invoked.\n     */\n    private _once;\n    /**\n     * The remaining value between the passed in time, and Math.floor(time).\n     * This value is later added back when scheduling to get sub-tick precision.\n     */\n    protected _remainderTime: number;\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport: Transport, opts: Partial<TransportEventOptions>);\n    static getDefaults(): TransportEventOptions;\n    /**\n     * Current ID counter\n     */\n    private static _eventId;\n    /**\n     * Get the time and remainder time.\n     */\n    protected get floatTime(): number;\n    /**\n     * Invoke the event callback.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time: Seconds): void;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\n",
  "core/clock/TransportRepeatEvent.d.ts": "import { BaseContext } from \"../context/BaseContext\";\nimport { Seconds, Ticks } from \"../type/Units\";\nimport { TransportEvent, TransportEventOptions } from \"./TransportEvent\";\nimport type { TransportClass as Transport } from \"./Transport\";\ninterface TransportRepeatEventOptions extends TransportEventOptions {\n    interval: Ticks;\n    duration: Ticks;\n}\n/**\n * TransportRepeatEvent is an internal class used by Tone.Transport\n * to schedule repeat events. This class should not be instantiated directly.\n */\nexport declare class TransportRepeatEvent extends TransportEvent {\n    /**\n     * When the event should stop repeating\n     */\n    private duration;\n    /**\n     * The interval of the repeated event\n     */\n    private _interval;\n    /**\n     * The ID of the current timeline event\n     */\n    private _currentId;\n    /**\n     * The ID of the next timeline event\n     */\n    private _nextId;\n    /**\n     * The time of the next event\n     */\n    private _nextTick;\n    /**\n     * a reference to the bound start method\n     */\n    private _boundRestart;\n    /**\n     * The audio context belonging to this event\n     */\n    protected context: BaseContext;\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport: Transport, opts: Partial<TransportRepeatEventOptions>);\n    static getDefaults(): TransportRepeatEventOptions;\n    /**\n     * Invoke the callback. Returns the tick time which\n     * the next event should be scheduled at.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time: Seconds): void;\n    /**\n     * Create an event on the transport on the nextTick\n     */\n    private _createEvent;\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    private _createEvents;\n    /**\n     * Re-compute the events when the transport time has changed from a start/ticks/loopStart event\n     */\n    private _restart;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/context/AbstractParam.d.ts": "import { Time, UnitMap, UnitName } from \"../type/Units\";\n/**\n * Abstract base class for {@link Param} and {@link Signal}\n */\nexport declare abstract class AbstractParam<TypeName extends UnitName> {\n    /**\n     * Schedules a parameter value change at the given time.\n     * @param value The value to set the signal.\n     * @param time The time when the change should occur.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst osc = new Tone.Oscillator(20).toDestination().start();\n     * \t// set the frequency to 40 at exactly 0.25 seconds\n     * \tosc.frequency.setValueAtTime(40, 0.25);\n     * }, 0.5, 1);\n     */\n    abstract setValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    /**\n     * Get the signals value at the given time. Subsequent scheduling\n     * may invalidate the returned value.\n     * @param time When to get the value\n     * @example\n     * const signal = new Tone.Signal().toDestination();\n     * // ramp up to '8' over 3 seconds\n     * signal.rampTo(8, 3);\n     * // ramp back down to '0' over 3 seconds\n     * signal.rampTo(0, 3, \"+3\");\n     * setInterval(() => {\n     * \t// check the value every 100 ms\n     * \tconsole.log(signal.getValueAtTime(Tone.now()));\n     * }, 100);\n     */\n    abstract getValueAtTime(time: Time): UnitMap[TypeName];\n    /**\n     * Creates a schedule point with the current value at the current time.\n     * Automation methods like {@link linearRampToValueAtTime} and {@link exponentialRampToValueAtTime}\n     * require a starting automation value usually set by {@link setValueAtTime}. This method\n     * is useful since it will do a `setValueAtTime` with whatever the currently computed\n     * value at the given time is.\n     * @param time When to add a ramp point.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // set the frequency to \"G4\" in exactly 1 second from now.\n     * osc.frequency.setRampPoint(\"+1\");\n     * osc.frequency.linearRampToValueAtTime(\"C1\", \"+2\");\n     */\n    abstract setRampPoint(time: Time): this;\n    /**\n     * Schedules a linear continuous change in parameter value from the\n     * previous scheduled parameter value to the given value.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(0).toDestination();\n     * \t// the ramp starts from the previously scheduled value\n     * \tsignal.setValueAtTime(0, 0.1);\n     * \tsignal.linearRampToValueAtTime(1, 0.4);\n     * }, 0.5, 1);\n     */\n    abstract linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    /**\n     * Schedules an exponential continuous change in parameter value from\n     * the previous scheduled parameter value to the given value.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(1).toDestination();\n     * \t// the ramp starts from the previously scheduled value, which must be positive\n     * \tsignal.setValueAtTime(1, 0.1);\n     * \tsignal.exponentialRampToValueAtTime(0, 0.4);\n     * }, 0.5, 1);\n     */\n    abstract exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    /**\n     * Schedules an exponential continuous change in parameter value from\n     * the current time and current value to the given value over the\n     * duration of the rampTime.\n     * @param value   The value to ramp to.\n     * @param rampTime the time that it takes the\n     *                             value to ramp from it's current value\n     * @param startTime When the ramp should start.\n     * @example\n     * const delay = new Tone.FeedbackDelay(0.5, 0.98).toDestination();\n     * // a short burst of noise through the feedback delay\n     * const noise = new Tone.Noise().connect(delay).start().stop(\"+0.1\");\n     * // making the delay time shorter over time will also make the pitch rise\n     * delay.delayTime.exponentialRampTo(0.01, 20);\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(.1).toDestination();\n     * \tsignal.exponentialRampTo(5, 0.3, 0.1);\n     * }, 0.5, 1);\n     */\n    abstract exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    /**\n     * Schedules an linear continuous change in parameter value from\n     * the current time and current value to the given value over the\n     * duration of the rampTime.\n     *\n     * @param  value   The value to ramp to.\n     * @param  rampTime the time that it takes the\n     *                              value to ramp from it's current value\n     * @param startTime \tWhen the ramp should start.\n     * @returns {Param} this\n     * @example\n     * const delay = new Tone.FeedbackDelay(0.5, 0.98).toDestination();\n     * // a short burst of noise through the feedback delay\n     * const noise = new Tone.Noise().connect(delay).start().stop(\"+0.1\");\n     * // making the delay time shorter over time will also make the pitch rise\n     * delay.delayTime.linearRampTo(0.01, 20);\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(1).toDestination();\n     * \tsignal.linearRampTo(0, 0.3, 0.1);\n     * }, 0.5, 1);\n     */\n    abstract linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    /**\n     * Start exponentially approaching the target value at the given time. Since it\n     * is an exponential approach it will continue approaching after the ramp duration. The\n     * rampTime is the time that it takes to reach over 99% of the way towards the value.\n     * @param  value   The value to ramp to.\n     * @param  rampTime the time that it takes the\n     *                              value to ramp from it's current value\n     * @param startTime \tWhen the ramp should start.\n     * @example\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(1).toDestination();\n     * \tsignal.targetRampTo(0, 0.3, 0.1);\n     * }, 0.5, 1);\n     */\n    abstract targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    /**\n     * Start exponentially approaching the target value at the given time. Since it\n     * is an exponential approach it will continue approaching after the ramp duration. The\n     * rampTime is the time that it takes to reach over 99% of the way towards the value. This methods\n     * is similar to setTargetAtTime except the third argument is a time instead of a 'timeConstant'\n     * @param  value   The value to ramp to.\n     * @param time \tWhen the ramp should start.\n     * @param  rampTime the time that it takes the value to ramp from it's current value\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // exponential approach over 4 seconds starting in 1 second\n     * osc.frequency.exponentialApproachValueAtTime(\"C4\", \"+1\", 4);\n     */\n    abstract exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;\n    /**\n     * Start exponentially approaching the target value at the given time with\n     * a rate having the given time constant.\n     * @param value\n     * @param startTime\n     * @param timeConstant\n     */\n    abstract setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: number): this;\n    /**\n     * Sets an array of arbitrary parameter values starting at the given time\n     * for the given duration.\n     *\n     * @param values\n     * @param startTime\n     * @param duration\n     * @param scaling If the values in the curve should be scaled by some value\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(1).toDestination();\n     * \tsignal.setValueCurveAtTime([1, 0.2, 0.8, 0.1, 0], 0.2, 0.3);\n     * }, 0.5, 1);\n     */\n    abstract setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;\n    /**\n     * Cancels all scheduled parameter changes with times greater than or\n     * equal to startTime.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(0).toDestination();\n     * \tsignal.setValueAtTime(0.1, 0.1);\n     * \tsignal.setValueAtTime(0.2, 0.2);\n     * \tsignal.setValueAtTime(0.3, 0.3);\n     * \tsignal.setValueAtTime(0.4, 0.4);\n     * \t// cancels the last two scheduled changes\n     * \tsignal.cancelScheduledValues(0.3);\n     * }, 0.5, 1);\n     */\n    abstract cancelScheduledValues(time: Time): this;\n    /**\n     * This is similar to {@link cancelScheduledValues} except\n     * it holds the automated value at time until the next automated event.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst signal = new Tone.Signal(0).toDestination();\n     * \tsignal.linearRampTo(1, 0.5, 0);\n     * \tsignal.cancelAndHoldAtTime(0.3);\n     * }, 0.5, 1);\n     */\n    abstract cancelAndHoldAtTime(time: Time): this;\n    /**\n     * Ramps to the given value over the duration of the rampTime.\n     * Automatically selects the best ramp type (exponential or linear)\n     * depending on the `units` of the signal\n     *\n     * @param  value\n     * @param  rampTime The time that it takes the value to ramp from it's current value\n     * @param startTime When the ramp should start.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // schedule it to ramp either linearly or exponentially depending on the units\n     * osc.frequency.rampTo(\"A2\", 10);\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // schedule it to ramp starting at a specific time\n     * osc.frequency.rampTo(\"A2\", 10, \"+2\");\n     */\n    abstract rampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    /**\n     * The current value of the parameter. Setting this value\n     * is equivalent to setValueAtTime(value, context.currentTime)\n     */\n    abstract value: UnitMap[TypeName];\n    /**\n     * If the value should be converted or not\n     */\n    abstract convert: boolean;\n    /**\n     * The unit type\n     */\n    abstract readonly units: UnitName;\n    /**\n     * True if the signal value is being overridden by\n     * a connected signal. Internal use only.\n     */\n    abstract overridden: boolean;\n    /**\n     * The minimum value of the output given the units\n     */\n    abstract readonly minValue: number;\n    /**\n     * The maximum value of the output given the units\n     */\n    abstract readonly maxValue: number;\n}\n",
  "core/context/AudioContext.d.ts": "/**\n * Create a new AudioContext\n */\nexport declare function createAudioContext(options?: AudioContextOptions): AudioContext;\n/**\n * Create a new OfflineAudioContext\n */\nexport declare function createOfflineAudioContext(channels: number, length: number, sampleRate: number): OfflineAudioContext;\n/**\n * Either the online or offline audio context\n */\nexport type AnyAudioContext = AudioContext | OfflineAudioContext;\n/**\n * Interface for things that Tone.js adds to the window\n */\ninterface ToneWindow extends Window {\n    TONE_SILENCE_LOGGING?: boolean;\n    TONE_DEBUG_CLASS?: string;\n    BaseAudioContext: any;\n    AudioWorkletNode: any;\n}\n/**\n * A reference to the window object\n * @hidden\n */\nexport declare const theWindow: ToneWindow | null;\n/**\n * If the browser has a window object which has an AudioContext\n * @hidden\n */\nexport declare const hasAudioContext: boolean | null;\nexport declare function createAudioWorkletNode(context: AnyAudioContext, name: string, options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;\n/**\n * This promise resolves to a boolean which indicates if the\n * functionality is supported within the currently used browse.\n * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)\n */\nexport { isSupported as supported } from \"standardized-audio-context\";\n",
  "core/context/BaseContext.d.ts": "import { Seconds } from \"../type/Units\";\nimport { Emitter } from \"../util/Emitter\";\nimport { AnyAudioContext } from \"./AudioContext\";\nimport type { DrawClass as Draw } from \"../util/Draw\";\nimport type { DestinationClass as Destination } from \"./Destination\";\nimport type { TransportClass as Transport } from \"../clock/Transport\";\nimport type { ListenerClass as Listener } from \"./Listener\";\nexport type ExcludedFromBaseAudioContext = \"onstatechange\" | \"addEventListener\" | \"removeEventListener\" | \"listener\" | \"dispatchEvent\" | \"audioWorklet\" | \"destination\" | \"createScriptProcessor\";\nexport type BaseAudioContextSubset = Omit<BaseAudioContext, ExcludedFromBaseAudioContext>;\nexport type ContextLatencyHint = AudioContextLatencyCategory;\nexport declare abstract class BaseContext extends Emitter<\"statechange\" | \"tick\"> implements BaseAudioContextSubset {\n    abstract createAnalyser(): AnalyserNode;\n    abstract createOscillator(): OscillatorNode;\n    abstract createBufferSource(): AudioBufferSourceNode;\n    abstract createBiquadFilter(): BiquadFilterNode;\n    abstract createBuffer(_numberOfChannels: number, _length: number, _sampleRate: number): AudioBuffer;\n    abstract createChannelMerger(_numberOfInputs?: number | undefined): ChannelMergerNode;\n    abstract createChannelSplitter(_numberOfOutputs?: number | undefined): ChannelSplitterNode;\n    abstract createConstantSource(): ConstantSourceNode;\n    abstract createConvolver(): ConvolverNode;\n    abstract createDelay(_maxDelayTime?: number | undefined): DelayNode;\n    abstract createDynamicsCompressor(): DynamicsCompressorNode;\n    abstract createGain(): GainNode;\n    abstract createIIRFilter(_feedForward: number[] | Float32Array, _feedback: number[] | Float32Array): IIRFilterNode;\n    abstract createPanner(): PannerNode;\n    abstract createPeriodicWave(_real: number[] | Float32Array, _imag: number[] | Float32Array, _constraints?: PeriodicWaveConstraints | undefined): PeriodicWave;\n    abstract createStereoPanner(): StereoPannerNode;\n    abstract createWaveShaper(): WaveShaperNode;\n    abstract createMediaStreamSource(_stream: MediaStream): MediaStreamAudioSourceNode;\n    abstract createMediaElementSource(_element: HTMLMediaElement): MediaElementAudioSourceNode;\n    abstract createMediaStreamDestination(): MediaStreamAudioDestinationNode;\n    abstract decodeAudioData(_audioData: ArrayBuffer): Promise<AudioBuffer>;\n    abstract createAudioWorkletNode(_name: string, _options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;\n    abstract get rawContext(): AnyAudioContext;\n    abstract addAudioWorkletModule(_url: string): Promise<void>;\n    abstract lookAhead: number;\n    abstract latencyHint: ContextLatencyHint | Seconds;\n    abstract resume(): Promise<void>;\n    abstract setTimeout(_fn: (...args: any[]) => void, _timeout: Seconds): number;\n    abstract clearTimeout(_id: number): this;\n    abstract setInterval(_fn: (...args: any[]) => void, _interval: Seconds): number;\n    abstract clearInterval(_id: number): this;\n    abstract getConstant(_val: number): AudioBufferSourceNode;\n    abstract get currentTime(): Seconds;\n    abstract get state(): AudioContextState;\n    abstract get sampleRate(): number;\n    abstract get listener(): Listener;\n    abstract get transport(): Transport;\n    abstract get draw(): Draw;\n    abstract get destination(): Destination;\n    abstract now(): Seconds;\n    abstract immediate(): Seconds;\n    toJSON(): Record<string, any>;\n    readonly isOffline: boolean;\n}\n",
  "core/context/Context.d.ts": "import { TickerClockSource } from \"../clock/Ticker\";\nimport { Seconds } from \"../type/Units\";\nimport { AnyAudioContext } from \"./AudioContext\";\nimport { BaseContext, ContextLatencyHint } from \"./BaseContext\";\nimport type { DrawClass as Draw } from \"../util/Draw\";\nimport type { DestinationClass as Destination } from \"./Destination\";\nimport type { TransportClass as Transport } from \"../clock/Transport\";\nimport type { ListenerClass as Listener } from \"./Listener\";\nexport interface ContextOptions {\n    clockSource: TickerClockSource;\n    latencyHint: ContextLatencyHint;\n    lookAhead: Seconds;\n    updateInterval: Seconds;\n    context: AnyAudioContext;\n}\nexport interface ContextTimeoutEvent {\n    callback: (...args: any[]) => void;\n    id: number;\n    time: Seconds;\n}\n/**\n * Wrapper around the native AudioContext.\n * @category Core\n */\nexport declare class Context extends BaseContext {\n    readonly name: string;\n    /**\n     * private reference to the BaseAudioContext\n     */\n    protected readonly _context: AnyAudioContext;\n    /**\n     * A reliable callback method\n     */\n    private readonly _ticker;\n    /**\n     * The default latency hint\n     */\n    private _latencyHint;\n    /**\n     * An object containing all of the constants AudioBufferSourceNodes\n     */\n    private _constants;\n    /**\n     * All of the setTimeout events.\n     */\n    private _timeouts;\n    /**\n     * The timeout id counter\n     */\n    private _timeoutIds;\n    /**\n     * A reference the Transport singleton belonging to this context\n     */\n    private _transport;\n    /**\n     * A reference the Listener singleton belonging to this context\n     */\n    private _listener;\n    /**\n     * A reference the Destination singleton belonging to this context\n     */\n    private _destination;\n    /**\n     * A reference the Transport singleton belonging to this context\n     */\n    private _draw;\n    /**\n     * Private indicator if the context has been initialized\n     */\n    private _initialized;\n    /**\n     * Private indicator if a close() has been called on the context, since close is async\n     */\n    private _closeStarted;\n    /**\n     * Indicates if the context is an OfflineAudioContext or an AudioContext\n     */\n    readonly isOffline: boolean;\n    constructor(context?: AnyAudioContext);\n    constructor(options?: Partial<ContextOptions>);\n    static getDefaults(): ContextOptions;\n    /**\n     * Finish setting up the context. **You usually do not need to do this manually.**\n     */\n    private initialize;\n    createAnalyser(): AnalyserNode;\n    createOscillator(): OscillatorNode;\n    createBufferSource(): AudioBufferSourceNode;\n    createBiquadFilter(): BiquadFilterNode;\n    createBuffer(numberOfChannels: number, length: number, sampleRate: number): AudioBuffer;\n    createChannelMerger(numberOfInputs?: number | undefined): ChannelMergerNode;\n    createChannelSplitter(numberOfOutputs?: number | undefined): ChannelSplitterNode;\n    createConstantSource(): ConstantSourceNode;\n    createConvolver(): ConvolverNode;\n    createDelay(maxDelayTime?: number | undefined): DelayNode;\n    createDynamicsCompressor(): DynamicsCompressorNode;\n    createGain(): GainNode;\n    createIIRFilter(feedForward: number[] | Float32Array, feedback: number[] | Float32Array): IIRFilterNode;\n    createPanner(): PannerNode;\n    createPeriodicWave(real: number[] | Float32Array, imag: number[] | Float32Array, constraints?: PeriodicWaveConstraints | undefined): PeriodicWave;\n    createStereoPanner(): StereoPannerNode;\n    createWaveShaper(): WaveShaperNode;\n    createMediaStreamSource(stream: MediaStream): MediaStreamAudioSourceNode;\n    createMediaElementSource(element: HTMLMediaElement): MediaElementAudioSourceNode;\n    createMediaStreamDestination(): MediaStreamAudioDestinationNode;\n    decodeAudioData(audioData: ArrayBuffer): Promise<AudioBuffer>;\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get currentTime(): Seconds;\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get state(): AudioContextState;\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get sampleRate(): number;\n    /**\n     * The listener\n     */\n    get listener(): Listener;\n    set listener(l: Listener);\n    /**\n     * There is only one Transport per Context. It is created on initialization.\n     */\n    get transport(): Transport;\n    set transport(t: Transport);\n    /**\n     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.\n     */\n    get draw(): Draw;\n    set draw(d: Draw);\n    /**\n     * A reference to the Context's destination node.\n     */\n    get destination(): Destination;\n    set destination(d: Destination);\n    /**\n     * Maps a module name to promise of the addModule method\n     */\n    private _workletPromise;\n    /**\n     * Create an audio worklet node from a name and options. The module\n     * must first be loaded using {@link addAudioWorkletModule}.\n     */\n    createAudioWorkletNode(name: string, options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;\n    /**\n     * Add an AudioWorkletProcessor module\n     * @param url The url of the module\n     */\n    addAudioWorkletModule(url: string): Promise<void>;\n    /**\n     * Returns a promise which resolves when all of the worklets have been loaded on this context\n     */\n    protected workletsAreReady(): Promise<void>;\n    /**\n     * How often the interval callback is invoked.\n     * This number corresponds to how responsive the scheduling\n     * can be. Setting to 0 will result in the lowest practial interval\n     * based on context properties. context.updateInterval + context.lookAhead\n     * gives you the total latency between scheduling an event and hearing it.\n     */\n    get updateInterval(): Seconds;\n    set updateInterval(interval: Seconds);\n    /**\n     * What the source of the clock is, either \"worker\" (default),\n     * \"timeout\", or \"offline\" (none).\n     */\n    get clockSource(): TickerClockSource;\n    set clockSource(type: TickerClockSource);\n    /**\n     * The amount of time into the future events are scheduled. Giving Web Audio\n     * a short amount of time into the future to schedule events can reduce clicks and\n     * improve performance. This value can be set to 0 to get the lowest latency.\n     * Adjusting this value also affects the {@link updateInterval}.\n     */\n    get lookAhead(): Seconds;\n    set lookAhead(time: Seconds);\n    private _lookAhead;\n    /**\n     * The type of playback, which affects tradeoffs between audio\n     * output latency and responsiveness.\n     * In addition to setting the value in seconds, the latencyHint also\n     * accepts the strings \"interactive\" (prioritizes low latency),\n     * \"playback\" (prioritizes sustained playback), \"balanced\" (balances\n     * latency and performance).\n     * @example\n     * // prioritize sustained playback\n     * const context = new Tone.Context({ latencyHint: \"playback\" });\n     * // set this context as the global Context\n     * Tone.setContext(context);\n     * // the global context is gettable with Tone.getContext()\n     * console.log(Tone.getContext().latencyHint);\n     */\n    get latencyHint(): ContextLatencyHint | Seconds;\n    /**\n     * The unwrapped AudioContext or OfflineAudioContext\n     */\n    get rawContext(): AnyAudioContext;\n    /**\n     * The current audio context time plus a short {@link lookAhead}.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(\"now\", Tone.now());\n     * }, 100);\n     */\n    now(): Seconds;\n    /**\n     * The current audio context time without the {@link lookAhead}.\n     * In most cases it is better to use {@link now} instead of {@link immediate} since\n     * with {@link now} the {@link lookAhead} is applied equally to _all_ components including internal components,\n     * to making sure that everything is scheduled in sync. Mixing {@link now} and {@link immediate}\n     * can cause some timing issues. If no lookAhead is desired, you can set the {@link lookAhead} to `0`.\n     */\n    immediate(): Seconds;\n    /**\n     * Starts the audio context from a suspended state. This is required\n     * to initially start the AudioContext.\n     * @see {@link start}\n     */\n    resume(): Promise<void>;\n    /**\n     * Close the context. Once closed, the context can no longer be used and\n     * any AudioNodes created from the context will be silent.\n     */\n    close(): Promise<void>;\n    /**\n     * **Internal** Generate a looped buffer at some constant value.\n     */\n    getConstant(val: number): AudioBufferSourceNode;\n    /**\n     * Clean up. Also closes the audio context.\n     */\n    dispose(): this;\n    /**\n     * The private loop which keeps track of the context scheduled timeouts\n     * Is invoked from the clock source\n     */\n    private _timeoutLoop;\n    /**\n     * A setTimeout which is guaranteed by the clock source.\n     * Also runs in the offline context.\n     * @param  fn       The callback to invoke\n     * @param  timeout  The timeout in seconds\n     * @returns ID to use when invoking Context.clearTimeout\n     */\n    setTimeout(fn: (...args: any[]) => void, timeout: Seconds): number;\n    /**\n     * Clears a previously scheduled timeout with Tone.context.setTimeout\n     * @param  id  The ID returned from setTimeout\n     */\n    clearTimeout(id: number): this;\n    /**\n     * Clear the function scheduled by {@link setInterval}\n     */\n    clearInterval(id: number): this;\n    /**\n     * Adds a repeating event to the context's callback clock\n     */\n    setInterval(fn: (...args: any[]) => void, interval: Seconds): number;\n}\n",
  "core/context/ContextInitialization.d.ts": "import type { Context } from \"./Context\";\n/**\n * Used internally to setup a new Context\n */\nexport declare function onContextInit(cb: (ctx: Context) => void): void;\n/**\n * Invoke any classes which need to also be initialized when a new context is created.\n */\nexport declare function initializeContext(ctx: Context): void;\n/**\n * Used internally to tear down a Context\n */\nexport declare function onContextClose(cb: (ctx: Context) => void): void;\nexport declare function closeContext(ctx: Context): void;\n",
  "core/context/Delay.d.ts": "import { Param } from \"../context/Param\";\nimport { Seconds, Time } from \"../type/Units\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"./ToneAudioNode\";\nexport interface DelayOptions extends ToneAudioNodeOptions {\n    delayTime: Time;\n    maxDelay: Time;\n}\n/**\n * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst delay = new Tone.Delay(0.1).toDestination();\n * \t// connect the signal to both the delay and the destination\n * \tconst pulse = new Tone.PulseOscillator().connect(delay).toDestination();\n * \t// start and stop the pulse\n * \tpulse.start(0).stop(0.01);\n * }, 0.5, 1);\n */\nexport declare class Delay extends ToneAudioNode<DelayOptions> {\n    readonly name: string;\n    /**\n     * Private holder of the max delay time\n     */\n    private _maxDelay;\n    /**\n     * The amount of time the incoming signal is delayed.\n     * @example\n     * const delay = new Tone.Delay().toDestination();\n     * // modulate the delayTime between 0.1 and 1 seconds\n     * const delayLFO = new Tone.LFO(0.5, 0.1, 1).start().connect(delay.delayTime);\n     * const pulse = new Tone.PulseOscillator().connect(delay).start();\n     * // the change in delayTime causes the pitch to go up and down\n     */\n    readonly delayTime: Param<\"time\">;\n    /**\n     * Private reference to the internal DelayNode\n     */\n    private _delayNode;\n    readonly input: DelayNode;\n    readonly output: DelayNode;\n    /**\n     * @param delayTime The delay applied to the incoming signal.\n     * @param maxDelay The maximum delay time.\n     */\n    constructor(delayTime?: Time, maxDelay?: Time);\n    constructor(options?: Partial<DelayOptions>);\n    static getDefaults(): DelayOptions;\n    /**\n     * The maximum delay time. This cannot be changed after\n     * the value is passed into the constructor.\n     */\n    get maxDelay(): Seconds;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "core/context/Destination.d.ts": "import { Volume } from \"../../component/channel/Volume\";\nimport { Decibels } from \"../type/Units\";\nimport { Gain } from \"./Gain\";\nimport { Param } from \"./Param\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"./ToneAudioNode\";\ninterface DestinationOptions extends ToneAudioNodeOptions {\n    volume: Decibels;\n    mute: boolean;\n}\n/**\n * A single master output which is connected to the\n * AudioDestinationNode (aka your speakers).\n * It provides useful conveniences such as the ability\n * to set the volume and mute the entire application.\n * It also gives you the ability to apply master effects to your application.\n *\n * @example\n * const oscillator = new Tone.Oscillator().start();\n * // the audio will go from the oscillator to the speakers\n * oscillator.connect(Tone.getDestination());\n * // a convenience for connecting to the master output is also provided:\n * oscillator.toDestination();\n * @category Core\n */\nexport declare class DestinationClass extends ToneAudioNode<DestinationOptions> {\n    readonly name: string;\n    input: Volume;\n    output: Gain;\n    /**\n     * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * osc.start();\n     * // ramp the volume down to silent over 10 seconds\n     * Tone.getDestination().volume.rampTo(-Infinity, 10);\n     */\n    volume: Param<\"decibels\">;\n    constructor(options: Partial<DestinationOptions>);\n    static getDefaults(): DestinationOptions;\n    /**\n     * Mute the output.\n     * @example\n     * const oscillator = new Tone.Oscillator().start().toDestination();\n     * setTimeout(() => {\n     * \t// mute the output\n     * \tTone.Destination.mute = true;\n     * }, 1000);\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    /**\n     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously\n     * chained in the master effects chain.\n     * @param args All arguments will be connected in a row and the Master will be routed through it.\n     * @example\n     * // route all audio through a filter and compressor\n     * const lowpass = new Tone.Filter(800, \"lowpass\");\n     * const compressor = new Tone.Compressor(-18);\n     * Tone.Destination.chain(lowpass, compressor);\n     */\n    chain(...args: Array<AudioNode | ToneAudioNode>): this;\n    /**\n     * The maximum number of channels the system can output\n     * @example\n     * console.log(Tone.Destination.maxChannelCount);\n     */\n    get maxChannelCount(): number;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/context/DummyContext.d.ts": "import { BaseContext } from \"./BaseContext\";\nimport { Seconds } from \"../type/Units\";\nimport { AnyAudioContext } from \"./AudioContext\";\nimport type { DrawClass as Draw } from \"../util/Draw\";\nimport type { DestinationClass as Destination } from \"./Destination\";\nimport type { TransportClass as Transport } from \"../clock/Transport\";\nimport type { ListenerClass as Listener } from \"./Listener\";\nexport declare class DummyContext extends BaseContext {\n    createAnalyser(): AnalyserNode;\n    createOscillator(): OscillatorNode;\n    createBufferSource(): AudioBufferSourceNode;\n    createBiquadFilter(): BiquadFilterNode;\n    createBuffer(_numberOfChannels: number, _length: number, _sampleRate: number): AudioBuffer;\n    createChannelMerger(_numberOfInputs?: number | undefined): ChannelMergerNode;\n    createChannelSplitter(_numberOfOutputs?: number | undefined): ChannelSplitterNode;\n    createConstantSource(): ConstantSourceNode;\n    createConvolver(): ConvolverNode;\n    createDelay(_maxDelayTime?: number | undefined): DelayNode;\n    createDynamicsCompressor(): DynamicsCompressorNode;\n    createGain(): GainNode;\n    createIIRFilter(_feedForward: number[] | Float32Array, _feedback: number[] | Float32Array): IIRFilterNode;\n    createPanner(): PannerNode;\n    createPeriodicWave(_real: number[] | Float32Array, _imag: number[] | Float32Array, _constraints?: PeriodicWaveConstraints | undefined): PeriodicWave;\n    createStereoPanner(): StereoPannerNode;\n    createWaveShaper(): WaveShaperNode;\n    createMediaStreamSource(_stream: MediaStream): MediaStreamAudioSourceNode;\n    createMediaElementSource(_element: HTMLMediaElement): MediaElementAudioSourceNode;\n    createMediaStreamDestination(): MediaStreamAudioDestinationNode;\n    decodeAudioData(_audioData: ArrayBuffer): Promise<AudioBuffer>;\n    createAudioWorkletNode(_name: string, _options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;\n    get rawContext(): AnyAudioContext;\n    addAudioWorkletModule(_url: string): Promise<void>;\n    lookAhead: number;\n    latencyHint: number;\n    resume(): Promise<void>;\n    setTimeout(_fn: (...args: any[]) => void, _timeout: Seconds): number;\n    clearTimeout(_id: number): this;\n    setInterval(_fn: (...args: any[]) => void, _interval: Seconds): number;\n    clearInterval(_id: number): this;\n    getConstant(_val: number): AudioBufferSourceNode;\n    get currentTime(): Seconds;\n    get state(): AudioContextState;\n    get sampleRate(): number;\n    get listener(): Listener;\n    get transport(): Transport;\n    get draw(): Draw;\n    set draw(_d: Draw);\n    get destination(): Destination;\n    set destination(_d: Destination);\n    now(): number;\n    immediate(): number;\n    readonly isOffline: boolean;\n}\n",
  "core/context/Gain.d.ts": "import { Param } from \"../context/Param\";\nimport { UnitMap, UnitName } from \"../type/Units\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"./ToneAudioNode\";\ninterface GainOptions<TypeName extends UnitName> extends ToneAudioNodeOptions {\n    gain: UnitMap[TypeName];\n    units: TypeName;\n    convert: boolean;\n    minValue?: number;\n    maxValue?: number;\n}\n/**\n * A thin wrapper around the Native Web Audio GainNode.\n * The GainNode is a basic building block of the Web Audio\n * API and is useful for routing audio and adjusting gains.\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst gainNode = new Tone.Gain(0).toDestination();\n * \tconst osc = new Tone.Oscillator(30).connect(gainNode).start();\n * \tgainNode.gain.rampTo(1, 0.1);\n * \tgainNode.gain.rampTo(0, 0.4, 0.2);\n * }, 0.7, 1);\n */\nexport declare class Gain<TypeName extends \"gain\" | \"decibels\" | \"normalRange\" = \"gain\"> extends ToneAudioNode<GainOptions<TypeName>> {\n    readonly name: string;\n    /**\n     * The gain parameter of the gain node.\n     * @example\n     * const gainNode = new Tone.Gain(0).toDestination();\n     * const osc = new Tone.Oscillator().connect(gainNode).start();\n     * gainNode.gain.rampTo(1, 0.1);\n     * gainNode.gain.rampTo(0, 2, \"+0.5\");\n     */\n    readonly gain: Param<TypeName>;\n    /**\n     * The wrapped GainNode.\n     */\n    private _gainNode;\n    readonly input: GainNode;\n    readonly output: GainNode;\n    /**\n     * @param  gain The initial gain of the GainNode\n     * @param units The units of the gain parameter.\n     */\n    constructor(gain?: UnitMap[TypeName], units?: TypeName);\n    constructor(options?: Partial<GainOptions<TypeName>>);\n    static getDefaults(): GainOptions<any>;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/context/Listener.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"./ToneAudioNode\";\nimport { Param } from \"./Param\";\nexport interface ListenerOptions extends ToneAudioNodeOptions {\n    positionX: number;\n    positionY: number;\n    positionZ: number;\n    forwardX: number;\n    forwardY: number;\n    forwardZ: number;\n    upX: number;\n    upY: number;\n    upZ: number;\n}\n/**\n * Tone.Listener is a thin wrapper around the AudioListener. Listener combined\n * with {@link Panner3D} makes up the Web Audio API's 3D panning system. Panner3D allows you\n * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from\n * a first-person perspective. There is only one listener per audio context.\n */\nexport declare class ListenerClass extends ToneAudioNode<ListenerOptions> {\n    readonly name: string;\n    /**\n     * The listener has no inputs or outputs.\n     */\n    output: undefined;\n    input: undefined;\n    readonly positionX: Param;\n    readonly positionY: Param;\n    readonly positionZ: Param;\n    readonly forwardX: Param;\n    readonly forwardY: Param;\n    readonly forwardZ: Param;\n    readonly upX: Param;\n    readonly upY: Param;\n    readonly upZ: Param;\n    static getDefaults(): ListenerOptions;\n    dispose(): this;\n}\n",
  "core/context/Offline.d.ts": "import { Seconds } from \"../type/Units\";\nimport { OfflineContext } from \"./OfflineContext\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\nimport  \"./Destination\";\nimport  \"./Listener\";\n/**\n * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.\n * The OfflineAudioContext is capable of rendering much faster than real time in many cases.\n * The callback function also passes in an offline instance of {@link Context} which can be used\n * to schedule events along the Transport.\n * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.\n * @param  duration     the amount of time to record for.\n * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.\n * @example\n * // render 2 seconds of the oscillator\n * Tone.Offline(() => {\n * \t// only nodes created in this callback will be recorded\n * \tconst oscillator = new Tone.Oscillator().toDestination().start(0);\n * }, 2).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @example\n * // can also schedule events along the Transport\n * // using the passed in Offline Transport\n * Tone.Offline(({ transport }) => {\n * \tconst osc = new Tone.Oscillator().toDestination();\n * \ttransport.schedule(time => {\n * \t\tosc.start(time).stop(time + 0.1);\n * \t}, 1);\n * \t// make sure to start the transport\n * \ttransport.start(0.2);\n * }, 4).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @category Core\n */\nexport declare function Offline(callback: (context: OfflineContext) => Promise<void> | void, duration: Seconds, channels?: number, sampleRate?: number): Promise<ToneAudioBuffer>;\n",
  "core/context/OfflineContext.d.ts": "import { Context } from \"../context/Context\";\nimport { Seconds } from \"../type/Units\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\n/**\n * Wrapper around the OfflineAudioContext\n * @category Core\n * @example\n * // generate a single channel, 0.5 second buffer\n * const context = new Tone.OfflineContext(1, 0.5, 44100);\n * const osc = new Tone.Oscillator({ context });\n * context.render().then(buffer => {\n * \tconsole.log(buffer.numberOfChannels, buffer.duration);\n * });\n */\nexport declare class OfflineContext extends Context {\n    readonly name: string;\n    /**\n     * A private reference to the duration\n     */\n    private readonly _duration;\n    /**\n     * An artificial clock source\n     */\n    private _currentTime;\n    /**\n     * Private reference to the OfflineAudioContext.\n     */\n    protected _context: OfflineAudioContext;\n    readonly isOffline: boolean;\n    /**\n     * @param  channels  The number of channels to render\n     * @param  duration  The duration to render in seconds\n     * @param sampleRate the sample rate to render at\n     */\n    constructor(channels: number, duration: Seconds, sampleRate: number);\n    constructor(context: OfflineAudioContext);\n    /**\n     * Override the now method to point to the internal clock time\n     */\n    now(): Seconds;\n    /**\n     * Same as this.now()\n     */\n    get currentTime(): Seconds;\n    /**\n     * Render just the clock portion of the audio context.\n     */\n    private _renderClock;\n    /**\n     * Render the output of the OfflineContext\n     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.\n     */\n    render(asynchronous?: boolean): Promise<ToneAudioBuffer>;\n    /**\n     * Close the context\n     */\n    close(): Promise<void>;\n}\n",
  "core/context/Param.d.ts": "import { AbstractParam } from \"../context/AbstractParam\";\nimport { Positive, Time, UnitMap, UnitName } from \"../type/Units\";\nimport { Timeline } from \"../util/Timeline\";\nimport { ToneWithContext, ToneWithContextOptions } from \"./ToneWithContext\";\nexport interface ParamOptions<TypeName extends UnitName> extends ToneWithContextOptions {\n    units: TypeName;\n    value?: UnitMap[TypeName];\n    param: AudioParam | Param<TypeName>;\n    convert: boolean;\n    minValue?: number;\n    maxValue?: number;\n    swappable?: boolean;\n}\n/**\n * the possible automation types\n */\ntype AutomationType = \"linearRampToValueAtTime\" | \"exponentialRampToValueAtTime\" | \"setValueAtTime\" | \"setTargetAtTime\" | \"cancelScheduledValues\";\ninterface TargetAutomationEvent {\n    type: \"setTargetAtTime\";\n    time: number;\n    value: number;\n    constant: number;\n}\ninterface NormalAutomationEvent {\n    type: Exclude<AutomationType, \"setTargetAtTime\">;\n    time: number;\n    value: number;\n}\n/**\n * The events on the automation\n */\nexport type AutomationEvent = NormalAutomationEvent | TargetAutomationEvent;\n/**\n * Param wraps the native Web Audio's AudioParam to provide\n * additional unit conversion functionality. It also\n * serves as a base-class for classes which have a single,\n * automatable parameter.\n * @category Core\n */\nexport declare class Param<TypeName extends UnitName = \"number\"> extends ToneWithContext<ParamOptions<TypeName>> implements AbstractParam<TypeName> {\n    readonly name: string;\n    readonly input: GainNode | AudioParam;\n    readonly units: UnitName;\n    convert: boolean;\n    overridden: boolean;\n    /**\n     * The timeline which tracks all of the automations.\n     */\n    protected _events: Timeline<AutomationEvent>;\n    /**\n     * The native parameter to control\n     */\n    protected _param: AudioParam;\n    /**\n     * The default value before anything is assigned\n     */\n    protected _initialValue: number;\n    /**\n     * The minimum output value\n     */\n    private _minOutput;\n    /**\n     * Private reference to the min and max values if passed into the constructor\n     */\n    private readonly _minValue?;\n    private readonly _maxValue?;\n    /**\n     * If the underlying AudioParam can be swapped out\n     * using the setParam method.\n     */\n    protected readonly _swappable: boolean;\n    /**\n     * @param param The AudioParam to wrap\n     * @param units The unit name\n     * @param convert Whether or not to convert the value to the target units\n     */\n    constructor(param: AudioParam, units?: TypeName, convert?: boolean);\n    constructor(options: Partial<ParamOptions<TypeName>>);\n    static getDefaults(): ParamOptions<any>;\n    get value(): UnitMap[TypeName];\n    set value(value: UnitMap[TypeName]);\n    get minValue(): number;\n    get maxValue(): number;\n    /**\n     * Type guard based on the unit name\n     */\n    private _is;\n    /**\n     * Make sure the value is always in the defined range\n     */\n    private _assertRange;\n    /**\n     * Convert the given value from the type specified by Param.units\n     * into the destination value (such as Gain or Frequency).\n     */\n    protected _fromType(val: UnitMap[TypeName]): number;\n    /**\n     * Convert the parameters value into the units specified by Param.units.\n     */\n    protected _toType(val: number): UnitMap[TypeName];\n    setValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    getValueAtTime(time: Time): UnitMap[TypeName];\n    setRampPoint(time: Time): this;\n    linearRampToValueAtTime(value: UnitMap[TypeName], endTime: Time): this;\n    exponentialRampToValueAtTime(value: UnitMap[TypeName], endTime: Time): this;\n    exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;\n    setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: Positive): this;\n    setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;\n    cancelScheduledValues(time: Time): this;\n    cancelAndHoldAtTime(time: Time): this;\n    rampTo(value: UnitMap[TypeName], rampTime?: Time, startTime?: Time): this;\n    /**\n     * Apply all of the previously scheduled events to the passed in Param or AudioParam.\n     * The applied values will start at the context's current time and schedule\n     * all of the events which are scheduled on this Param onto the passed in param.\n     */\n    apply(param: Param | AudioParam): this;\n    /**\n     * Replace the Param's internal AudioParam. Will apply scheduled curves\n     * onto the parameter and replace the connections.\n     */\n    setParam(param: AudioParam): this;\n    dispose(): this;\n    get defaultValue(): UnitMap[TypeName];\n    protected _exponentialApproach(t0: number, v0: number, v1: number, timeConstant: number, t: number): number;\n    protected _linearInterpolate(t0: number, v0: number, t1: number, v1: number, t: number): number;\n    protected _exponentialInterpolate(t0: number, v0: number, t1: number, v1: number, t: number): number;\n}\nexport {};\n",
  "core/context/ToneAudioBuffer.d.ts": "import { Tone } from \"../Tone\";\nimport { Samples, Seconds } from \"../type/Units\";\ninterface ToneAudioBufferOptions {\n    url?: string | AudioBuffer | ToneAudioBuffer;\n    reverse: boolean;\n    onload: (buffer?: ToneAudioBuffer) => void;\n    onerror: (error: Error) => void;\n}\n/**\n * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all\n * classes that make requests for audio files such as Tone.Player,\n * Tone.Sampler and Tone.Convolver.\n * @example\n * const buffer = new Tone.ToneAudioBuffer(\"https://tonejs.github.io/audio/casio/A1.mp3\", () => {\n * \tconsole.log(\"loaded\");\n * });\n * @category Core\n */\nexport declare class ToneAudioBuffer extends Tone {\n    readonly name: string;\n    /**\n     * stores the loaded AudioBuffer\n     */\n    private _buffer?;\n    /**\n     * indicates if the buffer should be reversed or not\n     */\n    private _reversed;\n    /**\n     * Callback when the buffer is loaded.\n     */\n    onload: (buffer: ToneAudioBuffer) => void;\n    /**\n     *\n     * @param url The url to load, or the audio buffer to set.\n     * @param onload A callback which is invoked after the buffer is loaded.\n     *                           It's recommended to use `ToneAudioBuffer.on('load', callback)` instead\n     *                           since it will give you a callback when _all_ buffers are loaded.\n     * @param onerror The callback to invoke if there is an error\n     */\n    constructor(url?: string | ToneAudioBuffer | AudioBuffer, onload?: (buffer: ToneAudioBuffer) => void, onerror?: (error: Error) => void);\n    constructor(options?: Partial<ToneAudioBufferOptions>);\n    static getDefaults(): ToneAudioBufferOptions;\n    /**\n     * The sample rate of the AudioBuffer\n     */\n    get sampleRate(): number;\n    /**\n     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.\n     */\n    set(buffer: AudioBuffer | ToneAudioBuffer): this;\n    /**\n     * The audio buffer stored in the object.\n     */\n    get(): AudioBuffer | undefined;\n    /**\n     * Makes an fetch request for the selected url then decodes the file as an audio buffer.\n     * Invokes the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     * @returns A Promise which resolves with this ToneAudioBuffer\n     */\n    load(url: string): Promise<this>;\n    /**\n     * clean up\n     */\n    dispose(): this;\n    /**\n     * Set the audio buffer from the array.\n     * To create a multichannel AudioBuffer, pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     */\n    fromArray(array: Float32Array | Float32Array[]): this;\n    /**\n     * Sums multiple channels into 1 channel\n     * @param chanNum Optionally only copy a single channel from the array.\n     */\n    toMono(chanNum?: number): this;\n    /**\n     * Get the buffer as an array. Single channel buffers will return a 1-dimensional\n     * Float32Array, and multichannel buffers will return multidimensional arrays.\n     * @param channel Optionally only copy a single channel from the array.\n     */\n    toArray(channel?: number): Float32Array | Float32Array[];\n    /**\n     * Returns the Float32Array representing the PCM audio data for the specific channel.\n     * @param  channel  The channel number to return\n     * @return The audio as a TypedArray\n     */\n    getChannelData(channel: number): Float32Array;\n    /**\n     * Cut a subsection of the array and return a buffer of the\n     * subsection. Does not modify the original buffer\n     * @param start The time to start the slice\n     * @param end The end time to slice. If none is given will default to the end of the buffer\n     */\n    slice(start: Seconds, end?: Seconds): ToneAudioBuffer;\n    /**\n     * Reverse the buffer.\n     */\n    private _reverse;\n    /**\n     * If the buffer is loaded or not\n     */\n    get loaded(): boolean;\n    /**\n     * The duration of the buffer in seconds.\n     */\n    get duration(): Seconds;\n    /**\n     * The length of the buffer in samples\n     */\n    get length(): Samples;\n    /**\n     * The number of discrete audio channels. Returns 0 if no buffer is loaded.\n     */\n    get numberOfChannels(): number;\n    /**\n     * Reverse the buffer.\n     */\n    get reverse(): boolean;\n    set reverse(rev: boolean);\n    /**\n     * A path which is prefixed before every url.\n     */\n    static baseUrl: string;\n    /**\n     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,\n     * pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     * @return A ToneAudioBuffer created from the array\n     */\n    static fromArray(array: Float32Array | Float32Array[]): ToneAudioBuffer;\n    /**\n     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer\n     * @param  url The url to load.\n     * @return A promise which resolves to a ToneAudioBuffer\n     */\n    static fromUrl(url: string): Promise<ToneAudioBuffer>;\n    /**\n     * All of the downloads\n     */\n    static downloads: Array<Promise<void>>;\n    /**\n     * Loads a url using fetch and returns the AudioBuffer.\n     */\n    static load(url: string): Promise<AudioBuffer>;\n    /**\n     * Checks a url's extension to see if the current browser can play that file type.\n     * @param url The url/extension to test\n     * @return If the file extension can be played\n     * @static\n     * @example\n     * Tone.ToneAudioBuffer.supportsType(\"wav\"); // returns true\n     * Tone.ToneAudioBuffer.supportsType(\"path/to/file.wav\"); // returns true\n     */\n    static supportsType(url: string): boolean;\n    /**\n     * Returns a Promise which resolves when all of the buffers have loaded\n     */\n    static loaded(): Promise<void>;\n}\nexport {};\n",
  "core/context/ToneAudioBuffers.d.ts": "import { Tone } from \"../Tone\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\nexport interface ToneAudioBuffersUrlMap {\n    [name: string]: string | AudioBuffer | ToneAudioBuffer;\n    [name: number]: string | AudioBuffer | ToneAudioBuffer;\n}\ninterface ToneAudioBuffersOptions {\n    urls: ToneAudioBuffersUrlMap;\n    onload: () => void;\n    onerror?: (error: Error) => void;\n    baseUrl: string;\n}\n/**\n * A data structure for holding multiple buffers in a Map-like datastructure.\n *\n * @example\n * const pianoSamples = new Tone.ToneAudioBuffers({\n * \tA1: \"https://tonejs.github.io/audio/casio/A1.mp3\",\n * \tA2: \"https://tonejs.github.io/audio/casio/A2.mp3\",\n * }, () => {\n * \tconst player = new Tone.Player().toDestination();\n * \t// play one of the samples when they all load\n * \tplayer.buffer = pianoSamples.get(\"A2\");\n * \tplayer.start();\n * });\n * @example\n * // To pass in additional parameters in the second parameter\n * const buffers = new Tone.ToneAudioBuffers({\n * \t urls: {\n * \t\t A1: \"A1.mp3\",\n * \t\t A2: \"A2.mp3\",\n * \t },\n * \t onload: () => console.log(\"loaded\"),\n * \t baseUrl: \"https://tonejs.github.io/audio/casio/\"\n * });\n * @category Core\n */\nexport declare class ToneAudioBuffers extends Tone {\n    readonly name: string;\n    /**\n     * All of the buffers\n     */\n    private _buffers;\n    /**\n     * A path which is prefixed before every url.\n     */\n    baseUrl: string;\n    /**\n     * Keep track of the number of loaded buffers\n     */\n    private _loadingCount;\n    /**\n     * @param  urls  An object literal or array of urls to load.\n     * @param onload  The callback to invoke when the buffers are loaded.\n     * @param baseUrl A prefix url to add before all the urls\n     */\n    constructor(urls?: ToneAudioBuffersUrlMap, onload?: () => void, baseUrl?: string);\n    constructor(options?: Partial<ToneAudioBuffersOptions>);\n    static getDefaults(): ToneAudioBuffersOptions;\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param  name  The key or index of the buffer.\n     */\n    has(name: string | number): boolean;\n    /**\n     * Get a buffer by name. If an array was loaded,\n     * then use the array index.\n     * @param  name  The key or index of the buffer.\n     */\n    get(name: string | number): ToneAudioBuffer;\n    /**\n     * A buffer was loaded. decrement the counter.\n     */\n    private _bufferLoaded;\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded(): boolean;\n    /**\n     * Add a buffer by name and url to the Buffers\n     * @param  name      A unique name to give the buffer\n     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     * @param  onerror  Invoked if the buffer can't be loaded\n     */\n    add(name: string | number, url: string | AudioBuffer | ToneAudioBuffer, callback?: () => void, onerror?: (e: Error) => void): this;\n    dispose(): this;\n}\nexport {};\n",
  "core/context/ToneAudioNode.d.ts": "import { Param } from \"./Param\";\nimport { ToneWithContext, ToneWithContextOptions } from \"./ToneWithContext\";\nexport type InputNode = ToneAudioNode | AudioNode | Param<any> | AudioParam;\nexport type OutputNode = ToneAudioNode | AudioNode;\n/**\n * The possible options for this node\n */\nexport type ToneAudioNodeOptions = ToneWithContextOptions;\n/**\n * ToneAudioNode is the base class for classes which process audio.\n * @category Core\n */\nexport declare abstract class ToneAudioNode<Options extends ToneAudioNodeOptions = ToneAudioNodeOptions> extends ToneWithContext<Options> {\n    /**\n     * The name of the class\n     */\n    abstract readonly name: string;\n    /**\n     * The input node or nodes. If the object is a source,\n     * it does not have any input and this.input is undefined.\n     */\n    abstract input: InputNode | undefined;\n    /**\n     * The output nodes. If the object is a sink,\n     * it does not have any output and this.output is undefined.\n     */\n    abstract output: OutputNode | undefined;\n    /**\n     * The number of inputs feeding into the AudioNode.\n     * For source nodes, this will be 0.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfInputs);\n     */\n    get numberOfInputs(): number;\n    /**\n     * The number of outputs of the AudioNode.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfOutputs);\n     */\n    get numberOfOutputs(): number;\n    /**\n     * List all of the node that must be set to match the ChannelProperties\n     */\n    protected _internalChannels: OutputNode[];\n    /**\n     * Used to decide which nodes to get/set properties on\n     */\n    private _isAudioNode;\n    /**\n     * Get all of the audio nodes (either internal or input/output) which together\n     * make up how the class node responds to channel input/output\n     */\n    private _getInternalNodes;\n    /**\n     * Set the audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     * @param options\n     */\n    private _setChannelProperties;\n    /**\n     * Get the current audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     */\n    private _getChannelProperties;\n    /**\n     * channelCount is the number of channels used when up-mixing and down-mixing\n     * connections to any inputs to the node. The default value is 2 except for\n     * specific nodes where its value is specially determined.\n     */\n    get channelCount(): number;\n    set channelCount(channelCount: number);\n    /**\n     * channelCountMode determines how channels will be counted when up-mixing and\n     * down-mixing connections to any inputs to the node.\n     * The default value is \"max\". This attribute has no effect for nodes with no inputs.\n     * * \"max\" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.\n     * * \"clamped-max\" - computedNumberOfChannels is determined as for \"max\" and then clamped to a maximum value of the given channelCount.\n     * * \"explicit\" - computedNumberOfChannels is the exact value as specified by the channelCount.\n     */\n    get channelCountMode(): ChannelCountMode;\n    set channelCountMode(channelCountMode: ChannelCountMode);\n    /**\n     * channelInterpretation determines how individual channels will be treated\n     * when up-mixing and down-mixing connections to any inputs to the node.\n     * The default value is \"speakers\".\n     */\n    get channelInterpretation(): ChannelInterpretation;\n    set channelInterpretation(channelInterpretation: ChannelInterpretation);\n    /**\n     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode\n     * @param destination The output to connect to\n     * @param outputNum The output to connect from\n     * @param inputNum The input to connect to\n     */\n    connect(destination: InputNode, outputNum?: number, inputNum?: number): this;\n    /**\n     * Connect the output to the context's destination node.\n     * @example\n     * const osc = new Tone.Oscillator(\"C2\").start();\n     * osc.toDestination();\n     */\n    toDestination(): this;\n    /**\n     * Connect the output to the context's destination node.\n     * @see {@link toDestination}\n     * @deprecated\n     */\n    toMaster(): this;\n    /**\n     * disconnect the output\n     */\n    disconnect(destination?: InputNode, outputNum?: number, inputNum?: number): this;\n    /**\n     * Connect the output of this node to the rest of the nodes in series.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3\");\n     * player.autostart = true;\n     * const filter = new Tone.AutoFilter(4).start();\n     * const distortion = new Tone.Distortion(0.5);\n     * // connect the player to the filter, distortion and then to the master output\n     * player.chain(filter, distortion, Tone.Destination);\n     */\n    chain(...nodes: InputNode[]): this;\n    /**\n     * connect the output of this node to the rest of the nodes in parallel.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3\");\n     * player.autostart = true;\n     * const pitchShift = new Tone.PitchShift(4).toDestination();\n     * const filter = new Tone.Filter(\"G5\").toDestination();\n     * // connect a node to the pitch shift and filter in parallel\n     * player.fan(pitchShift, filter);\n     */\n    fan(...nodes: InputNode[]): this;\n    /**\n     * Dispose and disconnect\n     */\n    dispose(): this;\n}\n/**\n * connect together all of the arguments in series\n * @param nodes\n */\nexport declare function connectSeries(...nodes: InputNode[]): void;\n/**\n * Connect two nodes together so that signal flows from the\n * first node to the second. Optionally specify the input and output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nexport declare function connect(srcNode: OutputNode, dstNode: InputNode, outputNumber?: number, inputNumber?: number): void;\n/**\n * Disconnect a node from all nodes or optionally include a destination node and input/output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nexport declare function disconnect(srcNode: OutputNode, dstNode?: InputNode, outputNumber?: number, inputNumber?: number): void;\n/**\n * Connect the output of one or more source nodes to a single destination node\n * @param nodes One or more source nodes followed by one destination node\n * @example\n * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3\");\n * const player1 = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3\");\n * const filter = new Tone.Filter(\"G5\").toDestination();\n * // connect nodes to a common destination\n * Tone.fanIn(player, player1, filter);\n */\nexport declare function fanIn(...nodes: OutputNode[]): void;\n",
  "core/context/ToneWithContext.d.ts": "import { Tone } from \"../Tone\";\nimport { TimeClass } from \"../type/Time\";\nimport { Frequency, Hertz, Seconds, Ticks, Time } from \"../type/Units\";\nimport { RecursivePartial } from \"../util/Interface\";\nimport { BaseContext } from \"./BaseContext\";\n/**\n * A unit which process audio\n */\nexport interface ToneWithContextOptions {\n    context: BaseContext;\n}\n/**\n * The Base class for all nodes that have an AudioContext.\n */\nexport declare abstract class ToneWithContext<Options extends ToneWithContextOptions> extends Tone {\n    /**\n     * The context belonging to the node.\n     */\n    readonly context: BaseContext;\n    /**\n     * The default context to use if no AudioContext is passed in to the constructor.\n     * Probably should not be set manually. Used internally.\n     * @hidden\n     */\n    readonly defaultContext?: BaseContext;\n    /**\n     * Pass in a constructor as the first argument\n     */\n    constructor(context?: BaseContext);\n    constructor(options?: Partial<ToneWithContextOptions>);\n    static getDefaults(): ToneWithContextOptions;\n    /**\n     * Return the current time of the Context clock plus the lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.now());\n     * }, 100);\n     */\n    now(): Seconds;\n    /**\n     * Return the current time of the Context clock without any lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.immediate());\n     * }, 100);\n     */\n    immediate(): Seconds;\n    /**\n     * The duration in seconds of one sample.\n     */\n    get sampleTime(): Seconds;\n    /**\n     * The number of seconds of 1 processing block (128 samples)\n     * @example\n     * console.log(Tone.Destination.blockTime);\n     */\n    get blockTime(): Seconds;\n    /**\n     * Convert the incoming time to seconds.\n     * This is calculated against the current {@link TransportClass} bpm\n     * @example\n     * const gain = new Tone.Gain();\n     * setInterval(() => console.log(gain.toSeconds(\"4n\")), 100);\n     * // ramp the tempo to 60 bpm over 30 seconds\n     * Tone.getTransport().bpm.rampTo(60, 30);\n     */\n    toSeconds(time?: Time): Seconds;\n    /**\n     * Convert the input to a frequency number\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toFrequency(\"4n\"));\n     */\n    toFrequency(freq: Frequency): Hertz;\n    /**\n     * Convert the input time into ticks\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toTicks(\"4n\"));\n     */\n    toTicks(time?: Time | TimeClass): Ticks;\n    /**\n     * Get a subset of the properties which are in the partial props\n     */\n    protected _getPartialProperties(props: Options): Partial<Options>;\n    /**\n     * Get the object's attributes.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.get());\n     */\n    get(): Options;\n    /**\n     * Set multiple properties at once with an object.\n     * @example\n     * const filter = new Tone.Filter().toDestination();\n     * // set values using an object\n     * filter.set({\n     * \tfrequency: \"C6\",\n     * \ttype: \"highpass\"\n     * });\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3\").connect(filter);\n     * player.autostart = true;\n     */\n    set(props: RecursivePartial<Options>): this;\n}\n",
  "core/index.d.ts": "export * from \"./clock/Clock\";\nexport * from \"./context/Context\";\nexport * from \"./context/BaseContext\";\nexport * from \"./context/Delay\";\nexport * from \"./context/Gain\";\nexport * from \"./context/Offline\";\nexport * from \"./context/OfflineContext\";\nexport * from \"./context/Param\";\nexport * from \"./context/ToneAudioBuffer\";\nexport * from \"./context/ToneAudioBuffers\";\nexport * from \"./context/ToneAudioNode\";\nexport * from \"./type/Frequency\";\nexport * from \"./type/Midi\";\nexport * from \"./type/Time\";\nexport * from \"./type/Ticks\";\nexport * from \"./type/TransportTime\";\nimport  \"./util/Draw\";\nexport * from \"./util/Emitter\";\nexport * from \"./util/IntervalTimeline\";\nexport * from \"./util/StateTimeline\";\nexport * from \"./util/Timeline\";\nexport * from \"./util/TypeCheck\";\nexport { dbToGain, gainToDb, intervalToFrequencyRatio, ftom, mtof, } from \"./type/Conversions\";\nexport { optionsFromArguments, defaultArg } from \"./util/Defaults\";\nimport * as Unit from \"./type/Units\";\nexport { Unit };\nimport * as debug from \"./util/Debug\";\n/** @internal */\nexport { debug };\n",
  "core/type/Conversions.d.ts": "import { Decibels, GainFactor, Hertz, Interval, MidiNote, NormalRange } from \"./Units\";\n/**\n * Equal power gain scale. Good for cross-fading.\n * @param  percent (0-1)\n */\nexport declare function equalPowerScale(percent: NormalRange): number;\n/**\n * Convert decibels into gain.\n */\nexport declare function dbToGain(db: Decibels): GainFactor;\n/**\n * Convert gain to decibels.\n */\nexport declare function gainToDb(gain: GainFactor): Decibels;\n/**\n * Convert an interval (in semitones) to a frequency ratio.\n * @param interval the number of semitones above the base note\n * @example\n * Tone.intervalToFrequencyRatio(0); // 1\n * Tone.intervalToFrequencyRatio(12); // 2\n * Tone.intervalToFrequencyRatio(-12); // 0.5\n */\nexport declare function intervalToFrequencyRatio(interval: Interval): number;\nexport declare function getA4(): Hertz;\nexport declare function setA4(freq: Hertz): void;\n/**\n * Convert a frequency value to a MIDI note.\n * @param frequency The value to frequency value to convert.\n * @example\n * Tone.ftom(440); // returns 69\n */\nexport declare function ftom(frequency: Hertz): MidiNote;\n/**\n * Convert a frequency to a floating point midi value\n */\nexport declare function ftomf(frequency: Hertz): number;\n/**\n * Convert a MIDI note to frequency value.\n * @param  midi The midi number to convert.\n * @return The corresponding frequency value\n * @example\n * Tone.mtof(69); // 440\n */\nexport declare function mtof(midi: MidiNote): Hertz;\n",
  "core/type/Frequency.d.ts": "import { TimeClass } from \"./Time\";\nimport { TimeBaseUnit, TimeExpression, TimeValue } from \"./TimeBase\";\nimport { Frequency, Hertz, Interval, MidiNote, Note, Seconds, Ticks } from \"./Units\";\nexport type FrequencyUnit = TimeBaseUnit | \"midi\";\n/**\n * Frequency is a primitive type for encoding Frequency values.\n * Eventually all time values are evaluated to hertz using the `valueOf` method.\n * @example\n * Tone.Frequency(\"C3\"); // 261\n * Tone.Frequency(38, \"midi\");\n * Tone.Frequency(\"C3\").transpose(4);\n * @category Unit\n */\nexport declare class FrequencyClass<Type extends number = Hertz> extends TimeClass<Type, FrequencyUnit> {\n    readonly name: string;\n    readonly defaultUnits: FrequencyUnit;\n    /**\n     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n     * to generate all the other pitch values from notes. A4's values in Hertz.\n     */\n    static get A4(): Hertz;\n    static set A4(freq: Hertz);\n    protected _getExpressions(): TimeExpression<Type>;\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return  A new transposed frequency\n     * @example\n     * Tone.Frequency(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval: Interval): FrequencyClass;\n    /**\n     * Takes an array of semitone intervals and returns\n     * an array of frequencies transposed by those intervals.\n     * @return  Returns an array of Frequencies\n     * @example\n     * Tone.Frequency(\"A4\").harmonize([0, 3, 7]); // [\"A4\", \"C5\", \"E5\"]\n     */\n    harmonize(intervals: Interval[]): FrequencyClass[];\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Frequency(\"C4\").toMidi(); // 60\n     */\n    toMidi(): MidiNote;\n    /**\n     * Return the value of the frequency in Scientific Pitch Notation\n     * @example\n     * Tone.Frequency(69, \"midi\").toNote(); // \"A4\"\n     */\n    toNote(): Note;\n    /**\n     * Return the duration of one cycle in seconds.\n     */\n    toSeconds(): Seconds;\n    /**\n     * Return the duration of one cycle in ticks\n     */\n    toTicks(): Ticks;\n    /**\n     * With no arguments, return 0\n     */\n    protected _noArg(): Type;\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    protected _frequencyToUnits(freq: Hertz): Type;\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    protected _ticksToUnits(ticks: Ticks): Type;\n    /**\n     * Return the value of the beats in the current units\n     */\n    protected _beatsToUnits(beats: number): Type;\n    /**\n     * Returns the value of a second in the current units\n     */\n    protected _secondsToUnits(seconds: Seconds): Type;\n    /**\n     * Convert a MIDI note to frequency value.\n     * @param  midi The midi number to convert.\n     * @return The corresponding frequency value\n     */\n    static mtof(midi: MidiNote): Hertz;\n    /**\n     * Convert a frequency value to a MIDI note.\n     * @param frequency The value to frequency value to convert.\n     */\n    static ftom(frequency: Hertz): MidiNote;\n}\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n * @example\n * const midi = Tone.Frequency(\"C3\").toMidi();\n * console.log(midi);\n * @example\n * const hertz = Tone.Frequency(38, \"midi\").toFrequency();\n * console.log(hertz);\n */\nexport declare function Frequency(value?: TimeValue | Frequency, units?: FrequencyUnit): FrequencyClass;\n",
  "core/type/Midi.d.ts": "import { FrequencyClass, FrequencyUnit } from \"./Frequency\";\nimport { TimeValue } from \"./TimeBase\";\nimport { Hertz, Interval, MidiNote, Seconds, Ticks } from \"./Units\";\n/**\n * Midi is a primitive type for encoding Time values.\n * Midi can be constructed with or without the `new` keyword. Midi can be passed\n * into the parameter of any method which takes time as an argument.\n * @category Unit\n */\nexport declare class MidiClass extends FrequencyClass<MidiNote> {\n    readonly name: string;\n    readonly defaultUnits = \"midi\";\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    protected _frequencyToUnits(freq: Hertz): MidiNote;\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    protected _ticksToUnits(ticks: Ticks): MidiNote;\n    /**\n     * Return the value of the beats in the current units\n     */\n    protected _beatsToUnits(beats: number): MidiNote;\n    /**\n     * Returns the value of a second in the current units\n     */\n    protected _secondsToUnits(seconds: Seconds): MidiNote;\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toMidi(); // 60\n     */\n    toMidi(): MidiNote;\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toFrequency(); // 261.6255653005986\n     */\n    toFrequency(): Hertz;\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return A new transposed MidiClass\n     * @example\n     * Tone.Midi(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval: Interval): MidiClass;\n}\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n */\nexport declare function Midi(value?: TimeValue, units?: FrequencyUnit): MidiClass;\n",
  "core/type/NoteUnits.d.ts": "type Letter = \"C\" | \"D\" | \"E\" | \"F\" | \"G\" | \"A\" | \"B\";\ntype Accidental = \"bb\" | \"b\" | \"\" | \"#\" | \"x\";\ntype Octave = -4 | -3 | -2 | -1 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11;\n/**\n * A note in Scientific pitch notation.\n * The pitch class + octave number\n * e.g. \"C4\", \"D#3\", \"G-1\"\n * @category Unit\n */\nexport type Note = `${Letter}${Accidental}${Octave}`;\ntype IntegerRange<N extends number, A extends any[] = []> = A[\"length\"] extends N ? A[number] : IntegerRange<N, [...A, A[\"length\"]]>;\n/**\n * A number representing a midi note. Integers between 0-127\n * @category Unit\n */\nexport type MidiNote = IntegerRange<128>;\nexport {};\n",
  "core/type/Ticks.d.ts": "import { TimeBaseUnit, TimeValue } from \"./TimeBase\";\nimport { TransportTimeClass } from \"./TransportTime\";\nimport { Seconds, Ticks } from \"./Units\";\n/**\n * Ticks is a primitive type for encoding Time values.\n * Ticks can be constructed with or without the `new` keyword. Ticks can be passed\n * into the parameter of any method which takes time as an argument.\n * @example\n * const t = Tone.Ticks(\"4n\"); // a quarter note as ticks\n * @category Unit\n */\nexport declare class TicksClass extends TransportTimeClass<Ticks> {\n    readonly name: string;\n    readonly defaultUnits: TimeBaseUnit;\n    /**\n     * Get the current time in the given units\n     */\n    protected _now(): Ticks;\n    /**\n     * Return the value of the beats in the current units\n     */\n    protected _beatsToUnits(beats: number): Ticks;\n    /**\n     * Returns the value of a second in the current units\n     */\n    protected _secondsToUnits(seconds: Seconds): Ticks;\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    protected _ticksToUnits(ticks: Ticks): Ticks;\n    /**\n     * Return the time in ticks\n     */\n    toTicks(): Ticks;\n    /**\n     * Return the time in seconds\n     */\n    toSeconds(): Seconds;\n}\n/**\n * Convert a time representation to ticks\n * @category Unit\n */\nexport declare function Ticks(value?: TimeValue, units?: TimeBaseUnit): TicksClass;\n",
  "core/type/Time.d.ts": "import { TimeBaseClass, TimeBaseUnit, TimeExpression, TimeValue } from \"./TimeBase\";\nimport { BarsBeatsSixteenths, MidiNote, Seconds, Subdivision, Ticks, Time } from \"./Units\";\n/**\n * TimeClass is a primitive type for encoding and decoding Time values.\n * TimeClass can be passed into the parameter of any method which takes time as an argument.\n * @param  val    The time value.\n * @param  units  The units of the value.\n * @example\n * const time = Tone.Time(\"4n\"); // a quarter note\n * @category Unit\n */\nexport declare class TimeClass<Type extends Seconds | Ticks = Seconds, Unit extends string = TimeBaseUnit> extends TimeBaseClass<Type, Unit> {\n    readonly name: string;\n    protected _getExpressions(): TimeExpression<Type>;\n    /**\n     * Quantize the time by the given subdivision. Optionally add a\n     * percentage which will move the time value towards the ideal\n     * quantized value by that percentage.\n     * @param  subdiv    The subdivision to quantize to\n     * @param  percent  Move the time value towards the quantized value by a percentage.\n     * @example\n     * Tone.Time(21).quantize(2); // returns 22\n     * Tone.Time(0.6).quantize(\"4n\", 0.5); // returns 0.55\n     */\n    quantize(subdiv: Time, percent?: number): Type;\n    /**\n     * Convert a Time to Notation. The notation values are will be the\n     * closest representation between 1m to 128th note.\n     * @return {Notation}\n     * @example\n     * // if the Transport is at 120bpm:\n     * Tone.Time(2).toNotation(); // returns \"1m\"\n     */\n    toNotation(): Subdivision;\n    /**\n     * Return the time encoded as Bars:Beats:Sixteenths.\n     */\n    toBarsBeatsSixteenths(): BarsBeatsSixteenths;\n    /**\n     * Return the time in ticks.\n     */\n    toTicks(): Ticks;\n    /**\n     * Return the time in seconds.\n     */\n    toSeconds(): Seconds;\n    /**\n     * Return the value as a midi note.\n     */\n    toMidi(): MidiNote;\n    protected _now(): Type;\n}\n/**\n * Create a TimeClass from a time string or number. The time is computed against the\n * global Tone.Context. To use a specific context, use {@link TimeClass}\n * @param value A value which represents time\n * @param units The value's units if they can't be inferred by the value.\n * @category Unit\n * @example\n * const time = Tone.Time(\"4n\").toSeconds();\n * console.log(time);\n * @example\n * const note = Tone.Time(1).toNotation();\n * console.log(note);\n * @example\n * const freq = Tone.Time(0.5).toFrequency();\n * console.log(freq);\n */\nexport declare function Time(value?: TimeValue, units?: TimeBaseUnit): TimeClass<Seconds>;\n",
  "core/type/TimeBase.d.ts": "import { BaseContext } from \"../context/BaseContext\";\nimport { Tone } from \"../Tone\";\nimport { BPM, Hertz, MidiNote, Milliseconds, Samples, Seconds, Ticks, Time } from \"./Units\";\nexport type TimeValue = Time | TimeBaseClass<any, any>;\n/**\n * The units that the TimeBase can accept. extended by other classes\n */\nexport type TimeBaseUnit = \"s\" | \"n\" | \"t\" | \"m\" | \"i\" | \"hz\" | \"tr\" | \"samples\" | \"number\";\nexport interface TypeFunction {\n    regexp: RegExp;\n    method: (value: string, ...args: string[]) => number;\n}\nexport interface TimeExpression<Type extends number> {\n    [key: string]: {\n        regexp: RegExp;\n        method: (value: string, ...args: string[]) => Type;\n    };\n}\n/**\n * TimeBase is a flexible encoding of time which can be evaluated to and from a string.\n */\nexport declare abstract class TimeBaseClass<Type extends number, Unit extends string> extends Tone {\n    readonly context: BaseContext;\n    /**\n     * The value of the units\n     */\n    protected _val?: TimeValue;\n    /**\n     * The units of time\n     */\n    protected _units?: Unit;\n    /**\n     * All of the conversion expressions\n     */\n    protected _expressions: TimeExpression<Type>;\n    /**\n     * The default units\n     */\n    readonly defaultUnits: Unit;\n    /**\n     * @param context The context associated with the time value. Used to compute\n     * Transport and context-relative timing.\n     * @param  value  The time value as a number, string or object\n     * @param  units  Unit values\n     */\n    constructor(context: BaseContext, value?: TimeValue, units?: Unit);\n    /**\n     * All of the time encoding expressions\n     */\n    protected _getExpressions(): TimeExpression<Type>;\n    /**\n     * Evaluate the time value. Returns the time in seconds.\n     */\n    valueOf(): Type;\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    protected _frequencyToUnits(freq: Hertz): Type;\n    /**\n     * Return the value of the beats in the current units\n     */\n    protected _beatsToUnits(beats: number): Type;\n    /**\n     * Returns the value of a second in the current units\n     */\n    protected _secondsToUnits(seconds: Seconds): Type;\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    protected _ticksToUnits(ticks: Ticks): Type;\n    /**\n     * With no arguments, return 'now'\n     */\n    protected _noArg(): Type;\n    /**\n     * Return the bpm\n     */\n    protected _getBpm(): BPM;\n    /**\n     * Return the timeSignature\n     */\n    protected _getTimeSignature(): number;\n    /**\n     * Return the PPQ or 192 if Transport is not available\n     */\n    protected _getPPQ(): number;\n    /**\n     * Return the current time in whichever context is relevant\n     */\n    protected abstract _now(): Type;\n    /**\n     * Coerce a time type into this units type.\n     * @param type Any time type units\n     */\n    fromType(type: TimeBaseClass<any, any>): this;\n    /**\n     * Return the value in seconds\n     */\n    abstract toSeconds(): Seconds;\n    /**\n     * Return the value as a Midi note\n     */\n    abstract toMidi(): MidiNote;\n    /**\n     * Convert the value into ticks\n     */\n    abstract toTicks(): Ticks;\n    /**\n     * Return the value in hertz\n     */\n    toFrequency(): Hertz;\n    /**\n     * Return the time in samples\n     */\n    toSamples(): Samples;\n    /**\n     * Return the time in milliseconds.\n     */\n    toMilliseconds(): Milliseconds;\n}\n",
  "core/type/TransportTime.d.ts": "import { Seconds, Ticks } from \"../type/Units\";\nimport { TimeClass } from \"./Time\";\nimport { TimeBaseUnit, TimeValue } from \"./TimeBase\";\n/**\n * TransportTime is a time along the Transport's\n * timeline. It is similar to Tone.Time, but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nexport declare class TransportTimeClass<Type extends Seconds | Ticks = Seconds> extends TimeClass<Type> {\n    readonly name: string;\n    /**\n     * Return the current time in whichever context is relevant\n     */\n    protected _now(): Type;\n}\n/**\n * TransportTime is a time along the Transport's\n * timeline. It is similar to Tone.Time, but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nexport declare function TransportTime(value?: TimeValue, units?: TimeBaseUnit): TransportTimeClass;\n",
  "core/type/Units.d.ts": "export * from \"./NoteUnits\";\nimport { Note } from \"./NoteUnits\";\n/**\n * A number representing a time in seconds\n * @category Unit\n */\nexport type Seconds = number;\n/**\n * A number used to measure the intensity of a sound on a logarithmic scale.\n * @category Unit\n */\nexport type Decibels = number;\n/**\n * A number that is between [0, 1]\n * @category Unit\n */\nexport type NormalRange = number;\n/**\n * A number that is between [-1, 1]\n * @category Unit\n */\nexport type AudioRange = number;\n/**\n * Half-step note increments, i.e. 12 is an octave above the root. and 1 is a half-step up.\n * @category Unit\n */\nexport type Interval = number;\n/**\n * A number representing the multiplication factor applied to a signal\n * @category Unit\n */\nexport type GainFactor = number;\n/**\n * A number greater than or equal to 0.\n * @category Unit\n */\nexport type Positive = number;\n/**\n * Represents a subdivision of a measure.\n * The number represents the subdivision. \"t\" represents a triplet. A \".\" add a half.\n * e.g. \"4n\" is a quarter note, \"4t\" is a quarter note triplet, and \"4n.\" is a dotted quarter note.\n * @category Unit\n */\nexport type Subdivision = \"1m\" | \"1n\" | \"1n.\" | `${2 | 4 | 8 | 16 | 32 | 64 | 128 | 256}${\"n\" | \"n.\" | \"t\"}` | \"0\";\n/**\n * A time object has a subdivision as the keys and a number as the values.\n * @example\n * Tone.Time({\n * \t\"2n\": 1,\n * \t\"8n\": 3\n * }).valueOf(); // 2n + 8n * 3\n * @category Unit\n */\nexport type TimeObject = {\n    [sub in Subdivision]?: number;\n};\n/**\n * Time can be described in a number of ways. Read more [Time](https://github.com/Tonejs/Tone.js/wiki/Time).\n * * Numbers, which will be taken literally as the time (in seconds).\n * * Notation, (\"4n\", \"8t\") describes time in BPM and time signature relative values.\n * * TransportTime, (\"4:3:2\") will also provide tempo and time signature relative times in the form BARS:QUARTERS:SIXTEENTHS.\n * * Frequency, (\"8hz\") is converted to the length of the cycle in seconds.\n * * Now-Relative, (\"+1\") prefix any of the above with \"+\" and it will be interpreted as \"the current time plus whatever expression follows\".\n * * Object, ({\"4n\" : 3, \"8t\" : -1}). The resulting time is equal to the sum of all of the keys multiplied by the values in the object.\n * * No Argument, for methods which accept time, no argument will be interpreted as \"now\" (i.e. the currentTime).\n * @category Unit\n */\nexport type Time = string | Seconds | TimeObject | Subdivision;\n/**\n * Frequency can be described similar to time, except ultimately the\n * values are converted to frequency instead of seconds. A number\n * is taken literally as the value in hertz. Additionally any of the\n * Time encodings can be used. Note names in the form\n * of NOTE OCTAVE (i.e. C4) are also accepted and converted to their\n * frequency value.\n * @category Unit\n */\nexport type Frequency = Subdivision | Note | string | Hertz;\n/**\n *\n * @category Unit\n */\nexport type TimeSignature = number | number[];\n/**\n * TransportTime describes a position along the Transport's timeline. It is\n * similar to Time in that it uses all the same encodings, but TransportTime specifically\n * pertains to the Transport's timeline, which is startable, stoppable, loopable, and seekable.\n * [Read more](https://github.com/Tonejs/Tone.js/wiki/TransportTime)\n * @category Unit\n */\nexport type TransportTime = Time;\n/**\n * Ticks are the basic subunit of the Transport. They are\n * the smallest unit of time that the Transport supports.\n * @category Unit\n */\nexport type Ticks = number;\n/**\n * Beats per minute\n * @category Unit\n */\nexport type BPM = number;\n/**\n * Angle between 0 and 360.\n * @category Unit\n */\nexport type Degrees = number;\n/**\n * Angle between 0 and 2 * PI.\n * @category Unit\n */\nexport type Radians = number;\n/**\n * A colon-separated representation of time in the form of\n * Bars:Beats:Sixteenths.\n * @category Unit\n */\nexport type BarsBeatsSixteenths = `${number}:${number}:${number}`;\n/**\n * Sampling is the reduction of a continuous signal to a discrete signal.\n * Audio is typically sampled 44100 times per second.\n * @category Unit\n */\nexport type Samples = number;\n/**\n * Hertz are a frequency representation defined as one cycle per second.\n * @category Unit\n */\nexport type Hertz = number;\n/**\n * A Cent is 1/100th of a semitone.\n * e.g. a value of 50 cents would be halfway between two intervals.\n * @category Unit\n */\nexport type Cents = number;\n/**\n * One millisecond is a thousandth of a second.\n * @category Unit\n */\nexport type Milliseconds = number;\n/**\n * A value which is a power of 2\n * @category Unit\n */\nexport type PowerOfTwo = number;\n/**\n * Map the unit name to a unit value\n */\nexport interface UnitMap {\n    number: number;\n    decibels: Decibels;\n    normalRange: NormalRange;\n    audioRange: AudioRange;\n    gain: GainFactor;\n    positive: Positive;\n    time: Time;\n    frequency: Frequency;\n    transportTime: TransportTime;\n    ticks: Ticks;\n    bpm: BPM;\n    degrees: Degrees;\n    radians: Radians;\n    samples: Samples;\n    hertz: Hertz;\n    cents: Cents;\n}\n/**\n * All of the unit types\n * @category Unit\n */\nexport type Unit = UnitMap[keyof UnitMap];\n/**\n * All of the unit names\n * @category Unit\n */\nexport type UnitName = keyof UnitMap;\n",
  "core/util/AdvancedTypeCheck.d.ts": "import { AudioBuffer } from \"standardized-audio-context\";\n/**\n * Test if the given value is an instanceof AudioParam\n */\nexport declare function isAudioParam(arg: any): arg is AudioParam;\n/**\n * Test if the given value is an instanceof AudioNode\n */\nexport declare function isAudioNode(arg: any): arg is AudioNode;\n/**\n * Test if the arg is instanceof an OfflineAudioContext\n */\nexport declare function isOfflineAudioContext(arg: any): arg is OfflineAudioContext;\n/**\n * Test if the arg is an instanceof AudioContext\n */\nexport declare function isAudioContext(arg: any): arg is AudioContext;\n/**\n * Test if the arg is instanceof an AudioBuffer\n */\nexport declare function isAudioBuffer(arg: any): arg is AudioBuffer;\n",
  "core/util/Debug.d.ts": "import type { BaseContext } from \"../context/BaseContext\";\nimport type { Time } from \"../type/Units\";\n/**\n * Assert that the statement is true, otherwise invoke the error.\n * @param statement\n * @param error The message which is passed into an Error\n */\nexport declare function assert(statement: boolean, error: string): asserts statement;\n/**\n * Make sure that the given value is within the range\n */\nexport declare function assertRange(value: number, gte: number, lte?: number): void;\n/**\n * Warn if the context is not running.\n */\nexport declare function assertContextRunning(context: BaseContext): void;\n/**\n * Notify that the following block of code is occurring inside a Transport callback.\n */\nexport declare function enterScheduledCallback(insideCallback: boolean): void;\n/**\n * Make sure that a time was passed into\n */\nexport declare function assertUsedScheduleTime(time?: Time): void;\n/**\n * A basic logging interface\n */\ninterface Logger {\n    log: (args?: any[]) => void;\n    warn: (args?: any[]) => void;\n}\n/**\n * Set the logging interface\n */\nexport declare function setLogger(logger: Logger): void;\n/**\n * Log anything\n */\nexport declare function log(...args: any[]): void;\n/**\n * Warn anything\n */\nexport declare function warn(...args: any[]): void;\nexport {};\n",
  "core/util/Decorator.d.ts": "/**\n * Assert that the number is in the given range.\n */\nexport declare function range(min: number, max?: number): (target: any, propertyKey: string | symbol) => void;\n/**\n * Convert the time to seconds and assert that the time is in between the two\n * values when being set.\n */\nexport declare function timeRange(min: number, max?: number): (target: any, propertyKey: string) => void;\n",
  "core/util/Defaults.d.ts": "import type { BaseToneOptions } from \"../Tone\";\nexport declare function deepMerge<T>(target: T): T;\nexport declare function deepMerge<T, U>(target: T, source1: U): T & U;\nexport declare function deepMerge<T, U, V>(target: T, source1: U, source2: V): T & U & V;\nexport declare function deepMerge<T, U, V, W>(target: T, source1: U, source2: V, source3: W): T & U & V & W;\n/**\n * Returns true if the two arrays have the same value for each of the elements\n */\nexport declare function deepEquals<T>(arrayA: T[], arrayB: T[]): boolean;\n/**\n * Convert an args array into an object.\n * @internal\n */\nexport declare function optionsFromArguments<T extends object>(defaults: T, argsArray: IArguments, keys?: Array<keyof T>, objKey?: keyof T): T;\n/**\n * Return this instances default values by calling Constructor.getDefaults()\n */\nexport declare function getDefaultsFromInstance<T>(instance: T): BaseToneOptions;\n/**\n * Returns the fallback if the given object is undefined.\n * Take an array of arguments and return a formatted options object.\n * @internal\n */\nexport declare function defaultArg<T>(given: T, fallback: T): T;\n/**\n * Remove all of the properties belonging to omit from obj.\n */\nexport declare function omitFromObject<T extends object, O extends string[]>(obj: T, omit: O): Omit<T, keyof O>;\n",
  "core/util/Draw.d.ts": "import { ToneWithContext, ToneWithContextOptions } from \"../context/ToneWithContext\";\nimport { Seconds, Time } from \"../type/Units\";\n/**\n * Draw is useful for synchronizing visuals and audio events.\n * Callbacks from Tone.Transport or any of the Tone.Event classes\n * always happen _before_ the scheduled time and are not synchronized\n * to the animation frame so they are not good for triggering tightly\n * synchronized visuals and sound. Draw makes it easy to schedule\n * callbacks using the AudioContext time and uses requestAnimationFrame.\n * @example\n * Tone.Transport.schedule((time) => {\n * \t// use the time argument to schedule a callback with Draw\n * \tTone.Draw.schedule(() => {\n * \t\t// do drawing or DOM manipulation here\n * \t\tconsole.log(time);\n * \t}, time);\n * }, \"+0.5\");\n * Tone.Transport.start();\n * @category Core\n */\nexport declare class DrawClass extends ToneWithContext<ToneWithContextOptions> {\n    readonly name: string;\n    /**\n     * The duration after which events are not invoked.\n     */\n    expiration: Seconds;\n    /**\n     * The amount of time before the scheduled time\n     * that the callback can be invoked. Default is\n     * half the time of an animation frame (0.008 seconds).\n     */\n    anticipation: Seconds;\n    /**\n     * All of the events.\n     */\n    private _events;\n    /**\n     * The draw loop\n     */\n    private _boundDrawLoop;\n    /**\n     * The animation frame id\n     */\n    private _animationFrame;\n    /**\n     * Schedule a function at the given time to be invoked\n     * on the nearest animation frame.\n     * @param  callback  Callback is invoked at the given time.\n     * @param  time      The time relative to the AudioContext time to invoke the callback.\n     * @example\n     * Tone.Transport.scheduleRepeat(time => {\n     * \tTone.Draw.schedule(() => console.log(time), time);\n     * }, 1);\n     * Tone.Transport.start();\n     */\n    schedule(callback: () => void, time: Time): this;\n    /**\n     * Cancel events scheduled after the given time\n     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.\n     */\n    cancel(after?: Time): this;\n    /**\n     * The draw loop\n     */\n    private _drawLoop;\n    dispose(): this;\n}\n",
  "core/util/Emitter.d.ts": "import { Tone } from \"../Tone\";\nexport interface EmitterEventObject {\n    [event: string]: Array<(...args: any[]) => void>;\n}\n/**\n * Emitter gives classes which extend it\n * the ability to listen for and emit events.\n * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n * MIT (c) 2011 Jerome Etienne.\n * @category Core\n */\nexport declare class Emitter<EventType extends string = string> extends Tone {\n    readonly name: string;\n    /**\n     * Private container for the events\n     */\n    private _events?;\n    /**\n     * Bind a callback to a specific event.\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    on(event: EventType, callback: (...args: any[]) => void): this;\n    /**\n     * Bind a callback which is only invoked once\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    once(event: EventType, callback: (...args: any[]) => void): this;\n    /**\n     * Remove the event listener.\n     * @param  event     The event to stop listening to.\n     * @param  callback  The callback which was bound to the event with Emitter.on.\n     *                   If no callback is given, all callbacks events are removed.\n     */\n    off(event: EventType, callback?: (...args: any[]) => void): this;\n    /**\n     * Invoke all of the callbacks bound to the event\n     * with any arguments passed in.\n     * @param  event  The name of the event.\n     * @param args The arguments to pass to the functions listening.\n     */\n    emit(event: EventType, ...args: any[]): this;\n    /**\n     * Add Emitter functions (on/off/emit) to the object\n     */\n    static mixin(constr: any): void;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\n",
  "core/util/Interface.d.ts": "export type Omit<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;\n/**\n * Make the property not writable using `defineProperty`. Internal use only.\n */\nexport declare function readOnly(target: object, property: string | string[]): void;\n/**\n * Make an attribute writeable. Internal use only.\n */\nexport declare function writable(target: object, property: string | string[]): void;\nexport declare const noOp: (...args: any[]) => any;\n/**\n * Recursive Partial taken from here: https://stackoverflow.com/a/51365037\n */\nexport type RecursivePartial<T> = {\n    [P in keyof T]?: T[P] extends Array<infer U> ? Array<RecursivePartial<U>> : T[P] extends object ? RecursivePartial<T[P]> : T[P];\n};\n",
  "core/util/IntervalTimeline.d.ts": "import { Tone } from \"../Tone\";\n/**\n * An IntervalTimeline event must have a time and duration\n */\nexport interface IntervalTimelineEvent {\n    time: number;\n    duration: number;\n    [propName: string]: any;\n}\ntype IteratorCallback = (event: IntervalTimelineEvent) => void;\n/**\n * Similar to Tone.Timeline, but all events represent\n * intervals with both \"time\" and \"duration\" times. The\n * events are placed in a tree structure optimized\n * for querying an intersection point with the timeline\n * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n * to represent the data.\n * @internal\n */\nexport declare class IntervalTimeline extends Tone {\n    readonly name: string;\n    /**\n     * The root node of the inteval tree\n     */\n    private _root;\n    /**\n     * Keep track of the length of the timeline.\n     */\n    private _length;\n    /**\n     * The event to add to the timeline. All events must\n     * have a time and duration value\n     * @param  event  The event to add to the timeline\n     */\n    add(event: IntervalTimelineEvent): this;\n    /**\n     * Remove an event from the timeline.\n     * @param  event  The event to remove from the timeline\n     */\n    remove(event: IntervalTimelineEvent): this;\n    /**\n     * The number of items in the timeline.\n     * @readOnly\n     */\n    get length(): number;\n    /**\n     * Remove events whose time time is after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after: number): this;\n    /**\n     * Set the root node as the given node\n     */\n    private _setRoot;\n    /**\n     * Replace the references to the node in the node's parent\n     * with the replacement node.\n     */\n    private _replaceNodeInParent;\n    /**\n     * Remove the node from the tree and replace it with\n     * a successor which follows the schema.\n     */\n    private _removeNode;\n    /**\n     * Rotate the tree to the left\n     */\n    private _rotateLeft;\n    /**\n     * Rotate the tree to the right\n     */\n    private _rotateRight;\n    /**\n     * Balance the BST\n     */\n    private _rebalance;\n    /**\n     * Get an event whose time and duration span the give time. Will\n     * return the match whose \"time\" value is closest to the given time.\n     * @return  The event which spans the desired time\n     */\n    get(time: number): IntervalTimelineEvent | null;\n    /**\n     * Iterate over everything in the timeline.\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback: IteratorCallback): this;\n    /**\n     * Iterate over everything in the array in which the given time\n     * overlaps with the time and duration time of the event.\n     * @param  time The time to check if items are overlapping\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time: number, callback: IteratorCallback): this;\n    /**\n     * Iterate over everything in the array in which the time is greater\n     * than or equal to the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time: number, callback: IteratorCallback): this;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/util/Math.d.ts": "/**\n * Test if A is greater than B\n */\nexport declare function GT(a: number, b: number): boolean;\n/**\n * Test if A is greater than or equal to B\n */\nexport declare function GTE(a: number, b: number): boolean;\n/**\n * Test if A is less than B\n */\nexport declare function LT(a: number, b: number): boolean;\n/**\n * Test if A is less than B\n */\nexport declare function EQ(a: number, b: number): boolean;\n/**\n * Clamp the value within the given range\n */\nexport declare function clamp(value: number, min: number, max: number): number;\n",
  "core/util/StateTimeline.d.ts": "import { Seconds } from \"../type/Units\";\nimport { Timeline, TimelineEvent } from \"./Timeline\";\nexport type BasicPlaybackState = \"started\" | \"stopped\";\nexport type PlaybackState = BasicPlaybackState | \"paused\";\nexport interface StateTimelineEvent extends TimelineEvent {\n    state: PlaybackState;\n}\n/**\n * A Timeline State. Provides the methods: `setStateAtTime(\"state\", time)` and `getValueAtTime(time)`\n * @param initial The initial state of the StateTimeline.  Defaults to `undefined`\n * @internal\n */\nexport declare class StateTimeline<AdditionalOptions extends Record<string, any> = Record<string, any>> extends Timeline<StateTimelineEvent & AdditionalOptions> {\n    readonly name: string;\n    /**\n     * The initial state\n     */\n    private _initial;\n    constructor(initial?: PlaybackState);\n    /**\n     * Returns the scheduled state scheduled before or at\n     * the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     */\n    getValueAtTime(time: Seconds): PlaybackState;\n    /**\n     * Add a state to the timeline.\n     * @param  state The name of the state to set.\n     * @param  time  The time to query.\n     * @param options Any additional options that are needed in the timeline.\n     */\n    setStateAtTime(state: PlaybackState, time: Seconds, options?: AdditionalOptions): this;\n    /**\n     * Return the event before the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check before\n     * @return  The event with the given state before the time\n     */\n    getLastState(state: PlaybackState, time: number): (StateTimelineEvent & AdditionalOptions) | undefined;\n    /**\n     * Return the event after the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check from\n     * @return  The event with the given state after the time\n     */\n    getNextState(state: PlaybackState, time: number): (StateTimelineEvent & AdditionalOptions) | undefined;\n}\n",
  "core/util/Timeline.d.ts": "import { Tone } from \"../Tone\";\nimport { Seconds } from \"../type/Units\";\ntype TimelineSearchParam = \"ticks\" | \"time\";\n/**\n * The options object for Timeline\n */\ninterface TimelineOptions {\n    memory: number;\n    increasing: boolean;\n}\n/**\n * An event must have a time number\n */\nexport interface TimelineEvent {\n    time: number;\n}\n/**\n * A Timeline class for scheduling and maintaining state\n * along a timeline. All events must have a \"time\" property.\n * Internally, events are stored in time order for fast\n * retrieval.\n * @internal\n */\nexport declare class Timeline<GenericEvent extends TimelineEvent> extends Tone {\n    readonly name: string;\n    /**\n     * The memory of the timeline, i.e.\n     * how many events in the past it will retain\n     */\n    memory: number;\n    /**\n     * The array of scheduled timeline events\n     */\n    protected _timeline: GenericEvent[];\n    /**\n     * If the time value must always be greater than or equal to the last\n     * element on the list.\n     */\n    increasing: boolean;\n    /**\n     * @param memory The number of previous events that are retained.\n     */\n    constructor(memory?: number);\n    constructor(options?: Partial<TimelineOptions>);\n    static getDefaults(): TimelineOptions;\n    /**\n     * The number of items in the timeline.\n     */\n    get length(): number;\n    /**\n     * Insert an event object onto the timeline. Events must have a \"time\" attribute.\n     * @param event  The event object to insert into the timeline.\n     */\n    add(event: GenericEvent): this;\n    /**\n     * Remove an event from the timeline.\n     * @param  {Object}  event  The event object to remove from the list.\n     * @returns {Timeline} this\n     */\n    remove(event: GenericEvent): this;\n    /**\n     * Get the nearest event whose time is less than or equal to the given time.\n     * @param  time  The time to query.\n     */\n    get(time: number, param?: TimelineSearchParam): GenericEvent | null;\n    /**\n     * Return the first event in the timeline without removing it\n     * @returns {Object} The first event object\n     * @deprecated\n     */\n    peek(): GenericEvent | undefined;\n    /**\n     * Return the first event in the timeline and remove it\n     * @deprecated\n     */\n    shift(): GenericEvent | undefined;\n    /**\n     * Get the event which is scheduled after the given time.\n     * @param  time  The time to query.\n     */\n    getAfter(time: number, param?: TimelineSearchParam): GenericEvent | null;\n    /**\n     * Get the event before the event at the given time.\n     * @param  time  The time to query.\n     */\n    getBefore(time: number): GenericEvent | null;\n    /**\n     * Cancel events at and after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after: number): this;\n    /**\n     * Cancel events before or equal to the given time.\n     * @param  time  The time to cancel before.\n     */\n    cancelBefore(time: number): this;\n    /**\n     * Returns the previous event if there is one. null otherwise\n     * @param  event The event to find the previous one of\n     * @return The event right before the given event\n     */\n    previousEvent(event: GenericEvent): GenericEvent | null;\n    /**\n     * Does a binary search on the timeline array and returns the\n     * nearest event index whose time is after or equal to the given time.\n     * If a time is searched before the first index in the timeline, -1 is returned.\n     * If the time is after the end, the index of the last item is returned.\n     */\n    protected _search(time: number, param?: TimelineSearchParam): number;\n    /**\n     * Internal iterator. Applies extra safety checks for\n     * removing items from the array.\n     */\n    private _iterate;\n    /**\n     * Iterate over everything in the array\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback: (event: GenericEvent) => void): this;\n    /**\n     * Iterate over everything in the array at or before the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBefore(time: Seconds, callback: (event: GenericEvent) => void): this;\n    /**\n     * Iterate over everything in the array after the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAfter(time: Seconds, callback: (event: GenericEvent) => void): this;\n    /**\n     * Iterate over everything in the array between the startTime and endTime.\n     * The timerange is inclusive of the startTime, but exclusive of the endTime.\n     * range = [startTime, endTime).\n     * @param  startTime The time to check if items are before\n     * @param  endTime The end of the test interval.\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBetween(startTime: number, endTime: number, callback: (event: GenericEvent) => void): this;\n    /**\n     * Iterate over everything in the array at or after the given time. Similar to\n     * forEachAfter, but includes the item(s) at the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time: number, callback: (event: GenericEvent) => void): this;\n    /**\n     * Iterate over everything in the array at the given time\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time: number, callback: (event: GenericEvent) => void): this;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "core/util/TimelineValue.d.ts": "import { Tone } from \"../Tone\";\nimport { Seconds } from \"../type/Units\";\n/**\n * Represents a single value which is gettable and settable in a timed way\n */\nexport declare class TimelineValue<Type> extends Tone {\n    readonly name: string;\n    /**\n     * The timeline which stores the values\n     */\n    private _timeline;\n    /**\n     * Hold the value to return if there is no scheduled values\n     */\n    private _initialValue;\n    /**\n     * @param initialValue The value to return if there is no scheduled values\n     */\n    constructor(initialValue: Type);\n    /**\n     * Set the value at the given time\n     */\n    set(value: Type, time: Seconds): this;\n    /**\n     * Get the value at the given time\n     */\n    get(time: Seconds): Type;\n}\n",
  "core/util/TypeCheck.d.ts": "import { Note } from \"../type/Units\";\n/**\n * Test if the arg is undefined\n */\nexport declare function isUndef(arg: any): arg is undefined;\n/**\n * Test if the arg is not undefined\n */\nexport declare function isDefined<T>(arg: T | undefined): arg is T;\n/**\n * Test if the arg is a function\n */\nexport declare function isFunction(arg: any): arg is (a: any) => any;\n/**\n * Test if the argument is a number.\n */\nexport declare function isNumber(arg: any): arg is number;\n/**\n * Test if the given argument is an object literal (i.e. `{}`);\n */\nexport declare function isObject(arg: any): arg is object;\n/**\n * Test if the argument is a boolean.\n */\nexport declare function isBoolean(arg: any): arg is boolean;\n/**\n * Test if the argument is an Array\n */\nexport declare function isArray(arg: any): arg is any[];\n/**\n * Test if the argument is a string.\n */\nexport declare function isString(arg: any): arg is string;\n/**\n * Test if the argument is in the form of a note in scientific pitch notation.\n * e.g. \"C4\"\n */\nexport declare function isNote(arg: any): arg is Note;\n",
  "core/worklet/DelayLine.worklet.d.ts": "export {};\n",
  "core/worklet/SingleIOProcessor.worklet.d.ts": "import  \"./ToneAudioWorkletProcessor.worklet\";\nexport declare const singleIOProcess = \"\\n\\t/**\\n\\t * Abstract class for a single input/output processor. \\n\\t * has a 'generate' function which processes one sample at a time\\n\\t */\\n\\tclass SingleIOProcessor extends ToneAudioWorkletProcessor {\\n\\n\\t\\tconstructor(options) {\\n\\t\\t\\tsuper(Object.assign(options, {\\n\\t\\t\\t\\tnumberOfInputs: 1,\\n\\t\\t\\t\\tnumberOfOutputs: 1\\n\\t\\t\\t}));\\n\\t\\t\\t/**\\n\\t\\t\\t * Holds the name of the parameter and a single value of that\\n\\t\\t\\t * parameter at the current sample\\n\\t\\t\\t * @type { [name: string]: number }\\n\\t\\t\\t */\\n\\t\\t\\tthis.params = {}\\n\\t\\t}\\n\\n\\t\\t/**\\n\\t\\t * Generate an output sample from the input sample and parameters\\n\\t\\t * @abstract\\n\\t\\t * @param input number\\n\\t\\t * @param channel number\\n\\t\\t * @param parameters { [name: string]: number }\\n\\t\\t * @returns number\\n\\t\\t */\\n\\t\\tgenerate(){}\\n\\n\\t\\t/**\\n\\t\\t * Update the private params object with the \\n\\t\\t * values of the parameters at the given index\\n\\t\\t * @param parameters { [name: string]: Float32Array },\\n\\t\\t * @param index number\\n\\t\\t */\\n\\t\\tupdateParams(parameters, index) {\\n\\t\\t\\tfor (const paramName in parameters) {\\n\\t\\t\\t\\tconst param = parameters[paramName];\\n\\t\\t\\t\\tif (param.length > 1) {\\n\\t\\t\\t\\t\\tthis.params[paramName] = parameters[paramName][index];\\n\\t\\t\\t\\t} else {\\n\\t\\t\\t\\t\\tthis.params[paramName] = parameters[paramName][0];\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\t/**\\n\\t\\t * Process a single frame of the audio\\n\\t\\t * @param inputs Float32Array[][]\\n\\t\\t * @param outputs Float32Array[][]\\n\\t\\t */\\n\\t\\tprocess(inputs, outputs, parameters) {\\n\\t\\t\\tconst input = inputs[0];\\n\\t\\t\\tconst output = outputs[0];\\n\\t\\t\\t// get the parameter values\\n\\t\\t\\tconst channelCount = Math.max(input && input.length || 0, output.length);\\n\\t\\t\\tfor (let sample = 0; sample < this.blockSize; sample++) {\\n\\t\\t\\t\\tthis.updateParams(parameters, sample);\\n\\t\\t\\t\\tfor (let channel = 0; channel < channelCount; channel++) {\\n\\t\\t\\t\\t\\tconst inputSample = input && input.length ? input[channel][sample] : 0;\\n\\t\\t\\t\\t\\toutput[channel][sample] = this.generate(inputSample, channel, this.params);\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t\\treturn !this.disposed;\\n\\t\\t}\\n\\t};\\n\";\n",
  "core/worklet/ToneAudioWorklet.d.ts": "import { ToneAudioNode, ToneAudioNodeOptions } from \"../context/ToneAudioNode\";\nexport type ToneAudioWorkletOptions = ToneAudioNodeOptions;\nexport declare abstract class ToneAudioWorklet<Options extends ToneAudioWorkletOptions> extends ToneAudioNode<Options> {\n    readonly name: string;\n    /**\n     * The processing node\n     */\n    protected _worklet: AudioWorkletNode;\n    /**\n     * A dummy gain node to create a dummy audio param from\n     */\n    private _dummyGain;\n    /**\n     * A dummy audio param to use when creating Params\n     */\n    protected _dummyParam: AudioParam;\n    /**\n     * The constructor options for the node\n     */\n    protected workletOptions: Partial<AudioWorkletNodeOptions>;\n    /**\n     * Get the name of the audio worklet\n     */\n    protected abstract _audioWorkletName(): string;\n    /**\n     * Invoked when the module is loaded and the node is created\n     */\n    protected abstract onReady(node: AudioWorkletNode): void;\n    /**\n     * Callback which is invoked when there is an error in the processing\n     */\n    onprocessorerror: (e: string) => void;\n    constructor(options: Options);\n    dispose(): this;\n}\n",
  "core/worklet/ToneAudioWorkletProcessor.worklet.d.ts": "export {};\n",
  "core/worklet/WorkletGlobalScope.d.ts": "/**\n * Add a class to the AudioWorkletGlobalScope\n */\nexport declare function addToWorklet(classOrFunction: string): void;\n/**\n * Register a processor in the AudioWorkletGlobalScope with the given name\n */\nexport declare function registerProcessor(name: string, classDesc: string): void;\n/**\n * Get all of the modules which have been registered to the AudioWorkletGlobalScope\n */\nexport declare function getWorkletGlobalScope(): string;\n",
  "effect/AutoFilter.d.ts": "import { Frequency, Positive } from \"../core/type/Units\";\nimport { Filter, FilterOptions } from \"../component/filter/Filter\";\nimport { SourceOptions } from \"../source/Source\";\nimport { LFOEffect, LFOEffectOptions } from \"./LFOEffect\";\nexport interface AutoFilterOptions extends LFOEffectOptions {\n    baseFrequency: Frequency;\n    octaves: Positive;\n    filter: Omit<FilterOptions, keyof SourceOptions | \"frequency\" | \"detune\" | \"gain\">;\n}\n/**\n * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n * Setting the LFO rate and depth allows for control over the filter modulation rate\n * and depth.\n *\n * @example\n * // create an autofilter and start it's LFO\n * const autoFilter = new Tone.AutoFilter(\"4n\").toDestination().start();\n * // route an oscillator through the filter and start it\n * const oscillator = new Tone.Oscillator().connect(autoFilter).start();\n * @category Effect\n */\nexport declare class AutoFilter extends LFOEffect<AutoFilterOptions> {\n    readonly name: string;\n    /**\n     * The filter node\n     */\n    readonly filter: Filter;\n    /**\n     * The octaves placeholder\n     */\n    private _octaves;\n    /**\n     * @param frequency The rate of the LFO.\n     * @param baseFrequency The lower value of the LFOs oscillation\n     * @param octaves The number of octaves above the baseFrequency\n     */\n    constructor(frequency?: Frequency, baseFrequency?: Frequency, octaves?: Positive);\n    constructor(options?: Partial<AutoFilterOptions>);\n    static getDefaults(): AutoFilterOptions;\n    /**\n     * The minimum value of the filter's cutoff frequency.\n     */\n    get baseFrequency(): Frequency;\n    set baseFrequency(freq: Frequency);\n    /**\n     * The maximum value of the filter's cutoff frequency.\n     */\n    get octaves(): Positive;\n    set octaves(oct: Positive);\n    dispose(): this;\n}\n",
  "effect/AutoPanner.d.ts": "import { Panner } from \"../component/channel/Panner\";\nimport { LFOEffect, LFOEffectOptions } from \"./LFOEffect\";\nimport { Frequency } from \"../core/type/Units\";\nexport interface AutoPannerOptions extends LFOEffectOptions {\n    channelCount: number;\n}\n/**\n * AutoPanner is a {@link Panner} with an {@link LFO} connected to the pan amount.\n * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).\n *\n * @example\n * // create an autopanner and start it\n * const autoPanner = new Tone.AutoPanner(\"4n\").toDestination().start();\n * // route an oscillator through the panner and start it\n * const oscillator = new Tone.Oscillator().connect(autoPanner).start();\n * @category Effect\n */\nexport declare class AutoPanner extends LFOEffect<AutoPannerOptions> {\n    readonly name: string;\n    /**\n     * The filter node\n     */\n    readonly _panner: Panner;\n    /**\n     * @param frequency Rate of left-right oscillation.\n     */\n    constructor(frequency?: Frequency);\n    constructor(options?: Partial<AutoPannerOptions>);\n    static getDefaults(): AutoPannerOptions;\n    dispose(): this;\n}\n",
  "effect/AutoWah.d.ts": "import { Effect, EffectOptions } from \"./Effect\";\nimport { Decibels, Frequency, GainFactor, Positive, Time } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nexport interface AutoWahOptions extends EffectOptions {\n    baseFrequency: Frequency;\n    octaves: Positive;\n    sensitivity: Decibels;\n    Q: Positive;\n    gain: GainFactor;\n    follower: Time;\n}\n/**\n * AutoWah connects a {@link Follower} to a {@link Filter}.\n * The frequency of the filter, follows the input amplitude curve.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).\n *\n * @example\n * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();\n * // initialize the synth and connect to autowah\n * const synth = new Tone.Synth().connect(autoWah);\n * // Q value influences the effect of the wah - default is 2\n * autoWah.Q.value = 6;\n * // more audible on higher notes\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Effect\n */\nexport declare class AutoWah extends Effect<AutoWahOptions> {\n    readonly name: string;\n    /**\n     * The envelope follower. Set the attack/release\n     * timing to adjust how the envelope is followed.\n     */\n    private _follower;\n    /**\n     * scales the follower value to the frequency domain\n     */\n    private _sweepRange;\n    /**\n     * Hold the base frequency value\n     */\n    private _baseFrequency;\n    /**\n     * Private holder for the octave count\n     */\n    private _octaves;\n    /**\n     * the input gain to adjust the sensitivity\n     */\n    private _inputBoost;\n    /**\n     * Private holder for the filter\n     */\n    private _bandpass;\n    /**\n     * The peaking fitler\n     */\n    private _peaking;\n    /**\n     * The gain of the filter.\n     */\n    readonly gain: Signal<\"decibels\">;\n    /**\n     * The quality of the filter.\n     */\n    readonly Q: Signal<\"positive\">;\n    /**\n     * @param baseFrequency The frequency the filter is set to at the low point of the wah\n     * @param octaves The number of octaves above the baseFrequency the filter will sweep to when fully open.\n     * @param sensitivity The decibel threshold sensitivity for the incoming signal. Normal range of -40 to 0.\n     */\n    constructor(baseFrequency?: Frequency, octaves?: Positive, sensitivity?: Decibels);\n    constructor(options?: Partial<AutoWahOptions>);\n    static getDefaults(): AutoWahOptions;\n    /**\n     * The number of octaves that the filter will sweep above the baseFrequency.\n     */\n    get octaves(): number;\n    set octaves(octaves: number);\n    /**\n     * The follower's smoothing time\n     */\n    get follower(): Time;\n    set follower(follower: Time);\n    /**\n     * The base frequency from which the sweep will start from.\n     */\n    get baseFrequency(): Frequency;\n    set baseFrequency(baseFreq: Frequency);\n    /**\n     * The sensitivity to control how responsive to the input signal the filter is.\n     */\n    get sensitivity(): Decibels;\n    set sensitivity(sensitivity: Decibels);\n    /**\n     * sets the sweep range of the scaler\n     */\n    private _setSweepRange;\n    dispose(): this;\n}\n",
  "effect/BitCrusher.d.ts": "import { ToneAudioWorkletOptions } from \"../core/worklet/ToneAudioWorklet\";\nimport { Effect, EffectOptions } from \"./Effect\";\nimport { Positive } from \"../core/type/Units\";\nimport { Param } from \"../core/context/Param\";\nexport interface BitCrusherOptions extends EffectOptions {\n    bits: Positive;\n}\n/**\n * BitCrusher down-samples the incoming signal to a different bit depth.\n * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing\n * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).\n * @example\n * // initialize crusher and route a synth through it\n * const crusher = new Tone.BitCrusher(4).toDestination();\n * const synth = new Tone.Synth().connect(crusher);\n * synth.triggerAttackRelease(\"C2\", 2);\n *\n * @category Effect\n */\nexport declare class BitCrusher extends Effect<BitCrusherOptions> {\n    readonly name: string;\n    /**\n     * The bit depth of the effect\n     * @min 1\n     * @max 16\n     */\n    readonly bits: Param<\"positive\">;\n    /**\n     * The node which does the bit crushing effect. Runs in an AudioWorklet when possible.\n     */\n    private _bitCrusherWorklet;\n    constructor(bits?: Positive);\n    constructor(options?: Partial<BitCrusherWorkletOptions>);\n    static getDefaults(): BitCrusherOptions;\n    dispose(): this;\n}\ninterface BitCrusherWorkletOptions extends ToneAudioWorkletOptions {\n    bits: number;\n}\nexport {};\n",
  "effect/BitCrusher.worklet.d.ts": "import  \"../core/worklet/SingleIOProcessor.worklet\";\nexport declare const workletName = \"bit-crusher\";\nexport declare const bitCrusherWorklet = \"\\n\\tclass BitCrusherWorklet extends SingleIOProcessor {\\n\\n\\t\\tstatic get parameterDescriptors() {\\n\\t\\t\\treturn [{\\n\\t\\t\\t\\tname: \\\"bits\\\",\\n\\t\\t\\t\\tdefaultValue: 12,\\n\\t\\t\\t\\tminValue: 1,\\n\\t\\t\\t\\tmaxValue: 16,\\n\\t\\t\\t\\tautomationRate: 'k-rate'\\n\\t\\t\\t}];\\n\\t\\t}\\n\\n\\t\\tgenerate(input, _channel, parameters) {\\n\\t\\t\\tconst step = Math.pow(0.5, parameters.bits - 1);\\n\\t\\t\\tconst val = step * Math.floor(input / step + 0.5);\\n\\t\\t\\treturn val;\\n\\t\\t}\\n\\t}\\n\";\n",
  "effect/Chebyshev.d.ts": "import { Effect, EffectOptions } from \"./Effect\";\nimport { Positive } from \"../core/type/Units\";\nexport interface ChebyshevOptions extends EffectOptions {\n    order: Positive;\n    oversample: OverSampleType;\n}\n/**\n * Chebyshev is a waveshaper which is good\n * for making different types of distortion sounds.\n * Note that odd orders sound very different from even ones,\n * and order = 1 is no change.\n * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).\n * @example\n * // create a new cheby\n * const cheby = new Tone.Chebyshev(50).toDestination();\n * // create a monosynth connected to our cheby\n * const synth = new Tone.MonoSynth().connect(cheby);\n * synth.triggerAttackRelease(\"C2\", 0.4);\n * @category Effect\n */\nexport declare class Chebyshev extends Effect<ChebyshevOptions> {\n    readonly name: string;\n    /**\n     * The private waveshaper node\n     */\n    private _shaper;\n    /**\n     * holds onto the order of the filter\n     */\n    private _order;\n    /**\n     * @param order The order of the chebyshev polynomial. Normal range between 1-100.\n     */\n    constructor(order?: Positive);\n    constructor(options?: Partial<ChebyshevOptions>);\n    static getDefaults(): ChebyshevOptions;\n    /**\n     * get the coefficient for that degree\n     * @param  x the x value\n     * @param  degree\n     * @param  memo memoize the computed value. this speeds up computation greatly.\n     */\n    private _getCoefficient;\n    /**\n     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming\n     * signal through a Tone.WaveShaper. Must be an integer. The equations are in the form:\n     * ```\n     * order 2: 2x^2 + 1\n     * order 3: 4x^3 + 3x\n     * ```\n     * @min 1\n     * @max 100\n     */\n    get order(): Positive;\n    set order(order: Positive);\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample(): OverSampleType;\n    set oversample(oversampling: OverSampleType);\n    dispose(): this;\n}\n",
  "effect/Chorus.d.ts": "import { StereoFeedbackEffect, StereoFeedbackEffectOptions } from \"../effect/StereoFeedbackEffect\";\nimport { Degrees, Frequency, Milliseconds, NormalRange, Time } from \"../core/type/Units\";\nimport { ToneOscillatorType } from \"../source/oscillator/OscillatorInterface\";\nimport { Signal } from \"../signal/Signal\";\nexport interface ChorusOptions extends StereoFeedbackEffectOptions {\n    frequency: Frequency;\n    delayTime: Milliseconds;\n    depth: NormalRange;\n    type: ToneOscillatorType;\n    spread: Degrees;\n}\n/**\n * Chorus is a stereo chorus effect composed of a left and right delay with an {@link LFO} applied to the delayTime of each channel.\n * When {@link feedback} is set to a value larger than 0, you also get Flanger-type effects.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n * Read more on the chorus effect on [Sound On Sound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).\n *\n * @example\n * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();\n * const synth = new Tone.PolySynth().connect(chorus);\n * synth.triggerAttackRelease([\"C3\", \"E3\", \"G3\"], \"8n\");\n *\n * @category Effect\n */\nexport declare class Chorus extends StereoFeedbackEffect<ChorusOptions> {\n    readonly name: string;\n    /**\n     * the depth of the chorus\n     */\n    private _depth;\n    /**\n     * the delayTime in seconds.\n     */\n    private _delayTime;\n    /**\n     * the lfo which controls the delayTime\n     */\n    private _lfoL;\n    /**\n     * another LFO for the right side with a 180 degree phase diff\n     */\n    private _lfoR;\n    /**\n     * delay for left\n     */\n    private _delayNodeL;\n    /**\n     * delay for right\n     */\n    private _delayNodeR;\n    /**\n     * The frequency of the LFO which modulates the delayTime.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * @param frequency The frequency of the LFO.\n     * @param delayTime The delay of the chorus effect in ms.\n     * @param depth The depth of the chorus.\n     */\n    constructor(frequency?: Frequency, delayTime?: Milliseconds, depth?: NormalRange);\n    constructor(options?: Partial<ChorusOptions>);\n    static getDefaults(): ChorusOptions;\n    /**\n     * The depth of the effect. A depth of 1 makes the delayTime\n     * modulate between 0 and 2*delayTime (centered around the delayTime).\n     */\n    get depth(): NormalRange;\n    set depth(depth: NormalRange);\n    /**\n     * The delayTime in milliseconds of the chorus. A larger delayTime\n     * will give a more pronounced effect. Nominal range a delayTime\n     * is between 2 and 20ms.\n     */\n    get delayTime(): Milliseconds;\n    set delayTime(delayTime: Milliseconds);\n    /**\n     * The oscillator type of the LFO.\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread(): Degrees;\n    set spread(spread: Degrees);\n    /**\n     * Start the effect.\n     */\n    start(time?: Time): this;\n    /**\n     * Stop the lfo\n     */\n    stop(time?: Time): this;\n    /**\n     * Sync the filter to the transport.\n     * @see {@link LFO.sync}\n     */\n    sync(): this;\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync(): this;\n    dispose(): this;\n}\n",
  "effect/Distortion.d.ts": "import { Effect, EffectOptions } from \"./Effect\";\nexport interface DistortionOptions extends EffectOptions {\n    distortion: number;\n    oversample: OverSampleType;\n}\n/**\n * A simple distortion effect using Tone.WaveShaper.\n * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).\n * Read more about distortion on [Wikipedia](https://en.wikipedia.org/wiki/Distortion_(music).\n * @example\n * const dist = new Tone.Distortion(0.8).toDestination();\n * const fm = new Tone.FMSynth().connect(dist);\n * fm.triggerAttackRelease(\"A1\", \"8n\");\n * @category Effect\n */\nexport declare class Distortion extends Effect<DistortionOptions> {\n    readonly name: string;\n    /**\n     * The waveshaper which does the distortion\n     */\n    private _shaper;\n    /**\n     * Stores the distortion value\n     */\n    private _distortion;\n    /**\n     * @param distortion The amount of distortion (nominal range of 0-1)\n     */\n    constructor(distortion?: number);\n    constructor(options?: Partial<DistortionOptions>);\n    static getDefaults(): DistortionOptions;\n    /**\n     * The amount of distortion. Nominal range is between 0 and 1.\n     */\n    get distortion(): number;\n    set distortion(amount: number);\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample(): OverSampleType;\n    set oversample(oversampling: OverSampleType);\n    dispose(): this;\n}\n",
  "effect/Effect.d.ts": "import { CrossFade } from \"../component/channel/CrossFade\";\nimport { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { NormalRange } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nexport interface EffectOptions extends ToneAudioNodeOptions {\n    wet: NormalRange;\n}\n/**\n * Effect is the base class for effects. Connect the effect between\n * the effectSend and effectReturn GainNodes, then control the amount of\n * effect which goes to the output using the wet control.\n */\nexport declare abstract class Effect<Options extends EffectOptions> extends ToneAudioNode<Options> {\n    readonly name: string;\n    /**\n     * the drywet knob to control the amount of effect\n     */\n    private _dryWet;\n    /**\n     * The wet control is how much of the effected\n     * will pass through to the output. 1 = 100% effected\n     * signal, 0 = 100% dry signal.\n     */\n    wet: Signal<\"normalRange\">;\n    /**\n     * connect the effectSend to the input of hte effect\n     */\n    protected effectSend: Gain;\n    /**\n     * connect the output of the effect to the effectReturn\n     */\n    protected effectReturn: Gain;\n    /**\n     * The effect input node\n     */\n    input: Gain;\n    /**\n     * The effect output\n     */\n    output: CrossFade;\n    constructor(options: EffectOptions);\n    static getDefaults(): EffectOptions;\n    /**\n     * chains the effect in between the effectSend and effectReturn\n     */\n    protected connectEffect(effect: ToneAudioNode | AudioNode): this;\n    dispose(): this;\n}\n",
  "effect/FeedbackDelay.d.ts": "import { Param } from \"../core/context/Param\";\nimport { NormalRange, Time } from \"../core/type/Units\";\nimport { FeedbackEffect, FeedbackEffectOptions } from \"./FeedbackEffect\";\nexport interface FeedbackDelayOptions extends FeedbackEffectOptions {\n    delayTime: Time;\n    maxDelay: Time;\n}\n/**\n * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.\n *\n * @param delayTime The delay applied to the incoming signal.\n * @param feedback The amount of the effected signal which is fed back through the delay.\n * @example\n * const feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toDestination();\n * const tom = new Tone.MembraneSynth({\n * \toctaves: 4,\n * \tpitchDecay: 0.1\n * }).connect(feedbackDelay);\n * tom.triggerAttackRelease(\"A2\", \"32n\");\n * @category Effect\n */\nexport declare class FeedbackDelay extends FeedbackEffect<FeedbackDelayOptions> {\n    readonly name: string;\n    /**\n     * the delay node\n     */\n    private _delayNode;\n    /**\n     * The delayTime of the FeedbackDelay.\n     */\n    readonly delayTime: Param<\"time\">;\n    constructor(delayTime?: Time, feedback?: NormalRange);\n    constructor(options?: Partial<FeedbackDelayOptions>);\n    static getDefaults(): FeedbackDelayOptions;\n    dispose(): this;\n}\n",
  "effect/FeedbackEffect.d.ts": "import { Param } from \"../core/context/Param\";\nimport { NormalRange } from \"../core/type/Units\";\nimport { Effect, EffectOptions } from \"./Effect\";\nexport interface FeedbackEffectOptions extends EffectOptions {\n    /**\n     * The feedback from the output back to the input\n     * ```\n     * +---<--------<---+\n     * |                |\n     * |  +----------+  |\n     * +--> feedback +>-+\n     *    +----------+\n     * ```\n     */\n    feedback: NormalRange;\n}\n/**\n * FeedbackEffect provides a loop between an audio source and its own output.\n * This is a base-class for feedback effects.\n *\n * NOTE: Feedback effects require at least one DelayNode to be in the feedback cycle.\n */\nexport declare abstract class FeedbackEffect<Options extends FeedbackEffectOptions> extends Effect<Options> {\n    readonly name: string;\n    /**\n     * the gain which controls the feedback\n     */\n    private _feedbackGain;\n    /**\n     * The amount of signal which is fed back into the effect input.\n     */\n    feedback: Param<\"normalRange\">;\n    constructor(options: FeedbackEffectOptions);\n    static getDefaults(): FeedbackEffectOptions;\n    dispose(): this;\n}\n",
  "effect/Freeverb.d.ts": "import { StereoEffect, StereoEffectOptions } from \"./StereoEffect\";\nimport { Frequency, NormalRange } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nexport interface FreeverbOptions extends StereoEffectOptions {\n    dampening: Frequency;\n    roomSize: NormalRange;\n}\n/**\n * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).\n * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.\n * @example\n * const freeverb = new Tone.Freeverb().toDestination();\n * freeverb.dampening = 1000;\n * // routing synth through the reverb\n * const synth = new Tone.NoiseSynth().connect(freeverb);\n * synth.triggerAttackRelease(0.05);\n * @category Effect\n */\nexport declare class Freeverb extends StereoEffect<FreeverbOptions> {\n    readonly name: string;\n    /**\n     * The roomSize value between 0 and 1. A larger roomSize will result in a longer decay.\n     */\n    readonly roomSize: Signal<\"normalRange\">;\n    /**\n     * the comb filters\n     */\n    private _combFilters;\n    /**\n     * the allpass filters on the left\n     */\n    private _allpassFiltersL;\n    /**\n     * the allpass filters on the right\n     */\n    private _allpassFiltersR;\n    /**\n     * @param roomSize Correlated to the decay time.\n     * @param dampening The cutoff frequency of a lowpass filter as part of the reverb.\n     */\n    constructor(roomSize?: NormalRange, dampening?: Frequency);\n    constructor(options?: Partial<FreeverbOptions>);\n    static getDefaults(): FreeverbOptions;\n    /**\n     * The amount of dampening of the reverberant signal.\n     */\n    get dampening(): Frequency;\n    set dampening(d: Frequency);\n    dispose(): this;\n}\n",
  "effect/FrequencyShifter.d.ts": "import { Frequency } from \"../core/type/Units\";\nimport { Effect, EffectOptions } from \"../effect/Effect\";\nimport { Signal } from \"../signal/Signal\";\nexport interface FrequencyShifterOptions extends EffectOptions {\n    frequency: Frequency;\n}\n/**\n * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.\n * The amount can be changed at audio rate and the effect is applied in real time.\n * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.\n * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,\n * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.\n * The algorithm will produces some aliasing towards the high end, especially if your source material\n * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling\n * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might\n * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.\n * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/\n *\n * @example\n * const input = new Tone.Oscillator(230, \"sawtooth\").start();\n * const shift = new Tone.FrequencyShifter(42).toDestination();\n * input.connect(shift);\n * @category Effect\n */\nexport declare class FrequencyShifter extends Effect<FrequencyShifterOptions> {\n    readonly name: string;\n    /**\n     * The ring modulators carrier frequency. This frequency determines\n     * by how many Hertz the input signal will be shifted up or down. Default is 0.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The ring modulators sine carrier\n     */\n    private _sine;\n    /**\n     * The ring modulators cosine carrier\n     */\n    private _cosine;\n    /**\n     * The sine multiply operator\n     */\n    private _sineMultiply;\n    /**\n     * The cosine multiply operator\n     */\n    private _cosineMultiply;\n    /**\n     * The negate operator\n     */\n    private _negate;\n    /**\n     * The final add operator\n     */\n    private _add;\n    /**\n     * The phase shifter to create the initial 90 phase offset\n     */\n    private _phaseShifter;\n    /**\n     * @param frequency The incoming signal is shifted by this frequency value.\n     */\n    constructor(frequency?: Frequency);\n    constructor(options?: Partial<FrequencyShifterOptions>);\n    static getDefaults(): FrequencyShifterOptions;\n    dispose(): this;\n}\n",
  "effect/JCReverb.d.ts": "import { NormalRange } from \"../core/type/Units\";\nimport { StereoEffect, StereoEffectOptions } from \"./StereoEffect\";\nimport { Signal } from \"../signal/Signal\";\nexport interface JCReverbOptions extends StereoEffectOptions {\n    roomSize: NormalRange;\n}\n/**\n * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n * tuned by John Chowning in 1970.\n * It is made up of three allpass filters and four {@link FeedbackCombFilter}.\n * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.\n * @example\n * const reverb = new Tone.JCReverb(0.4).toDestination();\n * const delay = new Tone.FeedbackDelay(0.5);\n * // connecting the synth to reverb through delay\n * const synth = new Tone.DuoSynth().chain(delay, reverb);\n * synth.triggerAttackRelease(\"A4\", \"8n\");\n *\n * @category Effect\n */\nexport declare class JCReverb extends StereoEffect<JCReverbOptions> {\n    readonly name: string;\n    /**\n     * Room size control values.\n     */\n    readonly roomSize: Signal<\"normalRange\">;\n    /**\n     * Scale the room size\n     */\n    private _scaleRoomSize;\n    /**\n     * a series of allpass filters\n     */\n    private _allpassFilters;\n    /**\n     * parallel feedback comb filters\n     */\n    private _feedbackCombFilters;\n    /**\n     * @param roomSize Correlated to the decay time.\n     */\n    constructor(roomSize?: NormalRange);\n    constructor(options?: Partial<JCReverbOptions>);\n    static getDefaults(): JCReverbOptions;\n    dispose(): this;\n}\n",
  "effect/LFOEffect.d.ts": "import { Effect, EffectOptions } from \"../effect/Effect\";\nimport { Frequency, NormalRange, Time } from \"../core/type/Units\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { ToneOscillatorType } from \"../source/oscillator/OscillatorInterface\";\nimport { Signal } from \"../signal/Signal\";\nimport { Param } from \"../core/context/Param\";\nexport interface LFOEffectOptions extends EffectOptions {\n    frequency: Frequency;\n    type: ToneOscillatorType;\n    depth: NormalRange;\n}\n/**\n * Base class for LFO-based effects.\n */\nexport declare abstract class LFOEffect<Options extends LFOEffectOptions> extends Effect<Options> {\n    readonly name: string;\n    /**\n     * the lfo which drives the filter cutoff\n     */\n    protected _lfo: LFO;\n    /**\n     * The range of the filter modulating between the min and max frequency.\n     * 0 = no modulation. 1 = full modulation.\n     */\n    readonly depth: Param<\"normalRange\">;\n    /**\n     * How fast the filter modulates between min and max.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    constructor(options: LFOEffectOptions);\n    static getDefaults(): LFOEffectOptions;\n    /**\n     * Start the effect.\n     */\n    start(time?: Time): this;\n    /**\n     * Stop the lfo\n     */\n    stop(time?: Time): this;\n    /**\n     * Sync the filter to the transport.\n     * @see {@link LFO.sync}\n     */\n    sync(): this;\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync(): this;\n    /**\n     * The type of the LFO's oscillator.\n     * @see {@link Oscillator.type}\n     * @example\n     * const autoFilter = new Tone.AutoFilter().start().toDestination();\n     * const noise = new Tone.Noise().start().connect(autoFilter);\n     * autoFilter.type = \"square\";\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    dispose(): this;\n}\n",
  "effect/MidSideEffect.d.ts": "import { Effect, EffectOptions } from \"./Effect\";\nimport { OutputNode, ToneAudioNode } from \"../core/context/ToneAudioNode\";\nexport type MidSideEffectOptions = EffectOptions;\n/**\n * Mid/Side processing separates the the 'mid' signal\n * (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels)\n * and effects them separately before being recombined.\n * Applies a Mid/Side seperation and recombination.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * This is a base-class for Mid/Side Effects.\n * @category Effect\n */\nexport declare abstract class MidSideEffect<Options extends MidSideEffectOptions> extends Effect<Options> {\n    readonly name: string;\n    /**\n     * The mid/side split\n     */\n    private _midSideSplit;\n    /**\n     * The mid/side merge\n     */\n    private _midSideMerge;\n    /**\n     * The mid send. Connect to mid processing\n     */\n    protected _midSend: ToneAudioNode;\n    /**\n     * The side send. Connect to side processing\n     */\n    protected _sideSend: ToneAudioNode;\n    /**\n     * The mid return connection\n     */\n    protected _midReturn: ToneAudioNode;\n    /**\n     * The side return connection\n     */\n    protected _sideReturn: ToneAudioNode;\n    constructor(options: MidSideEffectOptions);\n    /**\n     * Connect the mid chain of the effect\n     */\n    protected connectEffectMid(...nodes: OutputNode[]): void;\n    /**\n     * Connect the side chain of the effect\n     */\n    protected connectEffectSide(...nodes: OutputNode[]): void;\n    dispose(): this;\n}\n",
  "effect/Phaser.d.ts": "import { StereoEffect, StereoEffectOptions } from \"./StereoEffect\";\nimport { Frequency, Positive } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nexport interface PhaserOptions extends StereoEffectOptions {\n    frequency: Frequency;\n    octaves: Positive;\n    stages: Positive;\n    Q: Positive;\n    baseFrequency: Frequency;\n}\n/**\n * Phaser is a phaser effect. Phasers work by changing the phase\n * of different frequency components of an incoming signal. Read more on\n * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).\n * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).\n * @example\n * const phaser = new Tone.Phaser({\n * \tfrequency: 15,\n * \toctaves: 5,\n * \tbaseFrequency: 1000\n * }).toDestination();\n * const synth = new Tone.FMSynth().connect(phaser);\n * synth.triggerAttackRelease(\"E3\", \"2n\");\n * @category Effect\n */\nexport declare class Phaser extends StereoEffect<PhaserOptions> {\n    readonly name: string;\n    /**\n     * the lfo which controls the frequency on the left side\n     */\n    private _lfoL;\n    /**\n     * the lfo which controls the frequency on the right side\n     */\n    private _lfoR;\n    /**\n     * the base modulation frequency\n     */\n    private _baseFrequency;\n    /**\n     * the octaves of the phasing\n     */\n    private _octaves;\n    /**\n     * The quality factor of the filters\n     */\n    readonly Q: Signal<\"positive\">;\n    /**\n     * the array of filters for the left side\n     */\n    private _filtersL;\n    /**\n     * the array of filters for the left side\n     */\n    private _filtersR;\n    /**\n     * the frequency of the effect\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * @param frequency The speed of the phasing.\n     * @param octaves The octaves of the effect.\n     * @param baseFrequency The base frequency of the filters.\n     */\n    constructor(frequency?: Frequency, octaves?: Positive, baseFrequency?: Frequency);\n    constructor(options?: Partial<PhaserOptions>);\n    static getDefaults(): PhaserOptions;\n    private _makeFilters;\n    /**\n     * The number of octaves the phase goes above the baseFrequency\n     */\n    get octaves(): number;\n    set octaves(octaves: number);\n    /**\n     * The the base frequency of the filters.\n     */\n    get baseFrequency(): Frequency;\n    set baseFrequency(freq: Frequency);\n    dispose(): this;\n}\n",
  "effect/PingPongDelay.d.ts": "import { StereoXFeedbackEffect, StereoXFeedbackEffectOptions } from \"./StereoXFeedbackEffect\";\nimport { NormalRange, Seconds, Time } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nexport interface PingPongDelayOptions extends StereoXFeedbackEffectOptions {\n    delayTime: Time;\n    maxDelay: Seconds;\n}\n/**\n * PingPongDelay is a feedback delay effect where the echo is heard\n * first in one channel and next in the opposite channel. In a stereo\n * system these are the right and left channels.\n * PingPongDelay in more simplified terms is two Tone.FeedbackDelays\n * with independent delay values. Each delay is routed to one channel\n * (left or right), and the channel triggered second will always\n * trigger at the same interval after the first.\n * @example\n * const pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toDestination();\n * const drum = new Tone.MembraneSynth().connect(pingPong);\n * drum.triggerAttackRelease(\"C4\", \"32n\");\n * @category Effect\n */\nexport declare class PingPongDelay extends StereoXFeedbackEffect<PingPongDelayOptions> {\n    readonly name: string;\n    /**\n     * the delay node on the left side\n     */\n    private _leftDelay;\n    /**\n     * the delay node on the right side\n     */\n    private _rightDelay;\n    /**\n     * the predelay on the right side\n     */\n    private _rightPreDelay;\n    /**\n     * the delay time signal\n     */\n    readonly delayTime: Signal<\"time\">;\n    /**\n     * @param delayTime The delayTime between consecutive echos.\n     * @param feedback The amount of the effected signal which is fed back through the delay.\n     */\n    constructor(delayTime?: Time, feedback?: NormalRange);\n    constructor(options?: Partial<PingPongDelayOptions>);\n    static getDefaults(): PingPongDelayOptions;\n    dispose(): this;\n}\n",
  "effect/PitchShift.d.ts": "import { Interval, Seconds, Time } from \"../core/type/Units\";\nimport { FeedbackEffect, FeedbackEffectOptions } from \"./FeedbackEffect\";\nimport { Param } from \"../core/context/Param\";\nexport interface PitchShiftOptions extends FeedbackEffectOptions {\n    pitch: Interval;\n    windowSize: Seconds;\n    delayTime: Time;\n}\n/**\n * PitchShift does near-realtime pitch shifting to the incoming signal.\n * The effect is achieved by speeding up or slowing down the delayTime\n * of a DelayNode using a sawtooth wave.\n * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).\n * @category Effect\n */\nexport declare class PitchShift extends FeedbackEffect<PitchShiftOptions> {\n    readonly name: string;\n    /**\n     * The pitch signal\n     */\n    private _frequency;\n    /**\n     * Uses two DelayNodes to cover up the jump in the sawtooth wave.\n     */\n    private _delayA;\n    /**\n     * The first LFO.\n     */\n    private _lfoA;\n    /**\n     * The second DelayNode\n     */\n    private _delayB;\n    /**\n     * The second LFO.\n     */\n    private _lfoB;\n    /**\n     * Cross fade quickly between the two delay lines to cover up the jump in the sawtooth wave\n     */\n    private _crossFade;\n    /**\n     * LFO which alternates between the two delay lines to cover up the disparity in the\n     * sawtooth wave.\n     */\n    private _crossFadeLFO;\n    /**\n     * The delay node\n     */\n    private _feedbackDelay;\n    /**\n     * The amount of delay on the input signal\n     */\n    readonly delayTime: Param<\"time\">;\n    /**\n     * Hold the current pitch\n     */\n    private _pitch;\n    /**\n     * Hold the current windowSize\n     */\n    private _windowSize;\n    /**\n     * @param pitch The interval to transpose the incoming signal by.\n     */\n    constructor(pitch?: Interval);\n    constructor(options?: Partial<PitchShiftOptions>);\n    static getDefaults(): PitchShiftOptions;\n    /**\n     * Repitch the incoming signal by some interval (measured in semi-tones).\n     * @example\n     * const pitchShift = new Tone.PitchShift().toDestination();\n     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();\n     * pitchShift.pitch = -12; // down one octave\n     * pitchShift.pitch = 7; // up a fifth\n     */\n    get pitch(): number;\n    set pitch(interval: number);\n    /**\n     * The window size corresponds roughly to the sample length in a looping sampler.\n     * Smaller values are desirable for a less noticeable delay time of the pitch shifted\n     * signal, but larger values will result in smoother pitch shifting for larger intervals.\n     * A nominal range of 0.03 to 0.1 is recommended.\n     */\n    get windowSize(): Seconds;\n    set windowSize(size: Seconds);\n    dispose(): this;\n}\n",
  "effect/Reverb.d.ts": "import { Seconds, Time } from \"../core/type/Units\";\nimport { Effect, EffectOptions } from \"./Effect\";\nexport interface ReverbOptions extends EffectOptions {\n    decay: Seconds;\n    preDelay: Seconds;\n}\n/**\n * Simple convolution created with decaying noise.\n * Generates an Impulse Response Buffer\n * with Tone.Offline then feeds the IR into ConvolverNode.\n * The impulse response generation is async, so you have\n * to wait until {@link ready} resolves before it will make a sound.\n *\n * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).\n * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.\n *\n * @category Effect\n */\nexport declare class Reverb extends Effect<ReverbOptions> {\n    readonly name: string;\n    /**\n     * Convolver node\n     */\n    private _convolver;\n    /**\n     * The duration of the reverb.\n     */\n    private _decay;\n    /**\n     * The amount of time before the reverb is fully ramped in.\n     */\n    private _preDelay;\n    /**\n     * Resolves when the reverb buffer is generated. Whenever either {@link decay}\n     * or {@link preDelay} are set, you have to wait until {@link ready} resolves\n     * before the IR is generated with the latest values.\n     */\n    ready: Promise<void>;\n    /**\n     * @param decay The amount of time it will reverberate for.\n     */\n    constructor(decay?: Seconds);\n    constructor(options?: Partial<ReverbOptions>);\n    static getDefaults(): ReverbOptions;\n    /**\n     * The duration of the reverb.\n     */\n    get decay(): Time;\n    set decay(time: Time);\n    /**\n     * The amount of time before the reverb is fully ramped in.\n     */\n    get preDelay(): Time;\n    set preDelay(time: Time);\n    /**\n     * Generate the Impulse Response. Returns a promise while the IR is being generated.\n     * @return Promise which returns this object.\n     */\n    generate(): Promise<this>;\n    dispose(): this;\n}\n",
  "effect/StereoEffect.d.ts": "import { EffectOptions } from \"./Effect\";\nimport { OutputNode, ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { CrossFade } from \"../component/channel/CrossFade\";\nimport { Signal } from \"../signal/Signal\";\nimport { Split } from \"../component/channel/Split\";\nimport { Gain } from \"../core/context/Gain\";\nimport { Merge } from \"../component/channel/Merge\";\nexport type StereoEffectOptions = EffectOptions;\n/**\n * Base class for Stereo effects.\n */\nexport declare class StereoEffect<Options extends StereoEffectOptions> extends ToneAudioNode<Options> {\n    readonly name: string;\n    readonly input: Gain;\n    readonly output: CrossFade;\n    /**\n     * the drywet knob to control the amount of effect\n     */\n    private _dryWet;\n    /**\n     * The wet control, i.e. how much of the effected\n     * will pass through to the output.\n     */\n    readonly wet: Signal<\"normalRange\">;\n    /**\n     * Split it\n     */\n    protected _split: Split;\n    /**\n     * the stereo effect merger\n     */\n    protected _merge: Merge;\n    constructor(options: StereoEffectOptions);\n    /**\n     * Connect the left part of the effect\n     */\n    protected connectEffectLeft(...nodes: OutputNode[]): void;\n    /**\n     * Connect the right part of the effect\n     */\n    protected connectEffectRight(...nodes: OutputNode[]): void;\n    static getDefaults(): StereoEffectOptions;\n    dispose(): this;\n}\n",
  "effect/StereoFeedbackEffect.d.ts": "import { StereoEffect, StereoEffectOptions } from \"./StereoEffect\";\nimport { NormalRange } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nimport { Gain } from \"../core/context/Gain\";\nimport { Split } from \"../component/channel/Split\";\nimport { Merge } from \"../component/channel/Merge\";\nexport interface StereoFeedbackEffectOptions extends StereoEffectOptions {\n    feedback: NormalRange;\n}\n/**\n * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.\n */\nexport declare class StereoFeedbackEffect<Options extends StereoFeedbackEffectOptions> extends StereoEffect<Options> {\n    /**\n     * The amount of feedback from the output\n     * back into the input of the effect (routed\n     * across left and right channels).\n     */\n    readonly feedback: Signal<\"normalRange\">;\n    /**\n     * the left side feedback\n     */\n    protected _feedbackL: Gain;\n    /**\n     * the right side feedback\n     */\n    protected _feedbackR: Gain;\n    /**\n     * Split the channels for feedback\n     */\n    protected _feedbackSplit: Split;\n    /**\n     * Merge the channels for feedback\n     */\n    protected _feedbackMerge: Merge;\n    constructor(options: StereoFeedbackEffectOptions);\n    static getDefaults(): StereoFeedbackEffectOptions;\n    dispose(): this;\n}\n",
  "effect/StereoWidener.d.ts": "import { MidSideEffect, MidSideEffectOptions } from \"../effect/MidSideEffect\";\nimport { Signal } from \"../signal/Signal\";\nimport { NormalRange } from \"../core/type/Units\";\nexport interface StereoWidenerOptions extends MidSideEffectOptions {\n    width: NormalRange;\n}\n/**\n * Applies a width factor to the mid/side seperation.\n * 0 is all mid and 1 is all side.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * ```\n * Mid *= 2*(1-width)<br>\n * Side *= 2*width\n * ```\n * @category Effect\n */\nexport declare class StereoWidener extends MidSideEffect<StereoWidenerOptions> {\n    readonly name: string;\n    /**\n     * The width control. 0 = 100% mid. 1 = 100% side. 0.5 = no change.\n     */\n    readonly width: Signal<\"normalRange\">;\n    /**\n     * Two times the (1-width) for the mid channel\n     */\n    private _twoTimesWidthMid;\n    /**\n     * Two times the width for the side channel\n     */\n    private _twoTimesWidthSide;\n    /**\n     * Mid multiplier\n     */\n    private _midMult;\n    /**\n     * 1 - width\n     */\n    private _oneMinusWidth;\n    /**\n     * Side multiplier\n     */\n    private _sideMult;\n    /**\n     * @param width The stereo width. A width of 0 is mono and 1 is stereo. 0.5 is no change.\n     */\n    constructor(width?: NormalRange);\n    constructor(options?: Partial<StereoWidenerOptions>);\n    static getDefaults(): StereoWidenerOptions;\n    dispose(): this;\n}\n",
  "effect/StereoXFeedbackEffect.d.ts": "import { StereoFeedbackEffect, StereoFeedbackEffectOptions } from \"./StereoFeedbackEffect\";\nimport { NormalRange } from \"../core/type/Units\";\nexport interface StereoXFeedbackEffectOptions extends StereoFeedbackEffectOptions {\n    feedback: NormalRange;\n}\n/**\n * Just like a {@link StereoFeedbackEffect}, but the feedback is routed from left to right\n * and right to left instead of on the same channel.\n * ```\n * +--------------------------------+ feedbackL <-----------------------------------+\n * |                                                                                |\n * +-->                          +----->        +---->                          +-----+\n *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |\n * +-->                          +----->        +---->                          +---+ |\n * |                                                                                  |\n * +--------------------------------+ feedbackR <-------------------------------------+\n * ```\n */\nexport declare class StereoXFeedbackEffect<Options extends StereoXFeedbackEffectOptions> extends StereoFeedbackEffect<Options> {\n    constructor(options: StereoXFeedbackEffectOptions);\n}\n",
  "effect/Tremolo.d.ts": "import { StereoEffect, StereoEffectOptions } from \"./StereoEffect\";\nimport { Signal } from \"../signal/Signal\";\nimport { Degrees, Frequency, NormalRange, Time } from \"../core/type/Units\";\nimport { ToneOscillatorType } from \"../source/oscillator/OscillatorInterface\";\nexport interface TremoloOptions extends StereoEffectOptions {\n    frequency: Frequency;\n    type: ToneOscillatorType;\n    depth: NormalRange;\n    spread: Degrees;\n}\n/**\n * Tremolo modulates the amplitude of an incoming signal using an {@link LFO}.\n * The effect is a stereo effect where the modulation phase is inverted in each channel.\n *\n * @example\n * // create a tremolo and start it's LFO\n * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();\n * // route an oscillator through the tremolo and start it\n * const oscillator = new Tone.Oscillator().connect(tremolo).start();\n *\n * @category Effect\n */\nexport declare class Tremolo extends StereoEffect<TremoloOptions> {\n    readonly name: string;\n    /**\n     * The tremolo LFO in the left channel\n     */\n    private _lfoL;\n    /**\n     * The tremolo LFO in the left channel\n     */\n    private _lfoR;\n    /**\n     * Where the gain is multiplied\n     */\n    private _amplitudeL;\n    /**\n     * Where the gain is multiplied\n     */\n    private _amplitudeR;\n    /**\n     * The frequency of the tremolo.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The depth of the effect. A depth of 0, has no effect\n     * on the amplitude, and a depth of 1 makes the amplitude\n     * modulate fully between 0 and 1.\n     */\n    readonly depth: Signal<\"normalRange\">;\n    /**\n     * @param frequency The rate of the effect.\n     * @param depth The depth of the effect.\n     */\n    constructor(frequency?: Frequency, depth?: NormalRange);\n    constructor(options?: Partial<TremoloOptions>);\n    static getDefaults(): TremoloOptions;\n    /**\n     * Start the tremolo.\n     */\n    start(time?: Time): this;\n    /**\n     * Stop the tremolo.\n     */\n    stop(time?: Time): this;\n    /**\n     * Sync the effect to the transport.\n     */\n    sync(): this;\n    /**\n     * Unsync the filter from the transport\n     */\n    unsync(): this;\n    /**\n     * The oscillator type.\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread(): Degrees;\n    set spread(spread: Degrees);\n    dispose(): this;\n}\n",
  "effect/Vibrato.d.ts": "import { Effect, EffectOptions } from \"./Effect\";\nimport { ToneOscillatorType } from \"../source/oscillator/OscillatorInterface\";\nimport { Frequency, NormalRange, Seconds } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nimport { Param } from \"../core/context/Param\";\nexport interface VibratoOptions extends EffectOptions {\n    maxDelay: Seconds;\n    frequency: Frequency;\n    depth: NormalRange;\n    type: ToneOscillatorType;\n}\n/**\n * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n * modulates the delayTime of the delay, causing the pitch to rise and fall.\n * @category Effect\n */\nexport declare class Vibrato extends Effect<VibratoOptions> {\n    readonly name: string;\n    /**\n     * The delay node used for the vibrato effect\n     */\n    private _delayNode;\n    /**\n     * The LFO used to control the vibrato\n     */\n    private _lfo;\n    /**\n     * The frequency of the vibrato\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The depth of the vibrato.\n     */\n    readonly depth: Param<\"normalRange\">;\n    /**\n     * @param frequency The frequency of the vibrato.\n     * @param depth The amount the pitch is modulated.\n     */\n    constructor(frequency?: Frequency, depth?: NormalRange);\n    constructor(options?: Partial<VibratoOptions>);\n    static getDefaults(): VibratoOptions;\n    /**\n     * Type of oscillator attached to the Vibrato.\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    dispose(): this;\n}\n",
  "effect/index.d.ts": "export * from \"./AutoFilter\";\nexport * from \"./AutoPanner\";\nexport * from \"./AutoWah\";\nexport * from \"./BitCrusher\";\nexport * from \"./Chebyshev\";\nexport * from \"./Chorus\";\nexport * from \"./Distortion\";\nexport * from \"./FeedbackDelay\";\nexport * from \"./FrequencyShifter\";\nexport * from \"./Freeverb\";\nexport * from \"./JCReverb\";\nexport * from \"./PingPongDelay\";\nexport * from \"./PitchShift\";\nexport * from \"./Phaser\";\nexport * from \"./Reverb\";\nexport * from \"./StereoWidener\";\nexport * from \"./Tremolo\";\nexport * from \"./Vibrato\";\n",
  "event/Loop.d.ts": "import { NormalRange, Positive, Seconds, Time, TransportTime } from \"../core/type/Units\";\nimport { ToneWithContext, ToneWithContextOptions } from \"../core/context/ToneWithContext\";\nimport { BasicPlaybackState } from \"../core/util/StateTimeline\";\nexport interface LoopOptions extends ToneWithContextOptions {\n    callback: (time: Seconds) => void;\n    interval: Time;\n    playbackRate: Positive;\n    iterations: number;\n    probability: NormalRange;\n    mute: boolean;\n    humanize: boolean | Time;\n}\n/**\n * Loop creates a looped callback at the\n * specified interval. The callback can be\n * started, stopped and scheduled along\n * the Transport's timeline.\n * @example\n * const loop = new Tone.Loop((time) => {\n * \t// triggered every eighth note.\n * \tconsole.log(time);\n * }, \"8n\").start(0);\n * Tone.Transport.start();\n * @category Event\n */\nexport declare class Loop<Options extends LoopOptions = LoopOptions> extends ToneWithContext<Options> {\n    readonly name: string;\n    /**\n     * The event which produces the callbacks\n     */\n    private _event;\n    /**\n     * The callback to invoke with the next event in the pattern\n     */\n    callback: (time: Seconds) => void;\n    /**\n     * @param callback The callback to invoke at the time.\n     * @param interval The time between successive callback calls.\n     */\n    constructor(callback?: (time: Seconds) => void, interval?: Time);\n    constructor(options?: Partial<LoopOptions>);\n    static getDefaults(): LoopOptions;\n    /**\n     * Start the loop at the specified time along the Transport's timeline.\n     * @param  time  When to start the Loop.\n     */\n    start(time?: TransportTime): this;\n    /**\n     * Stop the loop at the given time.\n     * @param  time  When to stop the Loop.\n     */\n    stop(time?: TransportTime): this;\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time?: TransportTime): this;\n    /**\n     * Internal function called when the notes should be called\n     * @param time  The time the event occurs\n     */\n    protected _tick(time: Seconds): void;\n    /**\n     * The state of the Loop, either started or stopped.\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.\n     */\n    get progress(): NormalRange;\n    /**\n     * The time between successive callbacks.\n     * @example\n     * const loop = new Tone.Loop();\n     * loop.interval = \"8n\"; // loop every 8n\n     */\n    get interval(): Time;\n    set interval(interval: Time);\n    /**\n     * The playback rate of the loop. The normal playback rate is 1 (no change).\n     * A `playbackRate` of 2 would be twice as fast.\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * Random variation +/-0.01s to the scheduled time.\n     * Or give it a time value which it will randomize by.\n     */\n    get humanize(): boolean | Time;\n    set humanize(variation: boolean | Time);\n    /**\n     * The probably of the callback being invoked.\n     */\n    get probability(): NormalRange;\n    set probability(prob: NormalRange);\n    /**\n     * Muting the Loop means that no callbacks are invoked.\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    /**\n     * The number of iterations of the loop. The default value is `Infinity` (loop forever).\n     */\n    get iterations(): number;\n    set iterations(iters: number);\n    dispose(): this;\n}\n",
  "event/Part.d.ts": "import { TransportTimeClass } from \"../core/type/TransportTime\";\nimport { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from \"../core/type/Units\";\nimport { StateTimeline } from \"../core/util/StateTimeline\";\nimport { ToneEvent, ToneEventCallback, ToneEventOptions } from \"./ToneEvent\";\ntype CallbackType<T> = T extends {\n    time: Time;\n    [key: string]: any;\n} ? T : T extends ArrayLike<any> ? T[1] : T extends Time ? null : never;\ninterface PartOptions<T> extends Omit<ToneEventOptions<CallbackType<T>>, \"value\"> {\n    events: T[];\n}\n/**\n * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.\n *\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const part = new Tone.Part(((time, note) => {\n * \t// the notes given as the second element in the array\n * \t// will be passed in as the second argument\n * \tsynth.triggerAttackRelease(note, \"8n\", time);\n * }), [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]).start(0);\n * Tone.Transport.start();\n * @example\n * const synth = new Tone.Synth().toDestination();\n * // use an array of objects as long as the object has a \"time\" attribute\n * const part = new Tone.Part(((time, value) => {\n * \t// the value is an object which contains both the note and the velocity\n * \tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n * }), [{ time: 0, note: \"C3\", velocity: 0.9 },\n * \t{ time: \"0:2\", note: \"C4\", velocity: 0.5 }\n * ]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nexport declare class Part<ValueType = any> extends ToneEvent<ValueType> {\n    readonly name: string;\n    /**\n     * Tracks the scheduled events\n     */\n    protected _state: StateTimeline<{\n        id: number;\n        offset: number;\n    }>;\n    /**\n     * The events that belong to this part\n     */\n    private _events;\n    /**\n     * @param callback The callback to invoke on each event\n     * @param value the array of events\n     */\n    constructor(callback?: ToneEventCallback<CallbackType<ValueType>>, value?: ValueType[]);\n    constructor(options?: Partial<PartOptions<ValueType>>);\n    static getDefaults(): PartOptions<any>;\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset from the start of the part to begin playing at.\n     */\n    start(time?: TransportTime, offset?: Time): this;\n    /**\n     * Start the event in the given event at the correct time given\n     * the ticks and offset and looping.\n     * @param  event\n     * @param  ticks\n     * @param  offset\n     */\n    private _startNote;\n    get startOffset(): Ticks;\n    set startOffset(offset: Ticks);\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time?: TransportTime): this;\n    /**\n     * Get/Set an Event's value at the given time.\n     * If a value is passed in and no event exists at\n     * the given time, one will be created with that value.\n     * If two events are at the same time, the first one will\n     * be returned.\n     * @example\n     * const part = new Tone.Part();\n     * part.at(\"1m\"); // returns the part at the first measure\n     * part.at(\"2m\", \"C2\"); // set the value at \"2m\" to C2.\n     * // if an event didn't exist at that time, it will be created.\n     * @param time The time of the event to get or set.\n     * @param value If a value is passed in, the value of the event at the given time will be set to it.\n     */\n    at(time: Time, value?: any): ToneEvent | null;\n    /**\n     * Add a an event to the part.\n     * @param time The time the note should start. If an object is passed in, it should\n     * \t\thave a 'time' attribute and the rest of the object will be used as the 'value'.\n     * @param  value Any value to add to the timeline\n     * @example\n     * const part = new Tone.Part();\n     * part.add(\"1m\", \"C#+11\");\n     */\n    add(obj: {\n        time: Time;\n        [key: string]: any;\n    }): this;\n    add(time: Time, value?: any): this;\n    /**\n     * Restart the given event\n     */\n    private _restartEvent;\n    /**\n     * Remove an event from the part. If the event at that time is a Part,\n     * it will remove the entire part.\n     * @param time The time of the event\n     * @param value Optionally select only a specific event value\n     */\n    remove(obj: {\n        time: Time;\n        [key: string]: any;\n    }): this;\n    remove(time: Time, value?: any): this;\n    /**\n     * Remove all of the notes from the group.\n     */\n    clear(): this;\n    /**\n     * Cancel scheduled state change events: i.e. \"start\" and \"stop\".\n     * @param after The time after which to cancel the scheduled events.\n     */\n    cancel(after?: TransportTime | TransportTimeClass): this;\n    /**\n     * Iterate over all of the events\n     */\n    private _forEach;\n    /**\n     * Set the attribute of all of the events\n     * @param  attr  the attribute to set\n     * @param  value      The value to set it to\n     */\n    private _setAll;\n    /**\n     * Internal tick method\n     * @param  time  The time of the event in seconds\n     */\n    protected _tick(time: Seconds, value?: any): void;\n    /**\n     * Determine if the event should be currently looping\n     * given the loop boundries of this Part.\n     * @param  event  The event to test\n     */\n    private _testLoopBoundries;\n    get probability(): NormalRange;\n    set probability(prob: NormalRange);\n    get humanize(): boolean | Time;\n    set humanize(variation: boolean | Time);\n    /**\n     * If the part should loop or not\n     * between Part.loopStart and\n     * Part.loopEnd. If set to true,\n     * the part will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     * @example\n     * const part = new Tone.Part();\n     * // loop the part 8 times\n     * part.loop = 8;\n     */\n    get loop(): boolean | number;\n    set loop(loop: boolean | number);\n    /**\n     * The loopEnd point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopEnd(): Time;\n    set loopEnd(loopEnd: Time);\n    /**\n     * The loopStart point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopStart(): Time;\n    set loopStart(loopStart: Time);\n    /**\n     * The playback rate of the part\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * The number of scheduled notes in the part.\n     */\n    get length(): number;\n    dispose(): this;\n}\nexport {};\n",
  "event/Pattern.d.ts": "import { Loop, LoopOptions } from \"./Loop\";\nimport { PatternName } from \"./PatternGenerator\";\nimport { ToneEventCallback } from \"./ToneEvent\";\nimport { Seconds } from \"../core/type/Units\";\nexport interface PatternOptions<ValueType> extends LoopOptions {\n    pattern: PatternName;\n    values: ValueType[];\n    callback: (time: Seconds, value?: ValueType) => void;\n}\n/**\n * Pattern arpeggiates between the given notes\n * in a number of patterns.\n * @example\n * const pattern = new Tone.Pattern((time, note) => {\n * \t// the order of the notes passed in depends on the pattern\n * }, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n * @category Event\n */\nexport declare class Pattern<ValueType> extends Loop<PatternOptions<ValueType>> {\n    readonly name: string;\n    /**\n     * The pattern generator function\n     */\n    private _pattern;\n    /**\n     * The current index\n     */\n    private _index?;\n    /**\n     * The current value\n     */\n    private _value?;\n    /**\n     * Hold the pattern type\n     */\n    private _type;\n    /**\n     * Hold the values\n     */\n    private _values;\n    /**\n     * The callback to be invoked at a regular interval\n     */\n    callback: (time: Seconds, value?: ValueType) => void;\n    /**\n     * @param  callback The callback to invoke with the event.\n     * @param  values The values to arpeggiate over.\n     * @param  pattern  The name of the pattern\n     */\n    constructor(callback?: ToneEventCallback<ValueType>, values?: ValueType[], pattern?: PatternName);\n    constructor(options?: Partial<PatternOptions<ValueType>>);\n    static getDefaults(): PatternOptions<any>;\n    /**\n     * Internal function called when the notes should be called\n     */\n    protected _tick(time: Seconds): void;\n    /**\n     * The array of events.\n     */\n    get values(): ValueType[];\n    set values(val: ValueType[]);\n    /**\n     * The current value of the pattern.\n     */\n    get value(): ValueType | undefined;\n    /**\n     * The current index of the pattern.\n     */\n    get index(): number | undefined;\n    /**\n     * The pattern type.\n     */\n    get pattern(): PatternName;\n    set pattern(pattern: PatternName);\n}\n",
  "event/PatternGenerator.d.ts": "/**\n * The name of the patterns\n */\nexport type PatternName = \"up\" | \"down\" | \"upDown\" | \"downUp\" | \"alternateUp\" | \"alternateDown\" | \"random\" | \"randomOnce\" | \"randomWalk\";\n/**\n * PatternGenerator returns a generator which will yield numbers between 0 and numValues\n * according to the passed in pattern that can be used as indexes into an array of size numValues.\n * @param numValues The size of the array to emit indexes for\n * @param pattern The name of the pattern use when iterating over\n * @param index Where to start in the offset of the values array\n */\nexport declare function PatternGenerator(numValues: number, pattern?: PatternName, index?: number): Iterator<number>;\n",
  "event/Sequence.d.ts": "import { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from \"../core/type/Units\";\nimport { ToneEvent, ToneEventCallback, ToneEventOptions } from \"./ToneEvent\";\ntype SequenceEventDescription<T> = Array<T | SequenceEventDescription<T>>;\ninterface SequenceOptions<T> extends Omit<ToneEventOptions<T>, \"value\"> {\n    loopStart: number;\n    loopEnd: number;\n    subdivision: Time;\n    events: SequenceEventDescription<T>;\n}\n/**\n * A sequence is an alternate notation of a part. Instead\n * of passing in an array of [time, event] pairs, pass\n * in an array of events which will be spaced at the\n * given subdivision. Sub-arrays will subdivide that beat\n * by the number of items are in the array.\n * Sequence notation inspiration from [Tidal Cycles](http://tidalcycles.org/)\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const seq = new Tone.Sequence((time, note) => {\n * \tsynth.triggerAttackRelease(note, 0.1, time);\n * \t// subdivisions are given as subarrays\n * }, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nexport declare class Sequence<ValueType = any> extends ToneEvent<ValueType> {\n    readonly name: string;\n    /**\n     * The subdivison of each note\n     */\n    private _subdivision;\n    /**\n     * The object responsible for scheduling all of the events\n     */\n    private _part;\n    /**\n     * private reference to all of the sequence proxies\n     */\n    private _events;\n    /**\n     * The proxied array\n     */\n    private _eventsArray;\n    /**\n     * @param  callback  The callback to invoke with every note\n     * @param  events  The sequence of events\n     * @param  subdivision  The subdivision between which events are placed.\n     */\n    constructor(callback?: ToneEventCallback<ValueType>, events?: SequenceEventDescription<ValueType>, subdivision?: Time);\n    constructor(options?: Partial<SequenceOptions<ValueType>>);\n    static getDefaults(): SequenceOptions<any>;\n    /**\n     * The internal callback for when an event is invoked\n     */\n    private _seqCallback;\n    /**\n     * The sequence\n     */\n    get events(): any[];\n    set events(s: any[]);\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset index to start at\n     */\n    start(time?: TransportTime, offset?: number): this;\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time?: TransportTime): this;\n    /**\n     * The subdivision of the sequence. This can only be\n     * set in the constructor. The subdivision is the\n     * interval between successive steps.\n     */\n    get subdivision(): Seconds;\n    /**\n     * Create a sequence proxy which can be monitored to create subsequences\n     */\n    private _createSequence;\n    /**\n     * When the sequence has changed, all of the events need to be recreated\n     */\n    private _eventsUpdated;\n    /**\n     * reschedule all of the events that need to be rescheduled\n     */\n    private _rescheduleSequence;\n    /**\n     * Get the time of the index given the Sequence's subdivision\n     * @param  index\n     * @return The time of that index\n     */\n    private _indexTime;\n    /**\n     * Clear all of the events\n     */\n    clear(): this;\n    dispose(): this;\n    get loop(): boolean | number;\n    set loop(l: boolean | number);\n    /**\n     * The index at which the sequence should start looping\n     */\n    get loopStart(): number;\n    set loopStart(index: number);\n    /**\n     * The index at which the sequence should end looping\n     */\n    get loopEnd(): number;\n    set loopEnd(index: number);\n    get startOffset(): Ticks;\n    set startOffset(start: Ticks);\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    get probability(): NormalRange;\n    set probability(prob: NormalRange);\n    get progress(): NormalRange;\n    get humanize(): boolean | Time;\n    set humanize(variation: boolean | Time);\n    /**\n     * The number of scheduled events\n     */\n    get length(): number;\n}\nexport {};\n",
  "event/ToneEvent.d.ts": "import  \"../core/clock/Transport\";\nimport { ToneWithContext, ToneWithContextOptions } from \"../core/context/ToneWithContext\";\nimport { TransportTimeClass } from \"../core/type/TransportTime\";\nimport { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from \"../core/type/Units\";\nimport { BasicPlaybackState, StateTimeline } from \"../core/util/StateTimeline\";\nexport type ToneEventCallback<T> = (time: Seconds, value: T) => void;\nexport interface ToneEventOptions<T> extends ToneWithContextOptions {\n    callback: ToneEventCallback<T>;\n    loop: boolean | number;\n    loopEnd: Time;\n    loopStart: Time;\n    playbackRate: Positive;\n    value?: T;\n    probability: NormalRange;\n    mute: boolean;\n    humanize: boolean | Time;\n}\n/**\n * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable\n * callback for a single or repeatable events along the timeline.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * const chordEvent = new Tone.ToneEvent(((time, chord) => {\n * \t// the chord as well as the exact time of the event\n * \t// are passed in as arguments to the callback function\n * \tsynth.triggerAttackRelease(chord, 0.5, time);\n * }), [\"D4\", \"E4\", \"F4\"]);\n * // start the chord at the beginning of the transport timeline\n * chordEvent.start();\n * // loop it every measure for 8 measures\n * chordEvent.loop = 8;\n * chordEvent.loopEnd = \"1m\";\n * @category Event\n */\nexport declare class ToneEvent<ValueType = any> extends ToneWithContext<ToneEventOptions<ValueType>> {\n    readonly name: string;\n    /**\n     * Loop value\n     */\n    protected _loop: boolean | number;\n    /**\n     * The callback to invoke.\n     */\n    callback: ToneEventCallback<ValueType>;\n    /**\n     * The value which is passed to the\n     * callback function.\n     */\n    value: ValueType;\n    /**\n     * When the note is scheduled to start.\n     */\n    protected _loopStart: Ticks;\n    /**\n     * When the note is scheduled to start.\n     */\n    protected _loopEnd: Ticks;\n    /**\n     * Tracks the scheduled events\n     */\n    protected _state: StateTimeline<{\n        id: number;\n    }>;\n    /**\n     * The playback speed of the note. A speed of 1\n     * is no change.\n     */\n    protected _playbackRate: Positive;\n    /**\n     * A delay time from when the event is scheduled to start\n     */\n    protected _startOffset: Ticks;\n    /**\n     * private holder of probability value\n     */\n    protected _probability: NormalRange;\n    /**\n     * the amount of variation from the given time.\n     */\n    protected _humanize: boolean | Time;\n    /**\n     * If mute is true, the callback won't be invoked.\n     */\n    mute: boolean;\n    /**\n     * @param callback The callback to invoke at the time.\n     * @param value The value or values which should be passed to the callback function on invocation.\n     */\n    constructor(callback?: ToneEventCallback<ValueType>, value?: ValueType);\n    constructor(options?: Partial<ToneEventOptions<ValueType>>);\n    static getDefaults(): ToneEventOptions<any>;\n    /**\n     * Reschedule all of the events along the timeline\n     * with the updated values.\n     * @param after Only reschedules events after the given time.\n     */\n    private _rescheduleEvents;\n    /**\n     * Returns the playback state of the note, either \"started\" or \"stopped\".\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * The start from the scheduled start time.\n     */\n    get startOffset(): Ticks;\n    set startOffset(offset: Ticks);\n    /**\n     * The probability of the notes being triggered.\n     */\n    get probability(): NormalRange;\n    set probability(prob: NormalRange);\n    /**\n     * If set to true, will apply small random variation\n     * to the callback time. If the value is given as a time, it will randomize\n     * by that amount.\n     * @example\n     * const event = new Tone.ToneEvent();\n     * event.humanize = true;\n     */\n    get humanize(): Time | boolean;\n    set humanize(variation: Time | boolean);\n    /**\n     * Start the note at the given time.\n     * @param  time  When the event should start.\n     */\n    start(time?: TransportTime | TransportTimeClass): this;\n    /**\n     * Stop the Event at the given time.\n     * @param  time  When the event should stop.\n     */\n    stop(time?: TransportTime | TransportTimeClass): this;\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time?: TransportTime | TransportTimeClass): this;\n    /**\n     * The callback function invoker. Also\n     * checks if the Event is done playing\n     * @param  time  The time of the event in seconds\n     */\n    protected _tick(time: Seconds): void;\n    /**\n     * Get the duration of the loop.\n     */\n    protected _getLoopDuration(): Ticks;\n    /**\n     * If the note should loop or not\n     * between ToneEvent.loopStart and\n     * ToneEvent.loopEnd. If set to true,\n     * the event will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     */\n    get loop(): boolean | number;\n    set loop(loop: boolean | number);\n    /**\n     * The playback rate of the event. Defaults to 1.\n     * @example\n     * const note = new Tone.ToneEvent();\n     * note.loop = true;\n     * // repeat the note twice as fast\n     * note.playbackRate = 2;\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * The loopEnd point is the time the event will loop\n     * if ToneEvent.loop is true.\n     */\n    get loopEnd(): Time;\n    set loopEnd(loopEnd: Time);\n    /**\n     * The time when the loop should start.\n     */\n    get loopStart(): Time;\n    set loopStart(loopStart: Time);\n    /**\n     * The current progress of the loop interval.\n     * Returns 0 if the event is not started yet or\n     * it is not set to loop.\n     */\n    get progress(): NormalRange;\n    dispose(): this;\n}\n",
  "event/index.d.ts": "export * from \"./Loop\";\nexport * from \"./Part\";\nexport * from \"./Pattern\";\nexport * from \"./Sequence\";\nexport * from \"./ToneEvent\";\n",
  "fromContext.d.ts": "import * as Classes from \"./classes\";\nimport { TransportClass } from \"./core/clock/Transport\";\nimport { Context } from \"./core/context/Context\";\nimport { ListenerClass } from \"./core/context/Listener\";\nimport { DestinationClass } from \"./core/context/Destination\";\nimport { DrawClass } from \"./core/util/Draw\";\ntype ClassesWithoutSingletons = Omit<typeof Classes, \"Transport\" | \"Destination\" | \"Draw\">;\n/**\n * The exported Tone object. Contains all of the classes that default\n * to the same context and contains a singleton Transport and Destination node.\n */\ntype ToneObject = {\n    Transport: TransportClass;\n    Destination: DestinationClass;\n    Listener: ListenerClass;\n    Draw: DrawClass;\n    context: Context;\n    now: () => number;\n    immediate: () => number;\n} & ClassesWithoutSingletons;\n/**\n * Return an object with all of the classes bound to the passed in context\n * @param context The context to bind all of the nodes to\n */\nexport declare function fromContext(context: Context): ToneObject;\nexport {};\n",
  "index.d.ts": "export { getContext, setContext } from \"./core/Global\";\nexport * from \"./classes\";\nexport * from \"./version\";\nimport { ToneAudioBuffer } from \"./core/context/ToneAudioBuffer\";\nexport { start } from \"./core/Global\";\nimport { Seconds } from \"./core/type/Units\";\nexport { supported } from \"./core/context/AudioContext\";\nimport type { TransportClass } from \"./core/clock/Transport\";\nimport type { DestinationClass } from \"./core/context/Destination\";\nimport type { DrawClass } from \"./core/util/Draw\";\nimport type { ListenerClass } from \"./core/context/Listener\";\n/**\n * The current audio context time of the global {@link BaseContext}.\n * @see {@link Context.now}\n * @category Core\n */\nexport declare function now(): Seconds;\n/**\n * The current audio context time of the global {@link Context} without the {@link Context.lookAhead}\n * @see {@link Context.immediate}\n * @category Core\n */\nexport declare function immediate(): Seconds;\n/**\n * The Transport object belonging to the global Tone.js Context.\n * @see {@link TransportClass}\n * @category Core\n * @deprecated Use {@link getTransport} instead\n */\nexport declare const Transport: TransportClass;\n/**\n * The Transport object belonging to the global Tone.js Context.\n * @see {@link TransportClass}\n * @category Core\n */\nexport declare function getTransport(): TransportClass;\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * @see {@link DestinationClass}\n * @category Core\n * @deprecated Use {@link getDestination} instead\n */\nexport declare const Destination: DestinationClass;\n/**\n * @deprecated Use {@link getDestination} instead\n */\nexport declare const Master: DestinationClass;\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * @see {@link DestinationClass}\n * @category Core\n */\nexport declare function getDestination(): DestinationClass;\n/**\n * The {@link ListenerClass} belonging to the global Tone.js Context.\n * @category Core\n * @deprecated Use {@link getListener} instead\n */\nexport declare const Listener: ListenerClass;\n/**\n * The {@link ListenerClass} belonging to the global Tone.js Context.\n * @category Core\n */\nexport declare function getListener(): ListenerClass;\n/**\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * @see {@link DrawClass}\n * @category Core\n * @deprecated Use {@link getDraw} instead\n */\nexport declare const Draw: DrawClass;\n/**\n * Get the singleton attached to the global context.\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * @see {@link DrawClass}\n * @category Core\n */\nexport declare function getDraw(): DrawClass;\n/**\n * A reference to the global context\n * @see {@link Context}\n * @deprecated Use {@link getContext} instead\n */\nexport declare const context: import(\"./classes\").BaseContext;\n/**\n * Promise which resolves when all of the loading promises are resolved.\n * Alias for static {@link ToneAudioBuffer.loaded} method.\n * @category Core\n */\nexport declare function loaded(): Promise<void>;\nimport { ToneAudioBuffers } from \"./core/context/ToneAudioBuffers\";\nimport { ToneBufferSource } from \"./source/buffer/ToneBufferSource\";\n/** @deprecated Use {@link ToneAudioBuffer} */\nexport declare const Buffer: typeof ToneAudioBuffer;\n/** @deprecated Use {@link ToneAudioBuffers} */\nexport declare const Buffers: typeof ToneAudioBuffers;\n/** @deprecated Use {@link ToneBufferSource} */\nexport declare const BufferSource: typeof ToneBufferSource;\n",
  "instrument/AMSynth.d.ts": "import { RecursivePartial } from \"../core/util/Interface\";\nimport { ModulationSynth, ModulationSynthOptions } from \"./ModulationSynth\";\nexport type AMSynthOptions = ModulationSynthOptions;\n/**\n * AMSynth uses the output of one Tone.Synth to modulate the\n * amplitude of another Tone.Synth. The harmonicity (the ratio between\n * the two signals) affects the timbre of the output signal greatly.\n * Read more about Amplitude Modulation Synthesis on\n * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n *\n * @example\n * const synth = new Tone.AMSynth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"4n\");\n *\n * @category Instrument\n */\nexport declare class AMSynth extends ModulationSynth<AMSynthOptions> {\n    readonly name: string;\n    /**\n     * Scale the oscillator from -1,1 to 0-1\n     */\n    private _modulationScale;\n    constructor(options?: RecursivePartial<AMSynthOptions>);\n    dispose(): this;\n}\n",
  "instrument/DuoSynth.d.ts": "import { Monophonic, MonophonicOptions } from \"./Monophonic\";\nimport { MonoSynth, MonoSynthOptions } from \"./MonoSynth\";\nimport { Signal } from \"../signal/Signal\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Frequency, NormalRange, Positive, Seconds, Time } from \"../core/type/Units\";\nimport { Param } from \"../core/context/Param\";\nexport interface DuoSynthOptions extends MonophonicOptions {\n    voice0: Omit<MonoSynthOptions, keyof MonophonicOptions>;\n    voice1: Omit<MonoSynthOptions, keyof MonophonicOptions>;\n    harmonicity: Positive;\n    vibratoRate: Frequency;\n    vibratoAmount: Positive;\n}\n/**\n * DuoSynth is a monophonic synth composed of two {@link MonoSynth}s run in parallel with control over the\n * frequency ratio between the two voices and vibrato effect.\n * @example\n * const duoSynth = new Tone.DuoSynth().toDestination();\n * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n * @category Instrument\n */\nexport declare class DuoSynth extends Monophonic<DuoSynthOptions> {\n    readonly name: string;\n    readonly frequency: Signal<\"frequency\">;\n    readonly detune: Signal<\"cents\">;\n    /**\n     * the first voice\n     */\n    readonly voice0: MonoSynth;\n    /**\n     * the second voice\n     */\n    readonly voice1: MonoSynth;\n    /**\n     * The amount of vibrato\n     */\n    vibratoAmount: Param<\"normalRange\">;\n    /**\n     * the vibrato frequency\n     */\n    vibratoRate: Signal<\"frequency\">;\n    /**\n     * Harmonicity is the ratio between the two voices. A harmonicity of\n     * 1 is no change. Harmonicity = 2 means a change of an octave.\n     * @example\n     * const duoSynth = new Tone.DuoSynth().toDestination();\n     * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n     * // pitch voice1 an octave below voice0\n     * duoSynth.harmonicity.value = 0.5;\n     */\n    harmonicity: Signal<\"positive\">;\n    /**\n     * The vibrato LFO.\n     */\n    private _vibrato;\n    /**\n     * the vibrato gain\n     */\n    private _vibratoGain;\n    constructor(options?: RecursivePartial<DuoSynthOptions>);\n    getLevelAtTime(time: Time): NormalRange;\n    static getDefaults(): DuoSynthOptions;\n    /**\n     * Trigger the attack portion of the note\n     */\n    protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;\n    /**\n     * Trigger the release portion of the note\n     */\n    protected _triggerEnvelopeRelease(time: Seconds): this;\n    dispose(): this;\n}\n",
  "instrument/FMSynth.d.ts": "import { Positive } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { ModulationSynth, ModulationSynthOptions } from \"./ModulationSynth\";\nexport interface FMSynthOptions extends ModulationSynthOptions {\n    modulationIndex: Positive;\n}\n/**\n * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n * the frequency of a second Tone.Synth. A lot of spectral content\n * can be explored using the modulationIndex parameter. Read more about\n * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n *\n * @example\n * const fmSynth = new Tone.FMSynth().toDestination();\n * fmSynth.triggerAttackRelease(\"C5\", \"4n\");\n *\n * @category Instrument\n */\nexport declare class FMSynth extends ModulationSynth<FMSynthOptions> {\n    readonly name: string;\n    /**\n     * The modulation index which essentially the depth or amount of the modulation. It is the\n     * ratio of the frequency of the modulating signal (mf) to the amplitude of the\n     * modulating signal (ma) -- as in ma/mf.\n     */\n    readonly modulationIndex: Multiply;\n    constructor(options?: RecursivePartial<FMSynthOptions>);\n    static getDefaults(): FMSynthOptions;\n    dispose(): this;\n}\n",
  "instrument/Instrument.d.ts": "import { Param } from \"../core/context/Param\";\nimport { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Decibels, Frequency, NormalRange, Time } from \"../core/type/Units\";\nexport interface InstrumentOptions extends ToneAudioNodeOptions {\n    volume: Decibels;\n}\n/**\n * Base-class for all instruments\n */\nexport declare abstract class Instrument<Options extends InstrumentOptions> extends ToneAudioNode<Options> {\n    /**\n     * The output and volume triming node\n     */\n    private _volume;\n    output: OutputNode;\n    /**\n     * The instrument only has an output\n     */\n    input: undefined;\n    /**\n     * The volume of the output in decibels.\n     * @example\n     * const amSynth = new Tone.AMSynth().toDestination();\n     * amSynth.volume.value = -6;\n     * amSynth.triggerAttackRelease(\"G#3\", 0.2);\n     */\n    volume: Param<\"decibels\">;\n    /**\n     * Keep track of all events scheduled to the transport\n     * when the instrument is 'synced'\n     */\n    private _scheduledEvents;\n    /**\n     * If the instrument is currently synced\n     */\n    private _synced;\n    constructor(options?: Partial<InstrumentOptions>);\n    static getDefaults(): InstrumentOptions;\n    /**\n     * Sync the instrument to the Transport. All subsequent calls of\n     * {@link triggerAttack} and {@link triggerRelease} will be scheduled along the transport.\n     * @example\n     * const fmSynth = new Tone.FMSynth().toDestination();\n     * fmSynth.volume.value = -6;\n     * fmSynth.sync();\n     * // schedule 3 notes when the transport first starts\n     * fmSynth.triggerAttackRelease(\"C4\", \"8n\", 0);\n     * fmSynth.triggerAttackRelease(\"E4\", \"8n\", \"8n\");\n     * fmSynth.triggerAttackRelease(\"G4\", \"8n\", \"4n\");\n     * // start the transport to hear the notes\n     * Tone.Transport.start();\n     */\n    sync(): this;\n    /**\n     * set _sync\n     */\n    protected _syncState(): boolean;\n    /**\n     * Wrap the given method so that it can be synchronized\n     * @param method Which method to wrap and sync\n     * @param  timePosition What position the time argument appears in\n     */\n    protected _syncMethod(method: string, timePosition: number): void;\n    /**\n     * Unsync the instrument from the Transport\n     */\n    unsync(): this;\n    /**\n     * Trigger the attack and then the release after the duration.\n     * @param  note     The note to trigger.\n     * @param  duration How long the note should be held for before\n     *                         triggering the release. This value must be greater than 0.\n     * @param time  When the note should be triggered.\n     * @param  velocity The velocity the note should be triggered at.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger \"C4\" for the duration of an 8th note\n     * synth.triggerAttackRelease(\"C4\", \"8n\");\n     */\n    triggerAttackRelease(note: Frequency, duration: Time, time?: Time, velocity?: NormalRange): this;\n    /**\n     * Start the instrument's note.\n     * @param note the note to trigger\n     * @param time the time to trigger the note\n     * @param velocity the velocity to trigger the note (between 0-1)\n     */\n    abstract triggerAttack(note: Frequency, time?: Time, velocity?: NormalRange): this;\n    private _original_triggerAttack;\n    /**\n     * Trigger the release phase of the current note.\n     * @param time when to trigger the release\n     */\n    abstract triggerRelease(...args: any[]): this;\n    private _original_triggerRelease;\n    /**\n     * The release which is scheduled to the timeline.\n     */\n    protected _syncedRelease: (time: number) => this;\n    /**\n     * clean up\n     * @returns {Instrument} this\n     */\n    dispose(): this;\n}\n",
  "instrument/MembraneSynth.d.ts": "import { FrequencyClass } from \"../core/type/Frequency\";\nimport { Frequency, Positive, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Synth, SynthOptions } from \"./Synth\";\nexport interface MembraneSynthOptions extends SynthOptions {\n    pitchDecay: Time;\n    octaves: Positive;\n}\n/**\n * MembraneSynth makes kick and tom sounds using a single oscillator\n * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n * is routed through a Tone.AmplitudeEnvelope to the output. The drum\n * quality of the sound comes from the frequency envelope applied\n * during MembraneSynth.triggerAttack(note). The frequency envelope\n * starts at <code>note * .octaves</code> and ramps to <code>note</code>\n * over the duration of <code>.pitchDecay</code>.\n * @example\n * const synth = new Tone.MembraneSynth().toDestination();\n * synth.triggerAttackRelease(\"C2\", \"8n\");\n * @category Instrument\n */\nexport declare class MembraneSynth extends Synth<MembraneSynthOptions> {\n    readonly name: string;\n    /**\n     * The number of octaves the pitch envelope ramps.\n     * @min 0.5\n     * @max 8\n     */\n    octaves: Positive;\n    /**\n     * The amount of time the frequency envelope takes.\n     * @min 0\n     * @max 0.5\n     */\n    pitchDecay: Time;\n    /**\n     * Portamento is ignored in this synth. use pitch decay instead.\n     */\n    readonly portamento = 0;\n    /**\n     * @param options the options available for the synth see defaults\n     */\n    constructor(options?: RecursivePartial<MembraneSynthOptions>);\n    static getDefaults(): MembraneSynthOptions;\n    setNote(note: Frequency | FrequencyClass, time?: Time): this;\n    dispose(): this;\n}\n",
  "instrument/MetalSynth.d.ts": "import { Envelope, EnvelopeOptions } from \"../component/envelope/Envelope\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Frequency, NormalRange, Positive, Seconds, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Signal } from \"../signal/Signal\";\nimport { Monophonic, MonophonicOptions } from \"./Monophonic\";\nexport interface MetalSynthOptions extends MonophonicOptions {\n    harmonicity: Positive;\n    modulationIndex: Positive;\n    octaves: number;\n    resonance: Frequency;\n    envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;\n}\n/**\n * A highly inharmonic and spectrally complex source with a highpass filter\n * and amplitude envelope which is good for making metallophone sounds.\n * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n * @category Instrument\n */\nexport declare class MetalSynth extends Monophonic<MetalSynthOptions> {\n    readonly name: string;\n    /**\n     * The frequency of the cymbal\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune applied to the oscillators\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The array of FMOscillators\n     */\n    private _oscillators;\n    /**\n     * The frequency multipliers\n     */\n    private _freqMultipliers;\n    /**\n     * The gain node for the envelope.\n     */\n    private _amplitude;\n    /**\n     * Highpass the output\n     */\n    private _highpass;\n    /**\n     * The number of octaves the highpass\n     * filter frequency ramps\n     */\n    private _octaves;\n    /**\n     * Scale the body envelope for the highpass filter\n     */\n    private _filterFreqScaler;\n    /**\n     * The envelope which is connected both to the\n     * amplitude and a highpass filter's cutoff frequency.\n     * The lower-limit of the filter is controlled by the {@link resonance}\n     */\n    readonly envelope: Envelope;\n    constructor(options?: RecursivePartial<MetalSynthOptions>);\n    static getDefaults(): MetalSynthOptions;\n    /**\n     * Trigger the attack.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity that the envelope should be triggered at.\n     */\n    protected _triggerEnvelopeAttack(time: Seconds, velocity?: NormalRange): this;\n    /**\n     * Trigger the release of the envelope.\n     * @param time When the release should be triggered.\n     */\n    protected _triggerEnvelopeRelease(time: Seconds): this;\n    getLevelAtTime(time: Time): NormalRange;\n    /**\n     * The modulationIndex of the oscillators which make up the source.\n     * see {@link FMOscillator.modulationIndex}\n     * @min 1\n     * @max 100\n     */\n    get modulationIndex(): number;\n    set modulationIndex(val: number);\n    /**\n     * The harmonicity of the oscillators which make up the source.\n     * see Tone.FMOscillator.harmonicity\n     * @min 0.1\n     * @max 10\n     */\n    get harmonicity(): number;\n    set harmonicity(val: number);\n    /**\n     * The lower level of the highpass filter which is attached to the envelope.\n     * This value should be between [0, 7000]\n     * @min 0\n     * @max 7000\n     */\n    get resonance(): Frequency;\n    set resonance(val: Frequency);\n    /**\n     * The number of octaves above the \"resonance\" frequency\n     * that the filter ramps during the attack/decay envelope\n     * @min 0\n     * @max 8\n     */\n    get octaves(): number;\n    set octaves(val: number);\n    dispose(): this;\n}\n",
  "instrument/ModulationSynth.d.ts": "import { Signal } from \"../signal/Signal\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { Gain } from \"../core/context/Gain\";\nimport { NormalRange, Positive, Seconds, Time } from \"../core/type/Units\";\nimport { EnvelopeOptions } from \"../component/envelope/Envelope\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Monophonic } from \"./Monophonic\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { OmniOscillatorSynthOptions } from \"../source/oscillator/OscillatorInterface\";\nimport { Synth, SynthOptions } from \"./Synth\";\nimport { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nexport interface ModulationSynthOptions extends SynthOptions {\n    harmonicity: Positive;\n    modulationEnvelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;\n    modulation: OmniOscillatorSynthOptions;\n}\n/**\n * Base class for both AM and FM synths\n */\nexport declare abstract class ModulationSynth<Options extends ModulationSynthOptions> extends Monophonic<Options> {\n    readonly name: string;\n    /**\n     * The carrier voice.\n     */\n    protected _carrier: Synth;\n    /**\n     * The modulator voice.\n     */\n    protected _modulator: Synth;\n    /**\n     * The carrier's oscillator\n     */\n    readonly oscillator: OmniOscillator<any>;\n    /**\n     * The carrier's envelope\n     */\n    readonly envelope: AmplitudeEnvelope;\n    /**\n     * The modulator's oscillator which is applied to the amplitude of the oscillator\n     */\n    readonly modulation: OmniOscillator<any>;\n    /**\n     * The modulator's envelope\n     */\n    readonly modulationEnvelope: AmplitudeEnvelope;\n    /**\n     * The frequency control\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune in cents\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * Harmonicity is the ratio between the two voices. A harmonicity of\n     * 1 is no change. Harmonicity = 2 means a change of an octave.\n     * @example\n     * const amSynth = new Tone.AMSynth().toDestination();\n     * // pitch the modulator an octave below oscillator\n     * amSynth.harmonicity.value = 0.5;\n     * amSynth.triggerAttackRelease(\"C5\", \"4n\");\n     */\n    readonly harmonicity: Multiply;\n    /**\n     * The node where the modulation happens\n     */\n    protected _modulationNode: Gain;\n    constructor(options?: RecursivePartial<ModulationSynthOptions>);\n    static getDefaults(): ModulationSynthOptions;\n    /**\n     * Trigger the attack portion of the note\n     */\n    protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;\n    /**\n     * Trigger the release portion of the note\n     */\n    protected _triggerEnvelopeRelease(time: Seconds): this;\n    getLevelAtTime(time: Time): NormalRange;\n    dispose(): this;\n}\n",
  "instrument/MonoSynth.d.ts": "import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { EnvelopeOptions } from \"../component/envelope/Envelope\";\nimport { Filter, FilterOptions } from \"../component/filter/Filter\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Monophonic, MonophonicOptions } from \"../instrument/Monophonic\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { FrequencyEnvelope, FrequencyEnvelopeOptions } from \"../component/envelope/FrequencyEnvelope\";\nimport { NormalRange, Seconds, Time } from \"../core/type/Units\";\nimport { Signal } from \"../signal/Signal\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { OmniOscillatorSynthOptions } from \"../source/oscillator/OscillatorInterface\";\nexport interface MonoSynthOptions extends MonophonicOptions {\n    oscillator: OmniOscillatorSynthOptions;\n    envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;\n    filterEnvelope: Omit<FrequencyEnvelopeOptions, keyof ToneAudioNodeOptions>;\n    filter: Omit<FilterOptions, keyof ToneAudioNodeOptions>;\n}\n/**\n * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.\n * The amplitude of the Oscillator and the cutoff frequency of the\n * Filter are controlled by Envelopes.\n * <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">\n * @example\n * const synth = new Tone.MonoSynth({\n * \toscillator: {\n * \t\ttype: \"square\"\n * \t},\n * \tenvelope: {\n * \t\tattack: 0.1\n * \t}\n * }).toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nexport declare class MonoSynth extends Monophonic<MonoSynthOptions> {\n    readonly name = \"MonoSynth\";\n    /**\n     * The oscillator.\n     */\n    readonly oscillator: OmniOscillator<any>;\n    /**\n     * The frequency control.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune control.\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The filter.\n     */\n    readonly filter: Filter;\n    /**\n     * The filter envelope.\n     */\n    readonly filterEnvelope: FrequencyEnvelope;\n    /**\n     * The amplitude envelope.\n     */\n    readonly envelope: AmplitudeEnvelope;\n    constructor(options?: RecursivePartial<MonoSynthOptions>);\n    static getDefaults(): MonoSynthOptions;\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    protected _triggerEnvelopeAttack(time: Seconds, velocity?: number): void;\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    protected _triggerEnvelopeRelease(time: Seconds): void;\n    getLevelAtTime(time: Time): NormalRange;\n    dispose(): this;\n}\n",
  "instrument/Monophonic.d.ts": "import { FrequencyClass } from \"../core/type/Frequency\";\nimport { Cents, Frequency, NormalRange, Seconds, Time } from \"../core/type/Units\";\nimport { Instrument, InstrumentOptions } from \"../instrument/Instrument\";\nimport { Signal } from \"../signal/Signal\";\ntype onSilenceCallback = (instrument: Monophonic<any>) => void;\nexport interface MonophonicOptions extends InstrumentOptions {\n    portamento: Seconds;\n    onsilence: onSilenceCallback;\n    detune: Cents;\n}\n/**\n * Abstract base class for other monophonic instruments to extend.\n */\nexport declare abstract class Monophonic<Options extends MonophonicOptions> extends Instrument<Options> {\n    /**\n     * The glide time between notes.\n     */\n    portamento: Seconds;\n    /**\n     * Invoked when the release has finished and the output is silent.\n     */\n    onsilence: onSilenceCallback;\n    /**\n     * The instrument's frequency signal.\n     */\n    abstract readonly frequency: Signal<\"frequency\">;\n    /**\n     * The instrument's detune control signal.\n     */\n    abstract readonly detune: Signal<\"cents\">;\n    constructor(options?: Partial<MonophonicOptions>);\n    static getDefaults(): MonophonicOptions;\n    /**\n     * Trigger the attack of the note optionally with a given velocity.\n     * @param  note The note to trigger.\n     * @param  time When the note should start.\n     * @param  velocity The velocity determines how \"loud\" the note will be.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger the note a half second from now at half velocity\n     * synth.triggerAttack(\"C4\", \"+0.5\", 0.5);\n     */\n    triggerAttack(note: Frequency | FrequencyClass, time?: Time, velocity?: NormalRange): this;\n    /**\n     * Trigger the release portion of the envelope.\n     * @param  time If no time is given, the release happens immediately.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // trigger the release a second from now\n     * synth.triggerRelease(\"+1\");\n     */\n    triggerRelease(time?: Time): this;\n    /**\n     * Internal method which starts the envelope attack\n     */\n    protected abstract _triggerEnvelopeAttack(time: Seconds, velocity: NormalRange): void;\n    /**\n     * Internal method which starts the envelope release\n     */\n    protected abstract _triggerEnvelopeRelease(time: Seconds): void;\n    /**\n     * Get the level of the output at the given time. Measures\n     * the envelope(s) value at the time.\n     * @param time The time to query the envelope value\n     * @return The output level between 0-1\n     */\n    abstract getLevelAtTime(time: Time): NormalRange;\n    /**\n     * Set the note at the given time. If no time is given, the note\n     * will set immediately.\n     * @param note The note to change to.\n     * @param  time The time when the note should be set.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // change to F#6 in one quarter note from now.\n     * synth.setNote(\"F#6\", \"+4n\");\n     */\n    setNote(note: Frequency | FrequencyClass, time?: Time): this;\n}\nexport {};\n",
  "instrument/NoiseSynth.d.ts": "import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { NormalRange, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Noise, NoiseOptions } from \"../source/Noise\";\nimport { Instrument, InstrumentOptions } from \"./Instrument\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { EnvelopeOptions } from \"../component/envelope/Envelope\";\nexport interface NoiseSynthOptions extends InstrumentOptions {\n    envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;\n    noise: Omit<NoiseOptions, keyof ToneAudioNodeOptions>;\n}\n/**\n * Tone.NoiseSynth is composed of {@link Noise} through an {@link AmplitudeEnvelope}.\n * ```\n * +-------+   +-------------------+\n * | Noise +>--> AmplitudeEnvelope +>--> Output\n * +-------+   +-------------------+\n * ```\n * @example\n * const noiseSynth = new Tone.NoiseSynth().toDestination();\n * noiseSynth.triggerAttackRelease(\"8n\", 0.05);\n * @category Instrument\n */\nexport declare class NoiseSynth extends Instrument<NoiseSynthOptions> {\n    readonly name = \"NoiseSynth\";\n    /**\n     * The noise source.\n     */\n    readonly noise: Noise;\n    /**\n     * The amplitude envelope.\n     */\n    readonly envelope: AmplitudeEnvelope;\n    constructor(options?: RecursivePartial<NoiseSynthOptions>);\n    static getDefaults(): NoiseSynthOptions;\n    /**\n     * Start the attack portion of the envelopes. Unlike other\n     * instruments, Tone.NoiseSynth doesn't have a note.\n     * @example\n     * const noiseSynth = new Tone.NoiseSynth().toDestination();\n     * noiseSynth.triggerAttack();\n     */\n    triggerAttack(time?: Time, velocity?: NormalRange): this;\n    /**\n     * Start the release portion of the envelopes.\n     */\n    triggerRelease(time?: Time): this;\n    sync(): this;\n    /**\n     * Trigger the attack and then the release after the duration.\n     * @param duration The amount of time to hold the note for\n     * @param time The time the note should start\n     * @param velocity The volume of the note (0-1)\n     * @example\n     * const noiseSynth = new Tone.NoiseSynth().toDestination();\n     * // hold the note for 0.5 seconds\n     * noiseSynth.triggerAttackRelease(0.5);\n     */\n    triggerAttackRelease(duration: Time, time?: Time, velocity?: NormalRange): this;\n    dispose(): this;\n}\n",
  "instrument/PluckSynth.d.ts": "import { Frequency, NormalRange, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Instrument, InstrumentOptions } from \"./Instrument\";\nexport interface PluckSynthOptions extends InstrumentOptions {\n    attackNoise: number;\n    dampening: Frequency;\n    resonance: NormalRange;\n    release: Time;\n}\n/**\n * Karplus-Strong string synthesis.\n * @example\n * const plucky = new Tone.PluckSynth().toDestination();\n * plucky.triggerAttack(\"C4\", \"+0.5\");\n * plucky.triggerAttack(\"C3\", \"+1\");\n * plucky.triggerAttack(\"C2\", \"+1.5\");\n * plucky.triggerAttack(\"C1\", \"+2\");\n * @category Instrument\n */\nexport declare class PluckSynth extends Instrument<PluckSynthOptions> {\n    readonly name = \"PluckSynth\";\n    /**\n     * Noise burst at the beginning\n     */\n    private _noise;\n    private _lfcf;\n    /**\n     * The amount of noise at the attack.\n     * Nominal range of [0.1, 20]\n     * @min 0.1\n     * @max 20\n     */\n    attackNoise: number;\n    /**\n     * The amount of resonance of the pluck. Also correlates to the sustain duration.\n     */\n    resonance: NormalRange;\n    /**\n     * The release time which corresponds to a resonance ramp down to 0\n     */\n    release: Time;\n    constructor(options?: RecursivePartial<PluckSynthOptions>);\n    static getDefaults(): PluckSynthOptions;\n    /**\n     * The dampening control. i.e. the lowpass filter frequency of the comb filter\n     * @min 0\n     * @max 7000\n     */\n    get dampening(): Frequency;\n    set dampening(fq: Frequency);\n    triggerAttack(note: Frequency, time?: Time): this;\n    /**\n     * Ramp down the {@link resonance} to 0 over the duration of the release time.\n     */\n    triggerRelease(time?: Time): this;\n    dispose(): this;\n}\n",
  "instrument/PolySynth.d.ts": "import { Frequency, NormalRange, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Instrument, InstrumentOptions } from \"./Instrument\";\nimport { MembraneSynth, MembraneSynthOptions } from \"./MembraneSynth\";\nimport { FMSynth, FMSynthOptions } from \"./FMSynth\";\nimport { AMSynth, AMSynthOptions } from \"./AMSynth\";\nimport { MonoSynth, MonoSynthOptions } from \"./MonoSynth\";\nimport { MetalSynth, MetalSynthOptions } from \"./MetalSynth\";\nimport { Monophonic } from \"./Monophonic\";\nimport { Synth, SynthOptions } from \"./Synth\";\ntype VoiceConstructor<V> = {\n    getDefaults: () => VoiceOptions<V>;\n} & (new (...args: any[]) => V);\ntype OmitMonophonicOptions<T> = Omit<T, \"context\" | \"onsilence\">;\ntype VoiceOptions<T> = T extends MembraneSynth ? MembraneSynthOptions : T extends MetalSynth ? MetalSynthOptions : T extends FMSynth ? FMSynthOptions : T extends MonoSynth ? MonoSynthOptions : T extends AMSynth ? AMSynthOptions : T extends Synth ? SynthOptions : T extends Monophonic<infer U> ? U : never;\n/**\n * The settable synth options. excludes monophonic options.\n */\ntype PartialVoiceOptions<T> = RecursivePartial<OmitMonophonicOptions<VoiceOptions<T>>>;\nexport interface PolySynthOptions<Voice> extends InstrumentOptions {\n    maxPolyphony: number;\n    voice: VoiceConstructor<Voice>;\n    options: PartialVoiceOptions<Voice>;\n}\n/**\n * PolySynth handles voice creation and allocation for any\n * instruments passed in as the second parameter. PolySynth is\n * not a synthesizer by itself, it merely manages voices of\n * one of the other types of synths, allowing any of the\n * monophonic synthesizers to be polyphonic.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * // set the attributes across all the voices using 'set'\n * synth.set({ detune: -1200 });\n * // play a chord\n * synth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], 1);\n * @category Instrument\n */\nexport declare class PolySynth<Voice extends Monophonic<any> = Synth> extends Instrument<VoiceOptions<Voice>> {\n    readonly name: string;\n    /**\n     * The voices which are not currently in use\n     */\n    private _availableVoices;\n    /**\n     * The currently active voices\n     */\n    private _activeVoices;\n    /**\n     * All of the allocated voices for this synth.\n     */\n    private _voices;\n    /**\n     * The options that are set on the synth.\n     */\n    private options;\n    /**\n     * The polyphony limit.\n     */\n    maxPolyphony: number;\n    /**\n     * The voice constructor\n     */\n    private readonly voice;\n    /**\n     * A voice used for holding the get/set values\n     */\n    private _dummyVoice;\n    /**\n     * The GC timeout. Held so that it could be cancelled when the node is disposed.\n     */\n    private _gcTimeout;\n    /**\n     * A moving average of the number of active voices\n     */\n    private _averageActiveVoices;\n    /**\n     * @param voice The constructor of the voices\n     * @param options\tThe options object to set the synth voice\n     */\n    constructor(voice?: VoiceConstructor<Voice>, options?: PartialVoiceOptions<Voice>);\n    constructor(options?: Partial<PolySynthOptions<Voice>>);\n    static getDefaults(): PolySynthOptions<Synth>;\n    /**\n     * The number of active voices.\n     */\n    get activeVoices(): number;\n    /**\n     * Invoked when the source is done making sound, so that it can be\n     * readded to the pool of available voices\n     */\n    private _makeVoiceAvailable;\n    /**\n     * Get an available voice from the pool of available voices.\n     * If one is not available and the maxPolyphony limit is reached,\n     * steal a voice, otherwise return null.\n     */\n    private _getNextAvailableVoice;\n    /**\n     * Occasionally check if there are any allocated voices which can be cleaned up.\n     */\n    private _collectGarbage;\n    /**\n     * Internal method which triggers the attack\n     */\n    private _triggerAttack;\n    /**\n     * Internal method which triggers the release\n     */\n    private _triggerRelease;\n    /**\n     * Schedule the attack/release events. If the time is in the future, then it should set a timeout\n     * to wait for just-in-time scheduling\n     */\n    private _scheduleEvent;\n    /**\n     * Trigger the attack portion of the note\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  The start time of the note.\n     * @param velocity The velocity of the note.\n     * @example\n     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();\n     * // trigger a chord immediately with a velocity of 0.2\n     * synth.triggerAttack([\"Ab3\", \"C4\", \"F5\"], Tone.now(), 0.2);\n     */\n    triggerAttack(notes: Frequency | Frequency[], time?: Time, velocity?: NormalRange): this;\n    /**\n     * Trigger the release of the note. Unlike monophonic instruments,\n     * a note (or array of notes) needs to be passed in as the first argument.\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  When the release will be triggered.\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * poly.triggerAttack([\"Ab3\", \"C4\", \"F5\"]);\n     * // trigger the release of the given notes.\n     * poly.triggerRelease([\"Ab3\", \"C4\"], \"+1\");\n     * poly.triggerRelease(\"F5\", \"+3\");\n     */\n    triggerRelease(notes: Frequency | Frequency[], time?: Time): this;\n    /**\n     * Trigger the attack and release after the specified duration\n     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.\n     * @param  duration the duration of the note\n     * @param  time  if no time is given, defaults to now\n     * @param  velocity the velocity of the attack (0-1)\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * // can pass in an array of durations as well\n     * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"Bb4\", \"D5\"], [4, 3, 2, 1]);\n     */\n    triggerAttackRelease(notes: Frequency | Frequency[], duration: Time | Time[], time?: Time, velocity?: NormalRange): this;\n    sync(): this;\n    /**\n     * The release which is scheduled to the timeline.\n     */\n    protected _syncedRelease: (time: number) => this;\n    /**\n     * Set a member/attribute of the voices\n     * @example\n     * const poly = new Tone.PolySynth().toDestination();\n     * // set all of the voices using an options object for the synth type\n     * poly.set({\n     * \tenvelope: {\n     * \t\tattack: 0.25\n     * \t}\n     * });\n     * poly.triggerAttackRelease(\"Bb3\", 0.2);\n     */\n    set(options: RecursivePartial<VoiceOptions<Voice>>): this;\n    get(): VoiceOptions<Voice>;\n    /**\n     * Trigger the release portion of all the currently active voices immediately.\n     * Useful for silencing the synth.\n     */\n    releaseAll(time?: Time): this;\n    dispose(): this;\n}\nexport {};\n",
  "instrument/Sampler.d.ts": "import { ToneAudioBuffer } from \"../core/context/ToneAudioBuffer\";\nimport { Frequency, MidiNote, NormalRange, Note, Time } from \"../core/type/Units\";\nimport { Instrument, InstrumentOptions } from \"../instrument/Instrument\";\nimport { ToneBufferSourceCurve } from \"../source/buffer/ToneBufferSource\";\ninterface SamplesMap {\n    [note: string]: ToneAudioBuffer | AudioBuffer | string;\n    [midi: number]: ToneAudioBuffer | AudioBuffer | string;\n}\nexport interface SamplerOptions extends InstrumentOptions {\n    attack: Time;\n    release: Time;\n    onload: () => void;\n    onerror: (error: Error) => void;\n    baseUrl: string;\n    curve: ToneBufferSourceCurve;\n    urls: SamplesMap;\n}\n/**\n * Pass in an object which maps the note's pitch or midi value to the url,\n * then you can trigger the attack and release of that note like other instruments.\n * By automatically repitching the samples, it is possible to play pitches which\n * were not explicitly included which can save loading time.\n *\n * For sample or buffer playback where repitching is not necessary,\n * use {@link Player}.\n * @example\n * const sampler = new Tone.Sampler({\n * \turls: {\n * \t\tA1: \"A1.mp3\",\n * \t\tA2: \"A2.mp3\",\n * \t},\n * \tbaseUrl: \"https://tonejs.github.io/audio/casio/\",\n * \tonload: () => {\n * \t\tsampler.triggerAttackRelease([\"C1\", \"E1\", \"G1\", \"B1\"], 0.5);\n * \t}\n * }).toDestination();\n * @category Instrument\n */\nexport declare class Sampler extends Instrument<SamplerOptions> {\n    readonly name: string;\n    /**\n     * The stored and loaded buffers\n     */\n    private _buffers;\n    /**\n     * The object of all currently playing BufferSources\n     */\n    private _activeSources;\n    /**\n     * The envelope applied to the beginning of the sample.\n     * @min 0\n     * @max 1\n     */\n    attack: Time;\n    /**\n     * The envelope applied to the end of the envelope.\n     * @min 0\n     * @max 1\n     */\n    release: Time;\n    /**\n     * The shape of the attack/release curve.\n     * Either \"linear\" or \"exponential\"\n     */\n    curve: ToneBufferSourceCurve;\n    /**\n     * @param samples An object of samples mapping either Midi Note Numbers or\n     * \t\t\tScientific Pitch Notation to the url of that sample.\n     * @param onload The callback to invoke when all of the samples are loaded.\n     * @param baseUrl The root URL of all of the samples, which is prepended to all the URLs.\n     */\n    constructor(samples?: SamplesMap, onload?: () => void, baseUrl?: string);\n    /**\n     * @param samples An object of samples mapping either Midi Note Numbers or\n     * \t\t\tScientific Pitch Notation to the url of that sample.\n     * @param options The remaining options associated with the sampler\n     */\n    constructor(samples?: SamplesMap, options?: Partial<Omit<SamplerOptions, \"urls\">>);\n    constructor(options?: Partial<SamplerOptions>);\n    static getDefaults(): SamplerOptions;\n    /**\n     * Returns the difference in steps between the given midi note at the closets sample.\n     */\n    private _findClosest;\n    /**\n     * @param  notes\tThe note to play, or an array of notes.\n     * @param  time     When to play the note\n     * @param  velocity The velocity to play the sample back.\n     */\n    triggerAttack(notes: Frequency | Frequency[], time?: Time, velocity?: NormalRange): this;\n    /**\n     * @param  notes\tThe note to release, or an array of notes.\n     * @param  time     \tWhen to release the note.\n     */\n    triggerRelease(notes: Frequency | Frequency[], time?: Time): this;\n    /**\n     * Release all currently active notes.\n     * @param  time     \tWhen to release the notes.\n     */\n    releaseAll(time?: Time): this;\n    sync(): this;\n    /**\n     * Invoke the attack phase, then after the duration, invoke the release.\n     * @param  notes\tThe note to play and release, or an array of notes.\n     * @param  duration The time the note should be held\n     * @param  time     When to start the attack\n     * @param  velocity The velocity of the attack\n     */\n    triggerAttackRelease(notes: Frequency[] | Frequency, duration: Time | Time[], time?: Time, velocity?: NormalRange): this;\n    /**\n     * Add a note to the sampler.\n     * @param  note      The buffer's pitch.\n     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     */\n    add(note: Note | MidiNote, url: string | ToneAudioBuffer | AudioBuffer, callback?: () => void): this;\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded(): boolean;\n    /**\n     * Clean up\n     */\n    dispose(): this;\n}\nexport {};\n",
  "instrument/Synth.d.ts": "import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { EnvelopeOptions } from \"../component/envelope/Envelope\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { NormalRange, Seconds, Time } from \"../core/type/Units\";\nimport { RecursivePartial } from \"../core/util/Interface\";\nimport { Signal } from \"../signal/Signal\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { OmniOscillatorSynthOptions } from \"../source/oscillator/OscillatorInterface\";\nimport { Monophonic, MonophonicOptions } from \"./Monophonic\";\nexport interface SynthOptions extends MonophonicOptions {\n    oscillator: OmniOscillatorSynthOptions;\n    envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;\n}\n/**\n * Synth is composed simply of a {@link OmniOscillator} routed through an {@link AmplitudeEnvelope}.\n * ```\n * +----------------+   +-------------------+\n * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output\n * +----------------+   +-------------------+\n * ```\n * @example\n * const synth = new Tone.Synth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nexport declare class Synth<Options extends SynthOptions = SynthOptions> extends Monophonic<Options> {\n    readonly name: string;\n    /**\n     * The oscillator.\n     */\n    readonly oscillator: OmniOscillator<any>;\n    /**\n     * The frequency signal\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune signal\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The envelope\n     */\n    readonly envelope: AmplitudeEnvelope;\n    /**\n     * @param options the options available for the synth.\n     */\n    constructor(options?: RecursivePartial<SynthOptions>);\n    static getDefaults(): SynthOptions;\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    protected _triggerEnvelopeRelease(time: Seconds): void;\n    getLevelAtTime(time: Time): NormalRange;\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\n",
  "instrument/index.d.ts": "export * from \"./AMSynth\";\nexport * from \"./DuoSynth\";\nexport * from \"./FMSynth\";\nexport * from \"./MetalSynth\";\nexport * from \"./MembraneSynth\";\nexport * from \"./MonoSynth\";\nexport * from \"./NoiseSynth\";\nexport * from \"./PluckSynth\";\nexport * from \"./PolySynth\";\nexport * from \"./Sampler\";\nexport * from \"./Synth\";\n",
  "signal/Abs.d.ts": "import { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * Return the absolute value of an incoming signal.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst abs = new Tone.Abs().toDestination();\n * \tconst signal = new Tone.Signal(1);\n * \tsignal.rampTo(-1, 0.5);\n * \tsignal.connect(abs);\n * }, 0.5, 1);\n * @category Signal\n */\nexport declare class Abs extends SignalOperator<ToneAudioNodeOptions> {\n    readonly name: string;\n    /**\n     * The node which converts the audio ranges\n     */\n    private _abs;\n    /**\n     * The AudioRange input [-1, 1]\n     */\n    input: WaveShaper;\n    /**\n     * The output range [0, 1]\n     */\n    output: WaveShaper;\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\n",
  "signal/Add.d.ts": "import { Gain } from \"../core/context/Gain\";\nimport { Param } from \"../core/context/Param\";\nimport { Signal, SignalOptions } from \"./Signal\";\n/**\n * Add a signal and a number or two signals. When no value is\n * passed into the constructor, Tone.Add will sum input and `addend`\n * If a value is passed into the constructor, the it will be added to the input.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst add = new Tone.Add(2).toDestination();\n * \tadd.addend.setValueAtTime(1, 0.2);\n * \tconst signal = new Tone.Signal(2);\n * \t// add a signal and a scalar\n * \tsignal.connect(add);\n * \tsignal.setValueAtTime(1, 0.1);\n * }, 0.5, 1);\n * @category Signal\n */\nexport declare class Add extends Signal {\n    override: boolean;\n    readonly name: string;\n    /**\n     * the summing node\n     */\n    private _sum;\n    readonly input: Gain<\"gain\">;\n    readonly output: Gain<\"gain\">;\n    /**\n     * The value which is added to the input signal\n     */\n    readonly addend: Param<\"number\">;\n    /**\n     * @param value If no value is provided, will sum the input and {@link addend}.\n     */\n    constructor(value?: number);\n    constructor(options?: Partial<SignalOptions<\"number\">>);\n    static getDefaults(): SignalOptions<\"number\">;\n    dispose(): this;\n}\n",
  "signal/AudioToGain.d.ts": "import { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].\n * @see {@link GainToAudio}.\n * @category Signal\n */\nexport declare class AudioToGain extends SignalOperator<ToneAudioNodeOptions> {\n    readonly name: string;\n    /**\n     * The node which converts the audio ranges\n     */\n    private _norm;\n    /**\n     * The AudioRange input [-1, 1]\n     */\n    input: WaveShaper;\n    /**\n     * The GainRange output [0, 1]\n     */\n    output: WaveShaper;\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\n",
  "signal/GainToAudio.d.ts": "import { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].\n * @see {@link AudioToGain}.\n * @category Signal\n */\nexport declare class GainToAudio extends SignalOperator<ToneAudioNodeOptions> {\n    readonly name: string;\n    /**\n     * The node which converts the audio ranges\n     */\n    private _norm;\n    /**\n     * The NormalRange input [0, 1]\n     */\n    input: WaveShaper;\n    /**\n     * The AudioRange output [-1, 1]\n     */\n    output: WaveShaper;\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\n",
  "signal/GreaterThan.d.ts": "import { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { Signal, SignalOptions } from \"./Signal\";\nimport { Param } from \"../core/context/Param\";\nexport type GreaterThanOptions = SignalOptions<\"number\">;\n/**\n * Output 1 if the signal is greater than the value, otherwise outputs 0.\n * can compare two signals or a signal and a number.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst gt = new Tone.GreaterThan(2).toDestination();\n * \tconst sig = new Tone.Signal(4).connect(gt);\n * }, 0.1, 1);\n * @category Signal\n */\nexport declare class GreaterThan extends Signal<\"number\"> {\n    readonly name: string;\n    readonly override: boolean;\n    readonly input: ToneAudioNode;\n    readonly output: ToneAudioNode;\n    /**\n     * compare that amount to zero after subtracting\n     */\n    private _gtz;\n    /**\n     * Subtract the value from the input node\n     */\n    private _subtract;\n    /**\n     * The signal to compare to the incoming signal against.\n     * @example\n     * return Tone.Offline(() => {\n     * \t// change the comparison value\n     * \tconst gt = new Tone.GreaterThan(1.5).toDestination();\n     * \tconst signal = new Tone.Signal(1).connect(gt);\n     * \tgt.comparator.setValueAtTime(0.5, 0.1);\n     * }, 0.5, 1);\n     */\n    readonly comparator: Param<\"number\">;\n    /**\n     * @param value The value to compare to\n     */\n    constructor(value?: number);\n    constructor(options?: Partial<GreaterThanOptions>);\n    static getDefaults(): GreaterThanOptions;\n    dispose(): this;\n}\n",
  "signal/GreaterThanZero.d.ts": "import { SignalOperator, SignalOperatorOptions } from \"./SignalOperator\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nexport type GreaterThanZeroOptions = SignalOperatorOptions;\n/**\n * GreaterThanZero outputs 1 when the input is strictly greater than zero\n * @example\n * return Tone.Offline(() => {\n * \tconst gt0 = new Tone.GreaterThanZero().toDestination();\n * \tconst sig = new Tone.Signal(0.5).connect(gt0);\n * \tsig.setValueAtTime(-1, 0.05);\n * }, 0.1, 1);\n * @category Signal\n */\nexport declare class GreaterThanZero extends SignalOperator<GreaterThanZeroOptions> {\n    readonly name: string;\n    /**\n     * The waveshaper\n     */\n    private _thresh;\n    /**\n     * Scale the first thresholded signal by a large value.\n     * this will help with values which are very close to 0\n     */\n    private _scale;\n    readonly output: ToneAudioNode;\n    readonly input: ToneAudioNode;\n    constructor(options?: Partial<GreaterThanZeroOptions>);\n    dispose(): this;\n}\n",
  "signal/Multiply.d.ts": "import { Param } from \"../core/context/Param\";\nimport { Signal, SignalOptions } from \"./Signal\";\nimport { InputNode, OutputNode } from \"../core/context/ToneAudioNode\";\n/**\n * Multiply two incoming signals. Or, if a number is given in the constructor,\n * multiplies the incoming signal by that value.\n *\n * @example\n * // multiply two signals\n * const mult = new Tone.Multiply();\n * const sigA = new Tone.Signal(3);\n * const sigB = new Tone.Signal(4);\n * sigA.connect(mult);\n * sigB.connect(mult.factor);\n * // output of mult is 12.\n * @example\n * // multiply a signal and a number\n * const mult = new Tone.Multiply(10);\n * const sig = new Tone.Signal(2).connect(mult);\n * // the output of mult is 20.\n * @category Signal\n */\nexport declare class Multiply<TypeName extends \"number\" | \"positive\" = \"number\"> extends Signal<TypeName> {\n    readonly name: string;\n    /**\n     * Indicates if the value should be overridden on connection\n     */\n    readonly override = false;\n    /**\n     * the input gain node\n     */\n    private _mult;\n    /**\n     * The multiplicand input.\n     */\n    input: InputNode;\n    /**\n     * The product of the input and {@link factor}\n     */\n    output: OutputNode;\n    /**\n     * The multiplication factor. Can be set directly or a signal can be connected to it.\n     */\n    factor: Param<TypeName>;\n    /**\n     * @param value Constant value to multiple\n     */\n    constructor(value?: number);\n    constructor(options?: Partial<SignalOptions<TypeName>>);\n    static getDefaults(): SignalOptions<any>;\n    dispose(): this;\n}\n",
  "signal/Negate.d.ts": "import { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Multiply } from \"./Multiply\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Negate the incoming signal. i.e. an input signal of 10 will output -10\n *\n * @example\n * const neg = new Tone.Negate();\n * const sig = new Tone.Signal(-2).connect(neg);\n * // output of neg is positive 2.\n * @category Signal\n */\nexport declare class Negate extends SignalOperator<ToneAudioNodeOptions> {\n    readonly name: string;\n    /**\n     * negation is done by multiplying by -1\n     */\n    private _multiply;\n    /**\n     * The input and output are equal to the multiply node\n     */\n    input: Multiply<\"number\">;\n    output: Multiply<\"number\">;\n    /**\n     * clean up\n     * @returns {Negate} this\n     */\n    dispose(): this;\n}\n",
  "signal/Pow.d.ts": "import { WaveShaper } from \"./WaveShaper\";\nimport { SignalOperator } from \"./SignalOperator\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nexport interface PowOptions extends ToneAudioNodeOptions {\n    value: number;\n}\n/**\n * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]\n *\n * @example\n * const pow = new Tone.Pow(2);\n * const sig = new Tone.Signal(0.5).connect(pow);\n * // output of pow is 0.25.\n * @category Signal\n */\nexport declare class Pow extends SignalOperator<PowOptions> {\n    readonly name: string;\n    private _exponent;\n    private _exponentScaler;\n    input: WaveShaper;\n    output: WaveShaper;\n    /**\n     * @param value Constant exponent value to use\n     */\n    constructor(value?: number);\n    constructor(options?: Partial<PowOptions>);\n    static getDefaults(): PowOptions;\n    /**\n     * the function which maps the waveshaper\n     * @param exponent exponent value\n     */\n    private _expFunc;\n    /**\n     * The value of the exponent.\n     */\n    get value(): number;\n    set value(exponent: number);\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "signal/Scale.d.ts": "import { InputNode, OutputNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Add } from \"./Add\";\nimport { Multiply } from \"./Multiply\";\nimport { SignalOperator } from \"./SignalOperator\";\nexport interface ScaleOptions extends ToneAudioNodeOptions {\n    min: number;\n    max: number;\n}\n/**\n * Performs a linear scaling on an input signal.\n * Scales a NormalRange input to between\n * outputMin and outputMax.\n *\n * @example\n * const scale = new Tone.Scale(50, 100);\n * const signal = new Tone.Signal(0.5).connect(scale);\n * // the output of scale equals 75\n * @category Signal\n */\nexport declare class Scale<Options extends ScaleOptions = ScaleOptions> extends SignalOperator<Options> {\n    readonly name: string;\n    input: InputNode;\n    output: OutputNode;\n    /**\n     * Hold the multiple\n     */\n    protected _mult: Multiply;\n    /**\n     * Hold the adder\n     */\n    protected _add: Add;\n    /**\n     * Private reference to the min value\n     */\n    private _min;\n    /**\n     * Private reference to the max value\n     */\n    private _max;\n    /**\n     * @param min The output value when the input is 0.\n     * @param max The output value when the input is 1.\n     */\n    constructor(min?: number, max?: number);\n    constructor(options?: Partial<ScaleOptions>);\n    static getDefaults(): ScaleOptions;\n    /**\n     * The minimum output value. This number is output when the value input value is 0.\n     */\n    get min(): number;\n    set min(min: number);\n    /**\n     * The maximum output value. This number is output when the value input value is 1.\n     */\n    get max(): number;\n    set max(max: number);\n    /**\n     * set the values\n     */\n    private _setRange;\n    dispose(): this;\n}\n",
  "signal/ScaleExp.d.ts": "import { Scale, ScaleOptions } from \"./Scale\";\nimport { Positive } from \"../core/type/Units\";\nexport interface ScaleExpOptions extends ScaleOptions {\n    exponent: Positive;\n}\n/**\n * Performs an exponential scaling on an input signal.\n * Scales a NormalRange value [0,1] exponentially\n * to the output range of outputMin to outputMax.\n * @example\n * const scaleExp = new Tone.ScaleExp(0, 100, 2);\n * const signal = new Tone.Signal(0.5).connect(scaleExp);\n * @category Signal\n */\nexport declare class ScaleExp extends Scale<ScaleExpOptions> {\n    readonly name: string;\n    /**\n     * The exponent scaler\n     */\n    private _exp;\n    /**\n     * @param min The output value when the input is 0.\n     * @param max The output value when the input is 1.\n     * @param exponent The exponent which scales the incoming signal.\n     */\n    constructor(min?: number, max?: number, exponent?: number);\n    constructor(options?: Partial<ScaleExpOptions>);\n    static getDefaults(): ScaleExpOptions;\n    /**\n     * Instead of interpolating linearly between the {@link min} and\n     * {@link max} values, setting the exponent will interpolate between\n     * the two values with an exponential curve.\n     */\n    get exponent(): Positive;\n    set exponent(exp: Positive);\n    dispose(): this;\n}\n",
  "signal/Signal.d.ts": "import { AbstractParam } from \"../core/context/AbstractParam\";\nimport { Param } from \"../core/context/Param\";\nimport { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Time, UnitMap, UnitName } from \"../core/type/Units\";\nimport { ToneConstantSource } from \"./ToneConstantSource\";\nexport interface SignalOptions<TypeName extends UnitName> extends ToneAudioNodeOptions {\n    value: UnitMap[TypeName];\n    units: TypeName;\n    convert: boolean;\n    minValue?: number;\n    maxValue?: number;\n}\n/**\n * A signal is an audio-rate value. Tone.Signal is a core component of the library.\n * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n * has all of the methods available to native Web Audio\n * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n * as well as additional conveniences. Read more about working with signals\n * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // a scheduleable signal which can be connected to control an AudioParam or another Signal\n * const signal = new Tone.Signal({\n * \tvalue: \"C4\",\n * \tunits: \"frequency\"\n * }).connect(osc.frequency);\n * // the scheduled ramp controls the connected signal\n * signal.rampTo(\"C2\", 4, \"+0.5\");\n * @category Signal\n */\nexport declare class Signal<TypeName extends UnitName = \"number\"> extends ToneAudioNode<SignalOptions<any>> implements AbstractParam<TypeName> {\n    readonly name: string;\n    /**\n     * Indicates if the value should be overridden on connection.\n     */\n    readonly override: boolean;\n    /**\n     * The constant source node which generates the signal\n     */\n    protected _constantSource: ToneConstantSource<TypeName>;\n    readonly output: OutputNode;\n    protected _param: Param<TypeName>;\n    readonly input: InputNode;\n    /**\n     * @param value Initial value of the signal\n     * @param units The unit name, e.g. \"frequency\"\n     */\n    constructor(value?: UnitMap[TypeName], units?: TypeName);\n    constructor(options?: Partial<SignalOptions<TypeName>>);\n    static getDefaults(): SignalOptions<any>;\n    connect(destination: InputNode, outputNum?: number, inputNum?: number): this;\n    dispose(): this;\n    setValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    getValueAtTime(time: Time): UnitMap[TypeName];\n    setRampPoint(time: Time): this;\n    linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;\n    exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;\n    setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: number): this;\n    setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;\n    cancelScheduledValues(time: Time): this;\n    cancelAndHoldAtTime(time: Time): this;\n    rampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;\n    get value(): UnitMap[TypeName];\n    set value(value: UnitMap[TypeName]);\n    get convert(): boolean;\n    set convert(convert: boolean);\n    get units(): UnitName;\n    get overridden(): boolean;\n    set overridden(overridden: boolean);\n    get maxValue(): number;\n    get minValue(): number;\n    /**\n     * @see {@link Param.apply}.\n     */\n    apply(param: Param | AudioParam): this;\n}\n/**\n * When connecting from a signal, it's necessary to zero out the node destination\n * node if that node is also a signal. If the destination is not 0, then the values\n * will be summed. This method insures that the output of the destination signal will\n * be the same as the source signal, making the destination signal a pass through node.\n * @param signal The output signal to connect from\n * @param destination the destination to connect to\n * @param outputNum the optional output number\n * @param inputNum the input number\n */\nexport declare function connectSignal(signal: OutputNode, destination: InputNode, outputNum?: number, inputNum?: number): void;\n",
  "signal/SignalOperator.d.ts": "import { InputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nexport type SignalOperatorOptions = ToneAudioNodeOptions;\n/**\n * A signal operator has an input and output and modifies the signal.\n */\nexport declare abstract class SignalOperator<Options extends SignalOperatorOptions> extends ToneAudioNode<Options> {\n    constructor(options?: Partial<Options>);\n    connect(destination: InputNode, outputNum?: number, inputNum?: number): this;\n}\n",
  "signal/Subtract.d.ts": "import { Gain } from \"../core/context/Gain\";\nimport { Param } from \"../core/context/Param\";\nimport { Signal, SignalOptions } from \"../signal/Signal\";\n/**\n * Subtract the signal connected to the input is subtracted from the signal connected\n * The subtrahend.\n *\n * @example\n * // subtract a scalar from a signal\n * const sub = new Tone.Subtract(1);\n * const sig = new Tone.Signal(4).connect(sub);\n * // the output of sub is 3.\n * @example\n * // subtract two signals\n * const sub = new Tone.Subtract();\n * const sigA = new Tone.Signal(10);\n * const sigB = new Tone.Signal(2.5);\n * sigA.connect(sub);\n * sigB.connect(sub.subtrahend);\n * // output of sub is 7.5\n * @category Signal\n */\nexport declare class Subtract extends Signal {\n    override: boolean;\n    readonly name: string;\n    /**\n     * the summing node\n     */\n    private _sum;\n    readonly input: Gain;\n    readonly output: Gain;\n    /**\n     * Negate the input of the second input before connecting it to the summing node.\n     */\n    private _neg;\n    /**\n     * The value which is subtracted from the main signal\n     */\n    subtrahend: Param<\"number\">;\n    /**\n     * @param value The value to subtract from the incoming signal. If the value\n     *             is omitted, it will subtract the second signal from the first.\n     */\n    constructor(value?: number);\n    constructor(options?: Partial<SignalOptions<\"number\">>);\n    static getDefaults(): SignalOptions<\"number\">;\n    dispose(): this;\n}\n",
  "signal/SyncedSignal.d.ts": "import { Signal, SignalOptions } from \"./Signal\";\nimport { NormalRange, Time, TransportTime, UnitMap, UnitName } from \"../core/type/Units\";\nimport { OutputNode } from \"../core/context/ToneAudioNode\";\n/**\n * Adds the ability to synchronize the signal to the {@link TransportClass}\n * @category Signal\n */\nexport declare class SyncedSignal<TypeName extends UnitName = \"number\"> extends Signal<TypeName> {\n    readonly name: string;\n    /**\n     * Don't override when something is connected to the input\n     */\n    readonly override = false;\n    readonly output: OutputNode;\n    /**\n     * Keep track of the last value as an optimization.\n     */\n    private _lastVal;\n    /**\n     * The ID returned from scheduleRepeat\n     */\n    private _synced;\n    /**\n     * Remember the callback value\n     */\n    private _syncedCallback;\n    /**\n     * @param value Initial value of the signal\n     * @param units The unit name, e.g. \"frequency\"\n     */\n    constructor(value?: UnitMap[TypeName], units?: TypeName);\n    constructor(options?: Partial<SignalOptions<TypeName>>);\n    /**\n     * Callback which is invoked every tick.\n     */\n    private _onTick;\n    /**\n     * Anchor the value at the start and stop of the Transport\n     */\n    private _anchorValue;\n    getValueAtTime(time: TransportTime): UnitMap[TypeName];\n    setValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;\n    linearRampToValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;\n    exponentialRampToValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;\n    setTargetAtTime(value: any, startTime: TransportTime, timeConstant: number): this;\n    cancelScheduledValues(startTime: TransportTime): this;\n    setValueCurveAtTime(values: UnitMap[TypeName][], startTime: TransportTime, duration: Time, scaling: NormalRange): this;\n    cancelAndHoldAtTime(time: TransportTime): this;\n    setRampPoint(time: TransportTime): this;\n    exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;\n    linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;\n    targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;\n    dispose(): this;\n}\n",
  "signal/ToneConstantSource.d.ts": "import { Param } from \"../core/context/Param\";\nimport { Seconds, Time, UnitMap, UnitName } from \"../core/type/Units\";\nimport { OneShotSource, OneShotSourceOptions } from \"../source/OneShotSource\";\nexport interface ToneConstantSourceOptions<TypeName extends UnitName> extends OneShotSourceOptions {\n    convert: boolean;\n    offset: UnitMap[TypeName];\n    units: TypeName;\n    minValue?: number;\n    maxValue?: number;\n}\n/**\n * Wrapper around the native fire-and-forget ConstantSource.\n * Adds the ability to reschedule the stop method.\n * @category Signal\n */\nexport declare class ToneConstantSource<TypeName extends UnitName = \"number\"> extends OneShotSource<ToneConstantSourceOptions<TypeName>> {\n    readonly name: string;\n    /**\n     * The signal generator\n     */\n    private _source;\n    /**\n     * The offset of the signal generator\n     */\n    readonly offset: Param<TypeName>;\n    /**\n     * @param  offset   The offset value\n     */\n    constructor(offset: UnitMap[TypeName]);\n    constructor(options?: Partial<ToneConstantSourceOptions<TypeName>>);\n    static getDefaults(): ToneConstantSourceOptions<any>;\n    /**\n     * Start the source node at the given time\n     * @param  time When to start the source\n     */\n    start(time?: Time): this;\n    protected _stopSource(time?: Seconds): void;\n    dispose(): this;\n}\n",
  "signal/WaveShaper.d.ts": "import { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { SignalOperator } from \"./SignalOperator\";\nexport type WaveShaperMappingFn = (value: number, index?: number) => number;\ntype WaveShaperMapping = WaveShaperMappingFn | number[] | Float32Array;\ninterface WaveShaperOptions extends ToneAudioNodeOptions {\n    mapping?: WaveShaperMapping;\n    length: number;\n    curve?: number[] | Float32Array;\n}\n/**\n * Wraps the native Web Audio API\n * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // multiply the output of the signal by 2 using the waveshaper's function\n * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);\n * const signal = new Tone.Signal(440).connect(timesTwo);\n * @category Signal\n */\nexport declare class WaveShaper extends SignalOperator<WaveShaperOptions> {\n    readonly name: string;\n    /**\n     * the waveshaper node\n     */\n    private _shaper;\n    /**\n     * The input to the waveshaper node.\n     */\n    input: WaveShaperNode;\n    /**\n     * The output from the waveshaper node\n     */\n    output: WaveShaperNode;\n    /**\n     * @param mapping The function used to define the values.\n     *                The mapping function should take two arguments:\n     *                the first is the value at the current position\n     *                and the second is the array position.\n     *                If the argument is an array, that array will be\n     *                set as the wave shaping function. The input\n     *                signal is an AudioRange [-1, 1] value and the output\n     *                signal can take on any numerical values.\n     *\n     * @param length The length of the WaveShaperNode buffer.\n     */\n    constructor(mapping?: WaveShaperMapping, length?: number);\n    constructor(options?: Partial<WaveShaperOptions>);\n    static getDefaults(): WaveShaperOptions;\n    /**\n     * Uses a mapping function to set the value of the curve.\n     * @param mapping The function used to define the values.\n     *                The mapping function take two arguments:\n     *                the first is the value at the current position\n     *                which goes from -1 to 1 over the number of elements\n     *                in the curve array. The second argument is the array position.\n     * @example\n     * const shaper = new Tone.WaveShaper();\n     * // map the input signal from [-1, 1] to [0, 10]\n     * shaper.setMap((val, index) => (val + 1) * 5);\n     */\n    setMap(mapping: WaveShaperMappingFn, length?: number): this;\n    /**\n     * The array to set as the waveshaper curve. For linear curves\n     * array length does not make much difference, but for complex curves\n     * longer arrays will provide smoother interpolation.\n     */\n    get curve(): Float32Array | null;\n    set curve(mapping: Float32Array | null);\n    /**\n     * Specifies what type of oversampling (if any) should be used when\n     * applying the shaping curve. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample(): OverSampleType;\n    set oversample(oversampling: OverSampleType);\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "signal/Zero.d.ts": "import { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Tone.Zero outputs 0's at audio-rate. The reason this has to be\n * it's own class is that many browsers optimize out Tone.Signal\n * with a value of 0 and will not process nodes further down the graph.\n * @category Signal\n */\nexport declare class Zero extends SignalOperator<ToneAudioNodeOptions> {\n    readonly name: string;\n    /**\n     * The gain node which connects the constant source to the output\n     */\n    private _gain;\n    /**\n     * Only outputs 0\n     */\n    output: Gain<\"gain\">;\n    /**\n     * no input node\n     */\n    input: undefined;\n    constructor(options?: Partial<ToneAudioNodeOptions>);\n    /**\n     * clean up\n     */\n    dispose(): this;\n}\n",
  "signal/index.d.ts": "export * from \"./Add\";\nexport * from \"./Abs\";\nexport * from \"./AudioToGain\";\nexport * from \"./GainToAudio\";\nexport * from \"./GreaterThan\";\nexport * from \"./GreaterThanZero\";\nexport * from \"./Multiply\";\nexport * from \"./Negate\";\nexport * from \"./Pow\";\nexport * from \"./Signal\";\nexport * from \"./Scale\";\nexport * from \"./ScaleExp\";\nexport * from \"./Subtract\";\nexport * from \"./SyncedSignal\";\nexport * from \"./WaveShaper\";\nexport * from \"./Zero\";\n",
  "source/Noise.d.ts": "import { Positive, Time } from \"../core/type/Units\";\nimport { Source, SourceOptions } from \"../source/Source\";\nexport type NoiseType = \"white\" | \"brown\" | \"pink\";\nexport interface NoiseOptions extends SourceOptions {\n    type: NoiseType;\n    playbackRate: Positive;\n    fadeIn: Time;\n    fadeOut: Time;\n}\n/**\n * Noise is a noise generator. It uses looped noise buffers to save on performance.\n * Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).\n *\n * @example\n * // initialize the noise and start\n * const noise = new Tone.Noise(\"pink\").start();\n * // make an autofilter to shape the noise\n * const autoFilter = new Tone.AutoFilter({\n * \tfrequency: \"8n\",\n * \tbaseFrequency: 200,\n * \toctaves: 8\n * }).toDestination().start();\n * // connect the noise\n * noise.connect(autoFilter);\n * // start the autofilter LFO\n * autoFilter.start();\n * @category Source\n */\nexport declare class Noise extends Source<NoiseOptions> {\n    readonly name: string;\n    /**\n     * Private reference to the source\n     */\n    private _source;\n    /**\n     * private reference to the type\n     */\n    private _type;\n    /**\n     * The playback rate of the noise. Affects\n     * the \"frequency\" of the noise.\n     */\n    private _playbackRate;\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    protected _fadeIn: Time;\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    protected _fadeOut: Time;\n    /**\n     * @param type the noise type (white|pink|brown)\n     */\n    constructor(type?: NoiseType);\n    constructor(options?: Partial<NoiseOptions>);\n    static getDefaults(): NoiseOptions;\n    /**\n     * The type of the noise. Can be \"white\", \"brown\", or \"pink\".\n     * @example\n     * const noise = new Tone.Noise().toDestination().start();\n     * noise.type = \"brown\";\n     */\n    get type(): NoiseType;\n    set type(type: NoiseType);\n    /**\n     * The playback rate of the noise. Affects\n     * the \"frequency\" of the noise.\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * internal start method\n     */\n    protected _start(time?: Time): void;\n    /**\n     * internal stop method\n     */\n    protected _stop(time?: Time): void;\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn(): Time;\n    set fadeIn(time: Time);\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut(): Time;\n    set fadeOut(time: Time);\n    protected _restart(time?: Time): void;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/OneShotSource.d.ts": "import { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { GainFactor, Seconds, Time } from \"../core/type/Units\";\nimport { BasicPlaybackState } from \"../core/util/StateTimeline\";\nexport type OneShotSourceCurve = \"linear\" | \"exponential\";\ntype onEndedCallback = (source: OneShotSource<any>) => void;\nexport interface OneShotSourceOptions extends ToneAudioNodeOptions {\n    onended: onEndedCallback;\n    fadeIn: Time;\n    fadeOut: Time;\n    curve: OneShotSourceCurve;\n}\n/**\n * Base class for fire-and-forget nodes\n */\nexport declare abstract class OneShotSource<Options extends ToneAudioNodeOptions> extends ToneAudioNode<Options> {\n    /**\n     * The callback to invoke after the\n     * source is done playing.\n     */\n    onended: onEndedCallback;\n    /**\n     * Sources do not have input nodes\n     */\n    input: undefined;\n    /**\n     * The start time\n     */\n    protected _startTime: number;\n    /**\n     * The stop time\n     */\n    protected _stopTime: number;\n    /**\n     * The id of the timeout\n     */\n    private _timeout;\n    /**\n     * The public output node\n     */\n    output: Gain;\n    /**\n     * The output gain node.\n     */\n    protected _gainNode: Gain<\"gain\">;\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    protected _fadeIn: Time;\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    protected _fadeOut: Time;\n    /**\n     * The curve applied to the fades, either \"linear\" or \"exponential\"\n     */\n    protected _curve: OneShotSourceCurve;\n    constructor(options: OneShotSourceOptions);\n    static getDefaults(): OneShotSourceOptions;\n    /**\n     * Stop the source node\n     */\n    protected abstract _stopSource(time: Seconds): void;\n    /**\n     * Start the source node at the given time\n     * @param  time When to start the node\n     */\n    protected abstract start(time?: Time): this;\n    /**\n     * Start the source at the given time\n     * @param  time When to start the source\n     */\n    protected _startGain(time: Seconds, gain?: GainFactor): this;\n    /**\n     * Stop the source node at the given time.\n     * @param time When to stop the source\n     */\n    stop(time?: Time): this;\n    /**\n     * Stop the source at the given time\n     * @param  time When to stop the source\n     */\n    protected _stopGain(time: Seconds): this;\n    /**\n     * Invoke the onended callback\n     */\n    protected _onended(): void;\n    /**\n     * Get the playback state at the given time\n     */\n    getStateAtTime: (time: Time) => BasicPlaybackState;\n    /**\n     * Get the playback state at the current time\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * Cancel a scheduled stop event\n     */\n    cancelStop(): this;\n    dispose(): this;\n}\nexport {};\n",
  "source/Source.d.ts": "import  \"../core/context/Destination\";\nimport  \"../core/clock/Transport\";\nimport { Param } from \"../core/context/Param\";\nimport { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Decibels, Seconds, Time } from \"../core/type/Units\";\nimport { BasicPlaybackState, StateTimeline } from \"../core/util/StateTimeline\";\ntype onStopCallback = (source: Source<any>) => void;\nexport interface SourceOptions extends ToneAudioNodeOptions {\n    volume: Decibels;\n    mute: boolean;\n    onstop: onStopCallback;\n}\n/**\n * Base class for sources.\n * start/stop of this.context.transport.\n *\n * ```\n * // Multiple state change events can be chained together,\n * // but must be set in the correct order and with ascending times\n * // OK\n * state.start().stop(\"+0.2\");\n * // OK\n * state.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n * // BAD\n * state.stop(\"+0.2\").start();\n * // BAD\n * state.start(\"+0.3\").stop(\"+0.2\");\n * ```\n */\nexport declare abstract class Source<Options extends SourceOptions> extends ToneAudioNode<Options> {\n    /**\n     * The output volume node\n     */\n    private _volume;\n    /**\n     * The output node\n     */\n    output: OutputNode;\n    /**\n     * Sources have no inputs\n     */\n    input: undefined;\n    /**\n     * The volume of the output in decibels.\n     * @example\n     * const source = new Tone.PWMOscillator().toDestination();\n     * source.volume.value = -6;\n     */\n    volume: Param<\"decibels\">;\n    /**\n     * The callback to invoke when the source is stopped.\n     */\n    onstop: onStopCallback;\n    /**\n     * Keep track of the scheduled state.\n     */\n    protected _state: StateTimeline<{\n        duration?: Seconds;\n        offset?: Seconds;\n        /**\n         * Either the buffer is explicitly scheduled to end using the stop method,\n         * or it's implicitly ended when the buffer is over.\n         */\n        implicitEnd?: boolean;\n    }>;\n    /**\n     * The synced `start` callback function from the transport\n     */\n    protected _synced: boolean;\n    /**\n     * Keep track of all of the scheduled event ids\n     */\n    private _scheduled;\n    /**\n     * Placeholder functions for syncing/unsyncing to transport\n     */\n    private _syncedStart;\n    private _syncedStop;\n    constructor(options: SourceOptions);\n    static getDefaults(): SourceOptions;\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/ahntone_c3.mp3\", () => {\n     * \tplayer.start();\n     * \tconsole.log(player.state);\n     * }).toDestination();\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * Mute the output.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // mute the output\n     * osc.mute = true;\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    protected abstract _start(time: Time, offset?: Time, duration?: Time): void;\n    protected abstract _stop(time: Time): void;\n    protected abstract _restart(time: Seconds, offset?: Time, duration?: Time): void;\n    /**\n     * Ensure that the scheduled time is not before the current time.\n     * Should only be used when scheduled unsynced.\n     */\n    private _clampToCurrentTime;\n    /**\n     * Start the source at the specified time. If no time is given,\n     * start the source now.\n     * @param  time When the source should be started.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start(\"+0.5\"); // starts the source 0.5 seconds from now\n     */\n    start(time?: Time, offset?: Time, duration?: Time): this;\n    /**\n     * Stop the source at the specified time. If no time is given,\n     * stop the source now.\n     * @param  time When the source should be stopped.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start();\n     * source.stop(\"+0.5\"); // stops the source 0.5 seconds from now\n     */\n    stop(time?: Time): this;\n    /**\n     * Restart the source.\n     */\n    restart(time?: Time, offset?: Time, duration?: Time): this;\n    /**\n     * Sync the source to the Transport so that all subsequent\n     * calls to `start` and `stop` are synced to the TransportTime\n     * instead of the AudioContext time.\n     *\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline\n     * osc.sync().start(0).stop(0.3);\n     * // start the transport.\n     * Tone.Transport.start();\n     * // set it to loop once a second\n     * Tone.Transport.loop = true;\n     * Tone.Transport.loopEnd = 1;\n     */\n    sync(): this;\n    /**\n     * Unsync the source to the Transport.\n     * @see {@link sync}\n     */\n    unsync(): this;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\nexport {};\n",
  "source/UserMedia.d.ts": "import { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from \"../core/context/ToneAudioNode\";\nimport { Decibels } from \"../core/type/Units\";\nimport { Param } from \"../core/context/Param\";\nexport interface UserMediaOptions extends ToneAudioNodeOptions {\n    volume: Decibels;\n    mute: boolean;\n}\n/**\n * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.\n * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n * to see which browsers are supported. Access to an external input\n * is limited to secure (HTTPS) connections.\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia().connect(meter);\n * mic.open().then(() => {\n * \t// promise resolves when input is available\n * \tconsole.log(\"mic open\");\n * \t// print the incoming mic levels in decibels\n * \tsetInterval(() => console.log(meter.getValue()), 100);\n * }).catch(e => {\n * \t// promise is rejected when the user doesn't have or allow mic access\n * \tconsole.log(\"mic not open\");\n * });\n * @category Source\n */\nexport declare class UserMedia extends ToneAudioNode<UserMediaOptions> {\n    readonly name: string;\n    readonly input: undefined;\n    readonly output: OutputNode;\n    /**\n     * The MediaStreamNode\n     */\n    private _mediaStream?;\n    /**\n     * The media stream created by getUserMedia.\n     */\n    private _stream?;\n    /**\n     * The open device\n     */\n    private _device?;\n    /**\n     * The output volume node\n     */\n    private _volume;\n    /**\n     * The volume of the output in decibels.\n     */\n    readonly volume: Param<\"decibels\">;\n    /**\n     * @param volume The level of the input in decibels\n     */\n    constructor(volume?: Decibels);\n    constructor(options?: Partial<UserMediaOptions>);\n    static getDefaults(): UserMediaOptions;\n    /**\n     * Open the media stream. If a string is passed in, it is assumed\n     * to be the label or id of the stream, if a number is passed in,\n     * it is the input number of the stream.\n     * @param  labelOrId The label or id of the audio input media device.\n     *                   With no argument, the default stream is opened.\n     * @return The promise is resolved when the stream is open.\n     */\n    open(labelOrId?: string | number): Promise<this>;\n    /**\n     * Close the media stream\n     */\n    close(): this;\n    /**\n     * Returns a promise which resolves with the list of audio input devices available.\n     * @return The promise that is resolved with the devices\n     * @example\n     * Tone.UserMedia.enumerateDevices().then((devices) => {\n     * \t// print the device labels\n     * \tconsole.log(devices.map(device => device.label));\n     * });\n     */\n    static enumerateDevices(): Promise<MediaDeviceInfo[]>;\n    /**\n     * Returns the playback state of the source, \"started\" when the microphone is open\n     * and \"stopped\" when the mic is closed.\n     */\n    get state(): \"started\" | \"stopped\";\n    /**\n     * Returns an identifier for the represented device that is\n     * persisted across sessions. It is un-guessable by other applications and\n     * unique to the origin of the calling application. It is reset when the\n     * user clears cookies (for Private Browsing, a different identifier is\n     * used that is not persisted across sessions). Returns undefined when the\n     * device is not open.\n     */\n    get deviceId(): string | undefined;\n    /**\n     * Returns a group identifier. Two devices have the\n     * same group identifier if they belong to the same physical device.\n     * Returns null  when the device is not open.\n     */\n    get groupId(): string | undefined;\n    /**\n     * Returns a label describing this device (for example \"Built-in Microphone\").\n     * Returns undefined when the device is not open or label is not available\n     * because of permissions.\n     */\n    get label(): string | undefined;\n    /**\n     * Mute the output.\n     * @example\n     * const mic = new Tone.UserMedia();\n     * mic.open().then(() => {\n     * \t// promise resolves when input is available\n     * });\n     * // mute the output\n     * mic.mute = true;\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    dispose(): this;\n    /**\n     * If getUserMedia is supported by the browser.\n     */\n    static get supported(): boolean;\n}\n",
  "source/buffer/GrainPlayer.d.ts": "import { Source, SourceOptions } from \"../Source\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { Cents, Positive, Seconds, Time } from \"../../core/type/Units\";\ninterface GrainPlayerOptions extends SourceOptions {\n    onload: () => void;\n    onerror: (error: Error) => void;\n    reverse: boolean;\n    url?: ToneAudioBuffer | string | AudioBuffer;\n    overlap: Seconds;\n    grainSize: Seconds;\n    playbackRate: Positive;\n    detune: Cents;\n    loop: boolean;\n    loopStart: Time;\n    loopEnd: Time;\n}\n/**\n * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n * amount of time each small chunk of audio is played for and the overlap is the\n * amount of crossfading transition time between successive grains.\n * @category Source\n */\nexport declare class GrainPlayer extends Source<GrainPlayerOptions> {\n    readonly name: string;\n    /**\n     * The audio buffer belonging to the player.\n     */\n    buffer: ToneAudioBuffer;\n    /**\n     * Create a repeating tick to schedule the grains.\n     */\n    private _clock;\n    /**\n     * Internal loopStart value\n     */\n    private _loopStart;\n    /**\n     * Internal loopStart value\n     */\n    private _loopEnd;\n    /**\n     * All of the currently playing BufferSources\n     */\n    private _activeSources;\n    /**\n     * Internal reference to the playback rate\n     */\n    private _playbackRate;\n    /**\n     * Internal grain size reference;\n     */\n    private _grainSize;\n    /**\n     * Internal overlap reference;\n     */\n    private _overlap;\n    /**\n     * Adjust the pitch independently of the playbackRate.\n     */\n    detune: Cents;\n    /**\n     * If the buffer should loop back to the loopStart when completed\n     */\n    loop: boolean;\n    /**\n     * @param url Either the AudioBuffer or the url from which to load the AudioBuffer\n     * @param onload The function to invoke when the buffer is loaded.\n     */\n    constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);\n    constructor(options?: Partial<GrainPlayerOptions>);\n    static getDefaults(): GrainPlayerOptions;\n    /**\n     * Internal start method\n     */\n    protected _start(time?: Time, offset?: Time, duration?: Time): void;\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time?: Seconds, offset?: Time, duration?: Time): this;\n    protected _restart(time?: Seconds, offset?: Time, duration?: Time): void;\n    /**\n     * Internal stop method\n     */\n    protected _stop(time?: Time): void;\n    /**\n     * Invoked when the clock is stopped\n     */\n    private _onstop;\n    /**\n     * Invoked on each clock tick. scheduled a new grain at this time.\n     */\n    private _tick;\n    /**\n     * The playback rate of the sample\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * The loop start time.\n     */\n    get loopStart(): Time;\n    set loopStart(time: Time);\n    /**\n     * The loop end time.\n     */\n    get loopEnd(): Time;\n    set loopEnd(time: Time);\n    /**\n     * The direction the buffer should play in\n     */\n    get reverse(): boolean;\n    set reverse(rev: boolean);\n    /**\n     * The size of each chunk of audio that the\n     * buffer is chopped into and played back at.\n     */\n    get grainSize(): Time;\n    set grainSize(size: Time);\n    /**\n     * The duration of the cross-fade between successive grains.\n     */\n    get overlap(): Time;\n    set overlap(time: Time);\n    /**\n     * If all the buffer is loaded\n     */\n    get loaded(): boolean;\n    dispose(): this;\n}\nexport {};\n",
  "source/buffer/Player.d.ts": "import { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { Positive, Seconds, Time } from \"../../core/type/Units\";\nimport { Source, SourceOptions } from \"../Source\";\nexport interface PlayerOptions extends SourceOptions {\n    onload: () => void;\n    onerror: (error: Error) => void;\n    playbackRate: Positive;\n    loop: boolean;\n    autostart: boolean;\n    loopStart: Time;\n    loopEnd: Time;\n    reverse: boolean;\n    fadeIn: Time;\n    fadeOut: Time;\n    url?: ToneAudioBuffer | string | AudioBuffer;\n}\n/**\n * Player is an audio file player with start, loop, and stop functions.\n * @example\n * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gong_1.mp3\").toDestination();\n * // play as soon as the buffer is loaded\n * player.autostart = true;\n * @category Source\n */\nexport declare class Player extends Source<PlayerOptions> {\n    readonly name: string;\n    /**\n     * If the file should play as soon\n     * as the buffer is loaded.\n     */\n    autostart: boolean;\n    /**\n     * The buffer\n     */\n    private _buffer;\n    /**\n     * if the buffer should loop once it's over\n     */\n    private _loop;\n    /**\n     * if 'loop' is true, the loop will start at this position\n     */\n    private _loopStart;\n    /**\n     * if 'loop' is true, the loop will end at this position\n     */\n    private _loopEnd;\n    /**\n     * the playback rate\n     */\n    private _playbackRate;\n    /**\n     * All of the active buffer source nodes\n     */\n    private _activeSources;\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    fadeIn: Time;\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    fadeOut: Time;\n    /**\n     * @param url Either the AudioBuffer or the url from which to load the AudioBuffer\n     * @param onload The function to invoke when the buffer is loaded.\n     */\n    constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);\n    constructor(options?: Partial<PlayerOptions>);\n    static getDefaults(): PlayerOptions;\n    /**\n     * Load the audio file as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * Note: this does not need to be called if a url\n     * was passed in to the constructor. Only use this\n     * if you want to manually load a new url.\n     * @param url The url of the buffer to load. Filetype support depends on the browser.\n     */\n    load(url: string): Promise<this>;\n    /**\n     * Internal callback when the buffer is loaded.\n     */\n    private _onload;\n    /**\n     * Internal callback when the buffer is done playing.\n     */\n    private _onSourceEnd;\n    /**\n     * Play the buffer at the given startTime. Optionally add an offset\n     * and/or duration which will play the buffer from a position\n     * within the buffer for the given duration.\n     *\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     */\n    start(time?: Time, offset?: Time, duration?: Time): this;\n    /**\n     * Internal start method\n     */\n    protected _start(startTime?: Time, offset?: Time, duration?: Time): void;\n    /**\n     * Stop playback.\n     */\n    protected _stop(time?: Time): void;\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time?: Seconds, offset?: Time, duration?: Time): this;\n    protected _restart(time?: Seconds, offset?: Time, duration?: Time): void;\n    /**\n     * Seek to a specific time in the player's buffer. If the\n     * source is no longer playing at that time, it will stop.\n     * @param offset The time to seek to.\n     * @param when The time for the seek event to occur.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3\", () => {\n     * \tplayer.start();\n     * \t// seek to the offset in 1 second from now\n     * \tplayer.seek(0.4, \"+1\");\n     * }).toDestination();\n     */\n    seek(offset: Time, when?: Time): this;\n    /**\n     * Set the loop start and end. Will only loop if loop is set to true.\n     * @param loopStart The loop start time\n     * @param loopEnd The loop end time\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3\").toDestination();\n     * // loop between the given points\n     * player.setLoopPoints(0.2, 0.3);\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    setLoopPoints(loopStart: Time, loopEnd: Time): this;\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart(): Time;\n    set loopStart(loopStart: Time);\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd(): Time;\n    set loopEnd(loopEnd: Time);\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer(): ToneAudioBuffer;\n    set buffer(buffer: ToneAudioBuffer);\n    /**\n     * If the buffer should loop once it's over.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/breakbeat.mp3\").toDestination();\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    get loop(): boolean;\n    set loop(loop: boolean);\n    /**\n     * Normal speed is 1. The pitch will change with the playback rate.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3\").toDestination();\n     * // play at 1/4 speed\n     * player.playbackRate = 0.25;\n     * // play as soon as the buffer is loaded\n     * player.autostart = true;\n     */\n    get playbackRate(): Positive;\n    set playbackRate(rate: Positive);\n    /**\n     * If the buffer should be reversed. Note that this sets the underlying {@link ToneAudioBuffer.reverse}, so\n     * if multiple players are pointing at the same ToneAudioBuffer, they will all be reversed.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/chime_1.mp3\").toDestination();\n     * player.autostart = true;\n     * player.reverse = true;\n     */\n    get reverse(): boolean;\n    set reverse(rev: boolean);\n    /**\n     * If the buffer is loaded\n     */\n    get loaded(): boolean;\n    dispose(): this;\n}\n",
  "source/buffer/Players.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { ToneAudioBuffersUrlMap } from \"../../core/context/ToneAudioBuffers\";\nimport { OutputNode, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Decibels, Time } from \"../../core/type/Units\";\nimport { BasicPlaybackState } from \"../../core/util/StateTimeline\";\nimport { SourceOptions } from \"../Source\";\nimport { Player } from \"./Player\";\nexport interface PlayersOptions extends SourceOptions {\n    urls: ToneAudioBuffersUrlMap;\n    volume: Decibels;\n    mute: boolean;\n    onload: () => void;\n    onerror: (error: Error) => void;\n    baseUrl: string;\n    fadeIn: Time;\n    fadeOut: Time;\n}\n/**\n * Players combines multiple {@link Player} objects.\n * @category Source\n */\nexport declare class Players extends ToneAudioNode<PlayersOptions> {\n    readonly name: string;\n    /**\n     * The output volume node\n     */\n    private _volume;\n    /**\n     * The volume of the output in decibels.\n     */\n    readonly volume: Param<\"decibels\">;\n    /**\n     * The combined output of all of the players\n     */\n    readonly output: OutputNode;\n    /**\n     * Players has no input.\n     */\n    readonly input: undefined;\n    /**\n     * The container of all of the players\n     */\n    private _players;\n    /**\n     * The container of all the buffers\n     */\n    private _buffers;\n    /**\n     * private holder of the fadeIn time\n     */\n    private _fadeIn;\n    /**\n     * private holder of the fadeOut time\n     */\n    private _fadeOut;\n    /**\n     * @param urls An object mapping a name to a url.\n     * @param onload The function to invoke when all buffers are loaded.\n     */\n    constructor(urls?: ToneAudioBuffersUrlMap, onload?: () => void);\n    /**\n     * @param urls An object mapping a name to a url.\n     * @param options The remaining options associated with the players\n     */\n    constructor(urls?: ToneAudioBuffersUrlMap, options?: Partial<Omit<PlayersOptions, \"urls\">>);\n    constructor(options?: Partial<PlayersOptions>);\n    static getDefaults(): PlayersOptions;\n    /**\n     * Mute the output.\n     */\n    get mute(): boolean;\n    set mute(mute: boolean);\n    /**\n     * The fadeIn time of the envelope applied to the source.\n     */\n    get fadeIn(): Time;\n    set fadeIn(fadeIn: Time);\n    /**\n     * The fadeOut time of the each of the sources.\n     */\n    get fadeOut(): Time;\n    set fadeOut(fadeOut: Time);\n    /**\n     * The state of the players object. Returns \"started\" if any of the players are playing.\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param name  The key or index of the buffer.\n     */\n    has(name: string): boolean;\n    /**\n     * Get a player by name.\n     * @param  name  The players name as defined in the constructor object or `add` method.\n     */\n    player(name: string): Player;\n    /**\n     * If all the buffers are loaded or not\n     */\n    get loaded(): boolean;\n    /**\n     * Add a player by name and url to the Players\n     * @param  name A unique name to give the player\n     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.\n     * @param callback  The callback to invoke when the url is loaded.\n     * @example\n     * const players = new Tone.Players();\n     * players.add(\"gong\", \"https://tonejs.github.io/audio/berklee/gong_1.mp3\", () => {\n     * \tconsole.log(\"gong loaded\");\n     * \tplayers.player(\"gong\").start();\n     * });\n     */\n    add(name: string, url: string | ToneAudioBuffer | AudioBuffer, callback?: () => void): this;\n    /**\n     * Stop all of the players at the given time\n     * @param time The time to stop all of the players.\n     */\n    stopAll(time?: Time): this;\n    dispose(): this;\n}\n",
  "source/buffer/ToneBufferSource.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { GainFactor, Positive, Seconds, Time } from \"../../core/type/Units\";\nimport { OneShotSource, OneShotSourceCurve, OneShotSourceOptions } from \"../OneShotSource\";\nexport type ToneBufferSourceCurve = OneShotSourceCurve;\nexport interface ToneBufferSourceOptions extends OneShotSourceOptions {\n    url: string | AudioBuffer | ToneAudioBuffer;\n    curve: ToneBufferSourceCurve;\n    playbackRate: Positive;\n    fadeIn: Time;\n    fadeOut: Time;\n    loopStart: Time;\n    loopEnd: Time;\n    loop: boolean;\n    onload: () => void;\n    onerror: (error: Error) => void;\n}\n/**\n * Wrapper around the native BufferSourceNode.\n * @category Source\n */\nexport declare class ToneBufferSource extends OneShotSource<ToneBufferSourceOptions> {\n    readonly name: string;\n    /**\n     * The oscillator\n     */\n    private _source;\n    protected _internalChannels: AudioBufferSourceNode[];\n    /**\n     * The frequency of the oscillator\n     */\n    readonly playbackRate: Param<\"positive\">;\n    /**\n     * The private instance of the buffer object\n     */\n    private _buffer;\n    /**\n     * indicators if the source has started/stopped\n     */\n    private _sourceStarted;\n    private _sourceStopped;\n    /**\n     * @param url The buffer to play or url to load\n     * @param onload The callback to invoke when the buffer is done playing.\n     */\n    constructor(url?: ToneAudioBuffer | AudioBuffer | string, onload?: () => void);\n    constructor(options?: Partial<ToneBufferSourceOptions>);\n    static getDefaults(): ToneBufferSourceOptions;\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn(): Time;\n    set fadeIn(t: Time);\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut(): Time;\n    set fadeOut(t: Time);\n    /**\n     * The curve applied to the fades, either \"linear\" or \"exponential\"\n     */\n    get curve(): ToneBufferSourceCurve;\n    set curve(t: ToneBufferSourceCurve);\n    /**\n     * Start the buffer\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     * @param  gain  The gain to play the buffer back at.\n     */\n    start(time?: Time, offset?: Time, duration?: Time, gain?: GainFactor): this;\n    protected _stopSource(time?: Seconds): void;\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart(): Time;\n    set loopStart(loopStart: Time);\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd(): Time;\n    set loopEnd(loopEnd: Time);\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer(): ToneAudioBuffer;\n    set buffer(buffer: ToneAudioBuffer);\n    /**\n     * If the buffer should loop once it's over.\n     */\n    get loop(): boolean;\n    set loop(loop: boolean);\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/index.d.ts": "export * from \"./Noise\";\nexport * from \"./UserMedia\";\nexport * from \"./oscillator/Oscillator\";\nexport * from \"./oscillator/AMOscillator\";\nexport * from \"./oscillator/FMOscillator\";\nexport * from \"./oscillator/PulseOscillator\";\nexport * from \"./oscillator/FatOscillator\";\nexport * from \"./oscillator/PWMOscillator\";\nexport * from \"./oscillator/OmniOscillator\";\nexport * from \"./oscillator/ToneOscillatorNode\";\nexport * from \"./oscillator/LFO\";\nexport * from \"./buffer/ToneBufferSource\";\nexport * from \"./buffer/Player\";\nexport * from \"./buffer/Players\";\nexport * from \"./buffer/GrainPlayer\";\n",
  "source/oscillator/AMOscillator.d.ts": "import { Degrees, Frequency, Seconds } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { AMConstructorOptions, AMOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from \"./OscillatorInterface\";\nexport { AMOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * An amplitude modulated oscillator node. It is implemented with\n * two oscillators, one which modulators the other's amplitude\n * through a gain node.\n * ```\n *    +-------------+       +----------+\n *    | Carrier Osc +>------> GainNode |\n *    +-------------+       |          +--->Output\n *                      +---> gain     |\n * +---------------+    |   +----------+\n * | Modulator Osc +>---+\n * +---------------+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst amOsc = new Tone.AMOscillator(30, \"sine\", \"square\").toDestination().start();\n * }, 0.2, 1);\n * @category Source\n */\nexport declare class AMOscillator extends Source<AMOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    /**\n     * The carrier oscillator\n     */\n    private _carrier;\n    readonly frequency: Signal<\"frequency\">;\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The modulating oscillator\n     */\n    private _modulator;\n    /**\n     * convert the -1,1 output to 0,1\n     */\n    private _modulationScale;\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * A harmonicity of 1 gives both oscillators the same frequency.\n     * Harmonicity = 2 means a change of an octave.\n     * @example\n     * const amOsc = new Tone.AMOscillator(\"D2\").toDestination().start();\n     * Tone.Transport.scheduleRepeat(time => {\n     * \tamOsc.harmonicity.setValueAtTime(1, time);\n     * \tamOsc.harmonicity.setValueAtTime(0.5, time + 0.5);\n     * \tamOsc.harmonicity.setValueAtTime(1.5, time + 1);\n     * \tamOsc.harmonicity.setValueAtTime(1, time + 2);\n     * \tamOsc.harmonicity.linearRampToValueAtTime(2, time + 4);\n     * }, 4);\n     * Tone.Transport.start();\n     */\n    readonly harmonicity: Signal<\"positive\">;\n    /**\n     * the node where the modulation happens\n     */\n    private _modulationNode;\n    /**\n     * @param frequency The starting frequency of the oscillator.\n     * @param type The type of the carrier oscillator.\n     * @param modulationType The type of the modulator oscillator.\n     */\n    constructor(frequency?: Frequency, type?: ToneOscillatorType, modulationType?: ToneOscillatorType);\n    constructor(options?: Partial<AMConstructorOptions>);\n    static getDefaults(): AMOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Seconds): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time: Seconds): void;\n    protected _restart(time: Seconds): void;\n    /**\n     * The type of the carrier oscillator\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    get baseType(): OscillatorType;\n    set baseType(baseType: OscillatorType);\n    get partialCount(): number;\n    set partialCount(partialCount: number);\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType(): ToneOscillatorType;\n    set modulationType(type: ToneOscillatorType);\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    get partials(): number[];\n    set partials(partials: number[]);\n    asArray(length?: number): Promise<Float32Array>;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/oscillator/FMOscillator.d.ts": "import { Degrees, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { FMConstructorOptions, FMOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from \"./OscillatorInterface\";\nexport { FMOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * FMOscillator implements a frequency modulation synthesis\n * ```\n *                                              +-------------+\n * +---------------+        +-------------+     | Carrier Osc |\n * | Modulator Osc +>-------> GainNode    |     |             +--->Output\n * +---------------+        |             +>----> frequency   |\n *                       +--> gain        |     +-------------+\n *                       |  +-------------+\n * +-----------------+   |\n * | modulationIndex +>--+\n * +-----------------+\n * ```\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst fmOsc = new Tone.FMOscillator({\n * \t\tfrequency: 200,\n * \t\ttype: \"square\",\n * \t\tmodulationType: \"triangle\",\n * \t\tharmonicity: 0.2,\n * \t\tmodulationIndex: 3\n * \t}).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nexport declare class FMOscillator extends Source<FMOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    /**\n     * The carrier oscillator\n     */\n    private _carrier;\n    readonly frequency: Signal<\"frequency\">;\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The modulating oscillator\n     */\n    private _modulator;\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * A harmonicity of 1 gives both oscillators the same frequency.\n     * Harmonicity = 2 means a change of an octave.\n     * @example\n     * const fmOsc = new Tone.FMOscillator(\"D2\").toDestination().start();\n     * // pitch the modulator an octave below carrier\n     * fmOsc.harmonicity.value = 0.5;\n     */\n    readonly harmonicity: Signal<\"positive\">;\n    /**\n     * The modulation index which is in essence the depth or amount of the modulation. In other terms it is the\n     * ratio of the frequency of the modulating signal (mf) to the amplitude of the\n     * modulating signal (ma) -- as in ma/mf.\n     */\n    readonly modulationIndex: Signal<\"positive\">;\n    /**\n     * the node where the modulation happens\n     */\n    private _modulationNode;\n    /**\n     * @param frequency The starting frequency of the oscillator.\n     * @param type The type of the carrier oscillator.\n     * @param modulationType The type of the modulator oscillator.\n     */\n    constructor(frequency?: Frequency, type?: ToneOscillatorType, modulationType?: ToneOscillatorType);\n    constructor(options?: Partial<FMConstructorOptions>);\n    static getDefaults(): FMOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Time): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time: Time): void;\n    protected _restart(time: Seconds): this;\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    get baseType(): OscillatorType;\n    set baseType(baseType: OscillatorType);\n    get partialCount(): number;\n    set partialCount(partialCount: number);\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType(): ToneOscillatorType;\n    set modulationType(type: ToneOscillatorType);\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    get partials(): number[];\n    set partials(partials: number[]);\n    asArray(length?: number): Promise<Float32Array>;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/oscillator/FatOscillator.d.ts": "import { Cents, Degrees, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { FatConstructorOptions, FatOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from \"./OscillatorInterface\";\nexport { FatOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * FatOscillator is an array of oscillators with detune spread between the oscillators\n * @example\n * const fatOsc = new Tone.FatOscillator(\"Ab3\", \"sawtooth\", 40).toDestination().start();\n * @category Source\n */\nexport declare class FatOscillator extends Source<FatOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    readonly frequency: Signal<\"frequency\">;\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The array of oscillators\n     */\n    private _oscillators;\n    /**\n     * The total spread of the oscillators\n     */\n    private _spread;\n    /**\n     * The type of the oscillator\n     */\n    private _type;\n    /**\n     * The phase of the oscillators\n     */\n    private _phase;\n    /**\n     * The partials array\n     */\n    private _partials;\n    /**\n     * The number of partials to use\n     */\n    private _partialCount;\n    /**\n     * @param frequency The oscillator's frequency.\n     * @param type The type of the oscillator.\n     * @param spread The detune spread between the oscillators.\n     */\n    constructor(frequency?: Frequency, type?: ToneOscillatorType, spread?: Cents);\n    constructor(options?: Partial<FatConstructorOptions>);\n    static getDefaults(): FatOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Time): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time: Time): void;\n    protected _restart(time: Seconds): void;\n    /**\n     * Iterate over all of the oscillators\n     */\n    private _forEach;\n    /**\n     * The type of the oscillator\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    /**\n     * The detune spread between the oscillators. If \"count\" is\n     * set to 3 oscillators and the \"spread\" is set to 40,\n     * the three oscillators would be detuned like this: [-20, 0, 20]\n     * for a total detune spread of 40 cents.\n     * @example\n     * const fatOsc = new Tone.FatOscillator().toDestination().start();\n     * fatOsc.spread = 70;\n     */\n    get spread(): Cents;\n    set spread(spread: Cents);\n    /**\n     * The number of detuned oscillators. Must be an integer greater than 1.\n     * @example\n     * const fatOsc = new Tone.FatOscillator(\"C#3\", \"sawtooth\").toDestination().start();\n     * // use 4 sawtooth oscillators\n     * fatOsc.count = 4;\n     */\n    get count(): number;\n    set count(count: number);\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    get baseType(): OscillatorType;\n    set baseType(baseType: OscillatorType);\n    get partials(): number[];\n    set partials(partials: number[]);\n    get partialCount(): number;\n    set partialCount(partialCount: number);\n    asArray(length?: number): Promise<Float32Array>;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/oscillator/LFO.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { InputNode, OutputNode, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Degrees, Frequency, NormalRange, Time, UnitName } from \"../../core/type/Units\";\nimport { BasicPlaybackState } from \"../../core/util/StateTimeline\";\nimport { Signal } from \"../../signal/Signal\";\nimport { ToneOscillatorType } from \"./Oscillator\";\nimport { ToneOscillatorOptions } from \"./OscillatorInterface\";\nexport type LFOOptions = {\n    min: number;\n    max: number;\n    amplitude: NormalRange;\n    units: UnitName;\n} & ToneOscillatorOptions;\n/**\n * LFO stands for low frequency oscillator. LFO produces an output signal\n * which can be attached to an AudioParam or Tone.Signal\n * in order to modulate that parameter with an oscillator. The LFO can\n * also be synced to the transport to start/stop and change when the tempo changes.\n * @example\n * return Tone.Offline(() => {\n * \tconst lfo = new Tone.LFO(\"4n\", 400, 4000).start().toDestination();\n * }, 0.5, 1);\n * @category Source\n */\nexport declare class LFO extends ToneAudioNode<LFOOptions> {\n    readonly name: string;\n    /**\n     * The oscillator.\n     */\n    private _oscillator;\n    /**\n     * The gain of the output\n     */\n    private _amplitudeGain;\n    /**\n     * The amplitude of the LFO, which controls the output range between\n     * the min and max output. For example if the min is -10 and the max\n     * is 10, setting the amplitude to 0.5 would make the LFO modulate\n     * between -5 and 5.\n     */\n    readonly amplitude: Param<\"normalRange\">;\n    /**\n     * The signal which is output when the LFO is stopped\n     */\n    private _stoppedSignal;\n    /**\n     * Just outputs zeros. This is used so that scaled signal is not\n     * optimized to silence.\n     */\n    private _zeros;\n    /**\n     * The value that the LFO outputs when it's stopped\n     */\n    private _stoppedValue;\n    /**\n     * Convert the oscillators audio range to an output between 0-1 so it can be scaled\n     */\n    private _a2g;\n    /**\n     * Scales the final output to the min and max value\n     */\n    private _scaler;\n    /**\n     * The output of the LFO\n     */\n    readonly output: OutputNode;\n    /**\n     * There is no input node\n     */\n    readonly input: undefined;\n    /**\n     * A private placeholder for the units\n     */\n    private _units;\n    /**\n     * If the input value is converted using the {@link units}\n     */\n    convert: boolean;\n    /**\n     * The frequency value of the LFO\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * @param frequency The frequency of the oscillation.\n     * Typically, LFOs will be in the frequency range of 0.1 to 10 hertz.\n     * @param min The minimum output value of the LFO.\n     * @param max The maximum value of the LFO.\n     */\n    constructor(frequency?: Frequency, min?: number, max?: number);\n    constructor(options?: Partial<LFOOptions>);\n    static getDefaults(): LFOOptions;\n    /**\n     * Start the LFO.\n     * @param time The time the LFO will start\n     */\n    start(time?: Time): this;\n    /**\n     * Stop the LFO.\n     * @param  time The time the LFO will stop\n     */\n    stop(time?: Time): this;\n    /**\n     * Sync the start/stop/pause to the transport\n     * and the frequency to the bpm of the transport\n     * @example\n     * const lfo = new Tone.LFO(\"8n\");\n     * lfo.sync().start(0);\n     * // the rate of the LFO will always be an eighth note, even as the tempo changes\n     */\n    sync(): this;\n    /**\n     * unsync the LFO from transport control\n     */\n    unsync(): this;\n    /**\n     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform\n     */\n    private _setStoppedValue;\n    /**\n     * The minimum output of the LFO.\n     */\n    get min(): number;\n    set min(min: number);\n    /**\n     * The maximum output of the LFO.\n     */\n    get max(): number;\n    set max(max: number);\n    /**\n     * The type of the oscillator.\n     * @see {@link Oscillator.type}\n     */\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    /**\n     * The oscillator's partials array.\n     * @see {@link Oscillator.partials}\n     */\n    get partials(): number[];\n    set partials(partials: number[]);\n    /**\n     * The phase of the LFO.\n     */\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    /**\n     * The output units of the LFO.\n     */\n    get units(): UnitName;\n    set units(val: UnitName);\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     */\n    get state(): BasicPlaybackState;\n    /**\n     * @param node the destination to connect to\n     * @param outputNum the optional output number\n     * @param inputNum the input number\n     */\n    connect(node: InputNode, outputNum?: number, inputNum?: number): this;\n    /**\n     * Private methods borrowed from Param\n     */\n    private _fromType;\n    private _toType;\n    private _is;\n    private _clampValue;\n    dispose(): this;\n}\n",
  "source/oscillator/OmniOscillator.d.ts": "import { Cents, Degrees, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { AMOscillator } from \"./AMOscillator\";\nimport { FatOscillator } from \"./FatOscillator\";\nimport { FMOscillator } from \"./FMOscillator\";\nimport { Oscillator } from \"./Oscillator\";\nimport { OmniOscillatorOptions, OmniOscillatorType, ToneOscillatorInterface, ToneOscillatorType } from \"./OscillatorInterface\";\nimport { PulseOscillator } from \"./PulseOscillator\";\nimport { PWMOscillator } from \"./PWMOscillator\";\nexport { OmniOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * All of the oscillator types that OmniOscillator can take on\n */\ntype AnyOscillator = Oscillator | PWMOscillator | PulseOscillator | FatOscillator | AMOscillator | FMOscillator;\n/**\n * All of the Oscillator constructor types mapped to their name.\n */\ninterface OmniOscillatorSource {\n    fm: FMOscillator;\n    am: AMOscillator;\n    pwm: PWMOscillator;\n    pulse: PulseOscillator;\n    oscillator: Oscillator;\n    fat: FatOscillator;\n}\n/**\n * The available oscillator types.\n */\nexport type OmniOscSourceType = keyof OmniOscillatorSource;\ntype IsAmOrFmOscillator<Osc, Ret> = Osc extends AMOscillator ? Ret : Osc extends FMOscillator ? Ret : undefined;\ntype IsFatOscillator<Osc, Ret> = Osc extends FatOscillator ? Ret : undefined;\ntype IsPWMOscillator<Osc, Ret> = Osc extends PWMOscillator ? Ret : undefined;\ntype IsPulseOscillator<Osc, Ret> = Osc extends PulseOscillator ? Ret : undefined;\ntype IsFMOscillator<Osc, Ret> = Osc extends FMOscillator ? Ret : undefined;\n/**\n * OmniOscillator aggregates all of the oscillator types into one.\n * @example\n * return Tone.Offline(() => {\n * \tconst omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\").toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nexport declare class OmniOscillator<OscType extends AnyOscillator> extends Source<OmniOscillatorOptions> implements Omit<ToneOscillatorInterface, \"type\"> {\n    readonly name: string;\n    readonly frequency: Signal<\"frequency\">;\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The oscillator that can switch types\n     */\n    private _oscillator;\n    /**\n     * the type of the oscillator source\n     */\n    private _sourceType;\n    /**\n     * @param frequency The initial frequency of the oscillator.\n     * @param type The type of the oscillator.\n     */\n    constructor(frequency?: Frequency, type?: OmniOscillatorType);\n    constructor(options?: Partial<OmniOscillatorOptions>);\n    static getDefaults(): OmniOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Time): void;\n    /**\n     * start the oscillator\n     */\n    protected _stop(time: Time): void;\n    protected _restart(time: Seconds): this;\n    /**\n     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or\n     * prefix the basic types with \"fm\", \"am\", or \"fat\" to use the FMOscillator, AMOscillator or FatOscillator\n     * types. The oscillator could also be set to \"pwm\" or \"pulse\". All of the parameters of the\n     * oscillator's class are accessible when the oscillator is set to that type, but throws an error\n     * when it's not.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator().toDestination().start();\n     * omniOsc.type = \"pwm\";\n     * // modulationFrequency is parameter which is available\n     * // only when the type is \"pwm\".\n     * omniOsc.modulationFrequency.value = 0.5;\n     */\n    get type(): OmniOscillatorType;\n    set type(type: OmniOscillatorType);\n    /**\n     * The value is an empty array when the type is not \"custom\".\n     * This is not available on \"pwm\" and \"pulse\" oscillator types.\n     * @see {@link Oscillator.partials}\n     */\n    get partials(): number[];\n    set partials(partials: number[]);\n    get partialCount(): number;\n    set partialCount(partialCount: number);\n    set(props: Partial<OmniOscillatorOptions>): this;\n    /**\n     * connect the oscillator to the frequency and detune signals\n     */\n    private _createNewOscillator;\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    /**\n     * The source type of the oscillator.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare\");\n     * console.log(omniOsc.sourceType); // 'fm'\n     */\n    get sourceType(): OmniOscSourceType;\n    set sourceType(sType: OmniOscSourceType);\n    private _getOscType;\n    /**\n     * The base type of the oscillator.\n     * @see {@link Oscillator.baseType}\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare4\");\n     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);\n     */\n    get baseType(): OscillatorType | \"pwm\" | \"pulse\";\n    set baseType(baseType: OscillatorType | \"pwm\" | \"pulse\");\n    /**\n     * The width of the oscillator when sourceType === \"pulse\".\n     * @see {@link PWMOscillator}\n     */\n    get width(): IsPulseOscillator<OscType, Signal<\"audioRange\">>;\n    /**\n     * The number of detuned oscillators when sourceType === \"fat\".\n     * @see {@link FatOscillator.count}\n     */\n    get count(): IsFatOscillator<OscType, number>;\n    set count(count: IsFatOscillator<OscType, number>);\n    /**\n     * The detune spread between the oscillators when sourceType === \"fat\".\n     * @see {@link FatOscillator.count}\n     */\n    get spread(): IsFatOscillator<OscType, Cents>;\n    set spread(spread: IsFatOscillator<OscType, Cents>);\n    /**\n     * The type of the modulator oscillator. Only if the oscillator is set to \"am\" or \"fm\" types.\n     * @see {@link AMOscillator} or {@link FMOscillator}\n     */\n    get modulationType(): IsAmOrFmOscillator<OscType, ToneOscillatorType>;\n    set modulationType(mType: IsAmOrFmOscillator<OscType, ToneOscillatorType>);\n    /**\n     * The modulation index when the sourceType === \"fm\"\n     * @see {@link FMOscillator}.\n     */\n    get modulationIndex(): IsFMOscillator<OscType, Signal<\"positive\">>;\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * @see {@link AMOscillator} or {@link FMOscillator}\n     */\n    get harmonicity(): IsAmOrFmOscillator<OscType, Signal<\"positive\">>;\n    /**\n     * The modulationFrequency Signal of the oscillator when sourceType === \"pwm\"\n     * see {@link PWMOscillator}\n     * @min 0.1\n     * @max 5\n     */\n    get modulationFrequency(): IsPWMOscillator<OscType, Signal<\"frequency\">>;\n    asArray(length?: number): Promise<Float32Array>;\n    dispose(): this;\n}\n",
  "source/oscillator/Oscillator.d.ts": "import { AudioRange, Degrees, Frequency, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { ToneOscillatorConstructorOptions, ToneOscillatorInterface, ToneOscillatorOptions, ToneOscillatorType } from \"./OscillatorInterface\";\nexport { ToneOscillatorOptions, ToneOscillatorType, } from \"./OscillatorInterface\";\n/**\n * Oscillator supports a number of features including\n * phase rotation, multiple oscillator types (see Oscillator.type),\n * and Transport syncing (see Oscillator.syncFrequency).\n *\n * @example\n * // make and start a 440hz sine tone\n * const osc = new Tone.Oscillator(440, \"sine\").toDestination().start();\n * @category Source\n */\nexport declare class Oscillator extends Source<ToneOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    /**\n     * the main oscillator\n     */\n    private _oscillator;\n    /**\n     * The frequency control.\n     */\n    frequency: Signal<\"frequency\">;\n    /**\n     * The detune control signal.\n     */\n    detune: Signal<\"cents\">;\n    /**\n     * the periodic wave\n     */\n    private _wave?;\n    /**\n     * The partials of the oscillator\n     */\n    private _partials;\n    /**\n     * The number of partials to limit or extend the periodic wave by\n     */\n    private _partialCount;\n    /**\n     * the phase of the oscillator between 0 - 360\n     */\n    private _phase;\n    /**\n     * the type of the oscillator\n     */\n    private _type;\n    /**\n     * @param frequency Starting frequency\n     * @param type The oscillator type. Read more about type below.\n     */\n    constructor(frequency?: Frequency, type?: ToneOscillatorType);\n    constructor(options?: Partial<ToneOscillatorConstructorOptions>);\n    static getDefaults(): ToneOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time?: Time): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time?: Time): void;\n    /**\n     * Restart the oscillator. Does not stop the oscillator, but instead\n     * just cancels any scheduled 'stop' from being invoked.\n     */\n    protected _restart(time?: Time): this;\n    /**\n     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,\n     * will also affect the oscillators frequency.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * osc.frequency.value = 440;\n     * // the ratio between the bpm and the frequency will be maintained\n     * osc.syncFrequency();\n     * // double the tempo\n     * Tone.Transport.bpm.value *= 2;\n     * // the frequency of the oscillator is doubled to 880\n     */\n    syncFrequency(): this;\n    /**\n     * Unsync the oscillator's frequency from the Transport.\n     * @see {@link syncFrequency}\n     */\n    unsyncFrequency(): this;\n    /**\n     * Cache the periodic waves to avoid having to redo computations\n     */\n    private static _periodicWaveCache;\n    /**\n     * Get a cached periodic wave. Avoids having to recompute\n     * the oscillator values when they have already been computed\n     * with the same values.\n     */\n    private _getCachedPeriodicWave;\n    get type(): ToneOscillatorType;\n    set type(type: ToneOscillatorType);\n    get baseType(): OscillatorType;\n    set baseType(baseType: OscillatorType);\n    get partialCount(): number;\n    set partialCount(p: number);\n    /**\n     * Returns the real and imaginary components based\n     * on the oscillator type.\n     * @returns [real: Float32Array, imaginary: Float32Array]\n     */\n    private _getRealImaginary;\n    /**\n     * Compute the inverse FFT for a given phase.\n     */\n    private _inverseFFT;\n    /**\n     * Returns the initial value of the oscillator when stopped.\n     * E.g. a \"sine\" oscillator with phase = 90 would return an initial value of -1.\n     */\n    getInitialValue(): AudioRange;\n    get partials(): number[];\n    set partials(partials: number[]);\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    asArray(length?: number): Promise<Float32Array>;\n    dispose(): this;\n}\n",
  "source/oscillator/OscillatorInterface.d.ts": "import { AudioRange, Cents, Degrees, Frequency, Positive } from \"../../core/type/Units\";\nimport { Omit } from \"../../core/util/Interface\";\nimport { Signal } from \"../../signal/Signal\";\nimport { SourceOptions } from \"../Source\";\n/**\n * The common interface of all Oscillators\n */\nexport interface ToneOscillatorInterface {\n    /**\n     * The oscillator type without the partialsCount appended to the end\n     * @example\n     * const osc = new Tone.Oscillator();\n     * osc.type = \"sine2\";\n     * console.log(osc.baseType); // \"sine\"\n     */\n    baseType: OscillatorType | \"pulse\" | \"pwm\";\n    /**\n     * The oscillator's type. Also capable of setting the first x number of partials of the oscillator.\n     * For example: \"sine4\" would set be the first 4 partials of the sine wave and \"triangle8\" would\n     * set the first 8 partials of the triangle wave.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst osc = new Tone.Oscillator().toDestination().start();\n     * \tosc.type = \"sine2\";\n     * }, 0.1, 1);\n     */\n    type: ExtendedToneOscillatorType;\n    /**\n     * The frequency value of the oscillator\n     * @example\n     * const osc = new Tone.FMOscillator(\"Bb4\").toDestination().start();\n     * osc.frequency.rampTo(\"D2\", 3);\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune value in cents (100th of a semitone).\n     * @example\n     * const osc = new Tone.PulseOscillator(\"F3\").toDestination().start();\n     * // pitch it 1 octave = 12 semitones = 1200 cents\n     * osc.detune.setValueAtTime(-1200, Tone.now());\n     * osc.detune.setValueAtTime(1200, Tone.now() + 0.5);\n     * osc.detune.linearRampToValueAtTime(0, Tone.now() + 1);\n     * osc.stop(Tone.now() + 1.5);\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The phase is the starting position within the oscillator's cycle. For example\n     * a phase of 180 would start halfway through the oscillator's cycle.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst osc = new Tone.Oscillator({\n     * \t\tfrequency: 20,\n     * \t\tphase: 90\n     * \t}).toDestination().start();\n     * }, 0.1, 1);\n     */\n    phase: Degrees;\n    /**\n     * The partials describes the relative amplitude of each of the harmonics of the oscillator.\n     * The first value in the array is the first harmonic (i.e. the fundamental frequency), the\n     * second harmonic is an octave up, the third harmonic is an octave and a fifth, etc. The resulting\n     * oscillator output is composed of a sine tone at the relative amplitude at each of the harmonic intervals.\n     *\n     * Setting this value will automatically set the type to \"custom\".\n     * The value is an empty array when the type is not \"custom\".\n     * @example\n     * const osc = new Tone.Oscillator(\"F3\").toDestination().start();\n     * setInterval(() => {\n     * \t// generate 8 random partials\n     * \tosc.partials = new Array(8).fill(0).map(() => Math.random());\n     * }, 1000);\n     */\n    partials: number[];\n    /**\n     * 'partialCount' offers an alternative way to set the number of used partials.\n     * When partialCount is 0, the maximum number of partials are used when representing\n     * the waveform using the periodicWave. When 'partials' is set, this value is\n     * not settable, but equals the length of the partials array. A square wave wave\n     * is composed of only odd harmonics up through the harmonic series. Partial count\n     * can limit the number of harmonics which are used to generate the waveform.\n     * @example\n     * const osc = new Tone.Oscillator(\"C3\", \"square\").toDestination().start();\n     * osc.partialCount = 1;\n     * setInterval(() => {\n     * \tosc.partialCount++;\n     * \tconsole.log(osc.partialCount);\n     * }, 500);\n     */\n    partialCount?: number;\n    /**\n     * Returns an array of values which represents the waveform.\n     * @param length The length of the waveform to return\n     */\n    asArray(length: number): Promise<Float32Array>;\n}\n/**\n * Render a segment of the oscillator to an offline context and return the results as an array\n */\nexport declare function generateWaveform(instance: any, length: number): Promise<Float32Array>;\n/**\n * The supported number of partials\n */\ntype PartialsRange = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32;\n/**\n * Oscillators with partials\n */\ntype SineWithPartials = `sine${PartialsRange}`;\ntype SquareWithPartials = `square${PartialsRange}`;\ntype SawtoothWithPartials = `sawtooth${PartialsRange}`;\ntype TriangleWithPartials = `triangle${PartialsRange}`;\ntype TypeWithPartials = SineWithPartials | SquareWithPartials | TriangleWithPartials | SawtoothWithPartials;\ninterface BaseOscillatorOptions extends SourceOptions {\n    frequency: Frequency;\n    detune: Cents;\n    phase: Degrees;\n}\nexport type NonCustomOscillatorType = Exclude<OscillatorType, \"custom\">;\ntype AllNonCustomOscillatorType = NonCustomOscillatorType | TypeWithPartials;\nexport type ToneOscillatorType = AllNonCustomOscillatorType | \"custom\";\nexport type ExtendedToneOscillatorType = ToneOscillatorType | \"pwm\" | \"pulse\";\n/**\n * Oscillator Interfaces\n */\ninterface ToneCustomOscillatorOptions extends BaseOscillatorOptions {\n    type: \"custom\";\n    partials: number[];\n}\ninterface ToneTypeOscillatorOptions extends BaseOscillatorOptions {\n    type: NonCustomOscillatorType;\n    partialCount?: number;\n}\ninterface TonePartialOscillatorOptions extends BaseOscillatorOptions {\n    type: TypeWithPartials;\n}\nexport type ToneOscillatorConstructorOptions = ToneCustomOscillatorOptions | ToneTypeOscillatorOptions | TonePartialOscillatorOptions;\nexport interface ToneOscillatorOptions extends BaseOscillatorOptions {\n    type: ToneOscillatorType;\n    partialCount: number;\n    partials: number[];\n}\n/**\n * FMOscillator Interface\n */\ninterface FMBaseOscillatorOptions extends BaseOscillatorOptions {\n    harmonicity: Positive;\n    modulationIndex: Positive;\n    modulationType: AllNonCustomOscillatorType;\n}\ninterface FMCustomOscillatorOptions extends FMBaseOscillatorOptions {\n    type: \"custom\";\n    partials: number[];\n}\ninterface FMTypeOscillatorOptions extends FMBaseOscillatorOptions {\n    type: NonCustomOscillatorType;\n    partialsCount?: number;\n}\ninterface FMPartialsOscillatorOptions extends FMBaseOscillatorOptions {\n    type: TypeWithPartials;\n}\nexport type FMConstructorOptions = FMTypeOscillatorOptions | FMCustomOscillatorOptions | FMPartialsOscillatorOptions;\nexport interface FMOscillatorOptions extends ToneOscillatorOptions {\n    harmonicity: Positive;\n    modulationIndex: Positive;\n    modulationType: AllNonCustomOscillatorType;\n}\n/**\n * AMOscillator Interface\n */\ninterface AMBaseOscillatorOptions extends BaseOscillatorOptions {\n    harmonicity: Positive;\n    modulationType: AllNonCustomOscillatorType;\n}\ninterface AMCustomOscillatorOptions extends AMBaseOscillatorOptions {\n    type: \"custom\";\n    partials: number[];\n}\ninterface AMTypeOscillatorOptions extends AMBaseOscillatorOptions {\n    type: NonCustomOscillatorType;\n    partialsCount?: number;\n}\ninterface AMPartialsOscillatorOptions extends AMBaseOscillatorOptions {\n    type: TypeWithPartials;\n}\nexport type AMConstructorOptions = AMCustomOscillatorOptions | AMTypeOscillatorOptions | AMPartialsOscillatorOptions;\nexport interface AMOscillatorOptions extends ToneOscillatorOptions {\n    harmonicity: Positive;\n    modulationType: AllNonCustomOscillatorType;\n}\n/**\n * FatOscillator\n */\ninterface FatBaseOscillatorOptions extends BaseOscillatorOptions {\n    spread: Cents;\n    count: Positive;\n}\ninterface FatCustomOscillatorOptions extends FatBaseOscillatorOptions {\n    type: \"custom\";\n    partials: number[];\n}\ninterface FatTypeOscillatorOptions extends FatBaseOscillatorOptions {\n    type: NonCustomOscillatorType;\n    partialCount?: number;\n}\ninterface FatPartialsOscillatorOptions extends FatBaseOscillatorOptions {\n    type: TypeWithPartials;\n}\nexport type FatConstructorOptions = FatCustomOscillatorOptions | FatTypeOscillatorOptions | FatPartialsOscillatorOptions;\nexport interface FatOscillatorOptions extends ToneOscillatorOptions {\n    spread: Cents;\n    count: Positive;\n}\n/**\n * Pulse Oscillator\n */\nexport interface PulseOscillatorOptions extends BaseOscillatorOptions {\n    type: \"pulse\";\n    width: AudioRange;\n}\n/**\n * PWM Oscillator\n */\nexport interface PWMOscillatorOptions extends BaseOscillatorOptions {\n    type: \"pwm\";\n    modulationFrequency: Frequency;\n}\n/**\n * OMNI OSCILLATOR\n */\n/**\n * FM Oscillators with partials\n */\ntype FMSineWithPartials = `fmsine${PartialsRange}`;\ntype FMSquareWithPartials = `fmsquare${PartialsRange}`;\ntype FMSawtoothWithPartials = `fmsawtooth${PartialsRange}`;\ntype FMTriangleWithPartials = `fmtriangle${PartialsRange}`;\ntype FMTypeWithPartials = FMSineWithPartials | FMSquareWithPartials | FMSawtoothWithPartials | FMTriangleWithPartials;\n/**\n * AM Oscillators with partials\n */\ntype AMSineWithPartials = `amsine${PartialsRange}`;\ntype AMSquareWithPartials = `amsquare${PartialsRange}`;\ntype AMSawtoothWithPartials = `amsawtooth${PartialsRange}`;\ntype AMTriangleWithPartials = `amtriangle${PartialsRange}`;\ntype AMTypeWithPartials = AMSineWithPartials | AMSquareWithPartials | AMSawtoothWithPartials | AMTriangleWithPartials;\n/**\n * Fat Oscillators with partials\n */\ntype FatSineWithPartials = `fatsine${PartialsRange}`;\ntype FatSquareWithPartials = `fatsquare${PartialsRange}`;\ntype FatSawtoothWithPartials = `fatsawtooth${PartialsRange}`;\ntype FatTriangleWithPartials = `fattriangle${PartialsRange}`;\ntype FatTypeWithPartials = FatSineWithPartials | FatSquareWithPartials | FatSawtoothWithPartials | FatTriangleWithPartials;\n/**\n * Omni FM\n */\ninterface OmniFMCustomOscillatorOptions extends FMBaseOscillatorOptions {\n    type: \"fmcustom\";\n    partials: number[];\n}\ninterface OmniFMTypeOscillatorOptions extends FMBaseOscillatorOptions {\n    type: \"fmsine\" | \"fmsquare\" | \"fmsawtooth\" | \"fmtriangle\";\n    partialsCount?: number;\n}\ninterface OmniFMPartialsOscillatorOptions extends FMBaseOscillatorOptions {\n    type: FMTypeWithPartials;\n}\n/**\n * Omni AM\n */\ninterface OmniAMCustomOscillatorOptions extends AMBaseOscillatorOptions {\n    type: \"amcustom\";\n    partials: number[];\n}\ninterface OmniAMTypeOscillatorOptions extends AMBaseOscillatorOptions {\n    type: \"amsine\" | \"amsquare\" | \"amsawtooth\" | \"amtriangle\";\n    partialsCount?: number;\n}\ninterface OmniAMPartialsOscillatorOptions extends AMBaseOscillatorOptions {\n    type: AMTypeWithPartials;\n}\n/**\n * Omni Fat\n */\ninterface OmniFatCustomOscillatorOptions extends FatBaseOscillatorOptions {\n    type: \"fatcustom\";\n    partials: number[];\n}\ninterface OmniFatTypeOscillatorOptions extends FatBaseOscillatorOptions {\n    type: \"fatsine\" | \"fatsquare\" | \"fatsawtooth\" | \"fattriangle\";\n    partialsCount?: number;\n}\ninterface OmniFatPartialsOscillatorOptions extends FatBaseOscillatorOptions {\n    type: FatTypeWithPartials;\n}\nexport type OmniOscillatorType = \"fatsine\" | \"fatsquare\" | \"fatsawtooth\" | \"fattriangle\" | \"fatcustom\" | FatTypeWithPartials | \"fmsine\" | \"fmsquare\" | \"fmsawtooth\" | \"fmtriangle\" | \"fmcustom\" | FMTypeWithPartials | \"amsine\" | \"amsquare\" | \"amsawtooth\" | \"amtriangle\" | \"amcustom\" | AMTypeWithPartials | TypeWithPartials | OscillatorType | \"pulse\" | \"pwm\";\nexport type OmniOscillatorOptions = PulseOscillatorOptions | PWMOscillatorOptions | OmniFatCustomOscillatorOptions | OmniFatTypeOscillatorOptions | OmniFatPartialsOscillatorOptions | OmniFMCustomOscillatorOptions | OmniFMTypeOscillatorOptions | OmniFMPartialsOscillatorOptions | OmniAMCustomOscillatorOptions | OmniAMTypeOscillatorOptions | OmniAMPartialsOscillatorOptions | ToneOscillatorConstructorOptions;\ntype OmitSourceOptions<T extends BaseOscillatorOptions> = Omit<T, \"frequency\" | \"detune\" | \"context\">;\n/**\n * The settable options for the omni oscillator inside of the source which excludes certain attributes that are defined by the parent class\n */\nexport type OmniOscillatorSynthOptions = OmitSourceOptions<PulseOscillatorOptions> | OmitSourceOptions<PWMOscillatorOptions> | OmitSourceOptions<OmniFatCustomOscillatorOptions> | OmitSourceOptions<OmniFatTypeOscillatorOptions> | OmitSourceOptions<OmniFatPartialsOscillatorOptions> | OmitSourceOptions<OmniFMCustomOscillatorOptions> | OmitSourceOptions<OmniFMTypeOscillatorOptions> | OmitSourceOptions<OmniFMPartialsOscillatorOptions> | OmitSourceOptions<OmniAMCustomOscillatorOptions> | OmitSourceOptions<OmniAMTypeOscillatorOptions> | OmitSourceOptions<OmniAMPartialsOscillatorOptions> | OmitSourceOptions<ToneCustomOscillatorOptions> | OmitSourceOptions<ToneTypeOscillatorOptions> | OmitSourceOptions<TonePartialOscillatorOptions>;\nexport {};\n",
  "source/oscillator/PWMOscillator.d.ts": "import { Degrees, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { PWMOscillatorOptions, ToneOscillatorInterface } from \"./OscillatorInterface\";\nexport { PWMOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * PWMOscillator modulates the width of a Tone.PulseOscillator\n * at the modulationFrequency. This has the effect of continuously\n * changing the timbre of the oscillator by altering the harmonics\n * generated.\n * @example\n * return Tone.Offline(() => {\n * \tconst pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nexport declare class PWMOscillator extends Source<PWMOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    readonly sourceType = \"pwm\";\n    /**\n     * the pulse oscillator\n     */\n    private _pulse;\n    /**\n     * the modulator\n     */\n    private _modulator;\n    /**\n     * Scale the oscillator so it doesn't go silent\n     * at the extreme values.\n     */\n    private _scale;\n    /**\n     * The frequency control.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune of the oscillator.\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * The width modulation rate of the oscillator.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst osc = new Tone.PWMOscillator(20, 2).toDestination().start();\n     * }, 0.1, 1);\n     */\n    readonly modulationFrequency: Signal<\"frequency\">;\n    /**\n     * @param {Frequency} frequency The starting frequency of the oscillator.\n     * @param {Frequency} modulationFrequency The modulation frequency of the width of the pulse.\n     */\n    constructor(frequency?: Frequency, modulationFrequency?: Frequency);\n    constructor(options?: Partial<PWMOscillatorOptions>);\n    static getDefaults(): PWMOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Time): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time: Time): void;\n    /**\n     * restart the oscillator\n     */\n    protected _restart(time: Seconds): void;\n    /**\n     * The type of the oscillator. Always returns \"pwm\".\n     */\n    get type(): \"pwm\";\n    /**\n     * The baseType of the oscillator. Always returns \"pwm\".\n     */\n    get baseType(): \"pwm\";\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials(): number[];\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount(): number;\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    asArray(length?: number): Promise<Float32Array>;\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "source/oscillator/PulseOscillator.d.ts": "import { AudioRange, Degrees, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { PulseOscillatorOptions, ToneOscillatorInterface } from \"./OscillatorInterface\";\nexport { PulseOscillatorOptions } from \"./OscillatorInterface\";\n/**\n * PulseOscillator is an oscillator with control over pulse width,\n * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is\n * a square wave.\n * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).\n * ```\n *    width = -0.25        width = 0.0          width = 0.25\n *\n *   +-----+            +-------+       +    +-------+     +-+\n *   |     |            |       |       |            |     |\n *   |     |            |       |       |            |     |\n * +-+     +-------+    +       +-------+            +-----+\n *\n *\n *    width = -0.5                              width = 0.5\n *\n *     +---+                                 +-------+   +---+\n *     |   |                                         |   |\n *     |   |                                         |   |\n * +---+   +-------+                                 +---+\n *\n *\n *    width = -0.75                             width = 0.75\n *\n *       +-+                                 +-------+ +-----+\n *       | |                                         | |\n *       | |                                         | |\n * +-----+ +-------+                                 +-+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nexport declare class PulseOscillator extends Source<PulseOscillatorOptions> implements ToneOscillatorInterface {\n    readonly name: string;\n    /**\n     * The width of the pulse.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst pulse = new Tone.PulseOscillator(20, 0.8).toDestination().start();\n     * }, 0.1, 1);\n     */\n    readonly width: Signal<\"audioRange\">;\n    /**\n     * gate the width amount\n     */\n    private _widthGate;\n    /**\n     * the sawtooth oscillator\n     */\n    private _triangle;\n    /**\n     * The frequency control.\n     */\n    readonly frequency: Signal<\"frequency\">;\n    /**\n     * The detune in cents.\n     */\n    readonly detune: Signal<\"cents\">;\n    /**\n     * Threshold the signal to turn it into a square\n     */\n    private _thresh;\n    /**\n     * @param frequency The frequency of the oscillator\n     * @param width The width of the pulse\n     */\n    constructor(frequency?: Frequency, width?: AudioRange);\n    constructor(options?: Partial<PulseOscillatorOptions>);\n    static getDefaults(): PulseOscillatorOptions;\n    /**\n     * start the oscillator\n     */\n    protected _start(time: Time): void;\n    /**\n     * stop the oscillator\n     */\n    protected _stop(time: Time): void;\n    protected _restart(time: Seconds): void;\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase(): Degrees;\n    set phase(phase: Degrees);\n    /**\n     * The type of the oscillator. Always returns \"pulse\".\n     */\n    get type(): \"pulse\";\n    /**\n     * The baseType of the oscillator. Always returns \"pulse\".\n     */\n    get baseType(): \"pulse\";\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials(): number[];\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount(): number;\n    /**\n     * *Internal use* The carrier oscillator type is fed through the\n     * waveshaper node to create the pulse. Using different carrier oscillators\n     * changes oscillator's behavior.\n     */\n    set carrierType(type: \"triangle\" | \"sine\");\n    asArray(length?: number): Promise<Float32Array>;\n    /**\n     * Clean up method.\n     */\n    dispose(): this;\n}\n",
  "source/oscillator/ToneOscillatorNode.d.ts": "import { Param } from \"../../core/context/Param\";\nimport { Cents, Frequency, Seconds, Time } from \"../../core/type/Units\";\nimport { OneShotSource, OneShotSourceOptions } from \"../OneShotSource\";\nexport interface ToneOscillatorNodeOptions extends OneShotSourceOptions {\n    frequency: Frequency;\n    detune: Cents;\n    type: OscillatorType;\n}\n/**\n * Wrapper around the native fire-and-forget OscillatorNode.\n * Adds the ability to reschedule the stop method.\n * ***{@link Oscillator} is better for most use-cases***\n * @category Source\n */\nexport declare class ToneOscillatorNode extends OneShotSource<ToneOscillatorNodeOptions> {\n    readonly name: string;\n    /**\n     * The oscillator\n     */\n    private _oscillator;\n    protected _internalChannels: OscillatorNode[];\n    /**\n     * The frequency of the oscillator\n     */\n    readonly frequency: Param<\"frequency\">;\n    /**\n     * The detune of the oscillator\n     */\n    readonly detune: Param<\"cents\">;\n    /**\n     * @param  frequency   The frequency value\n     * @param  type  The basic oscillator type\n     */\n    constructor(frequency: Frequency, type: OscillatorType);\n    constructor(options?: Partial<ToneOscillatorNodeOptions>);\n    static getDefaults(): ToneOscillatorNodeOptions;\n    /**\n     * Start the oscillator node at the given time\n     * @param  time When to start the oscillator\n     */\n    start(time?: Time): this;\n    protected _stopSource(time?: Seconds): void;\n    /**\n     * Sets an arbitrary custom periodic waveform given a PeriodicWave.\n     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave\n     */\n    setPeriodicWave(periodicWave: PeriodicWave): this;\n    /**\n     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'\n     */\n    get type(): OscillatorType;\n    set type(type: OscillatorType);\n    /**\n     * Clean up.\n     */\n    dispose(): this;\n}\n",
  "version.d.ts": "export declare const version: string;\n"
}
